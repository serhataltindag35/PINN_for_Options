{
  "cells": [
    {
      "cell_type": "code",
      "source": [
        " pip install QuantLib"
      ],
      "metadata": {
        "id": "RWVWFuAc8RaA",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "7e0016aa-12e3-4748-c81c-c40f74b32483"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting QuantLib\n",
            "  Downloading quantlib-1.39-cp38-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (1.1 kB)\n",
            "Downloading quantlib-1.39-cp38-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (20.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m20.1/20.1 MB\u001b[0m \u001b[31m70.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: QuantLib\n",
            "Successfully installed QuantLib-1.39\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CONNECTING TO GOOGLE DRIVE***"
      ],
      "metadata": {
        "id": "hLxjrfN9SRqz"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XWz5dsiOsXKn",
        "outputId": "daa3317f-61d0-4433-dcda-b680eb790525"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mounted at /content/drive\n"
          ]
        }
      ],
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***LIBRARIES***"
      ],
      "metadata": {
        "id": "FzYg8erdSTu3"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "VcDiBAjHHdNp"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import numpy as np\n",
        "from scipy.stats import norm\n",
        "import matplotlib.pyplot as plt\n",
        "import torch.nn.functional as Func\n",
        "from sklearn.metrics import mean_absolute_percentage_error, mean_squared_error\n",
        "import pandas as pd\n",
        "import os\n",
        "from scipy.stats import norm\n",
        "from scipy.optimize import minimize\n",
        "import QuantLib as ql\n",
        "from datetime import datetime\n",
        "\n",
        "#torch.manual_seed(123)\n",
        "np.random.seed(123)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "WMR_Z90-PudB"
      },
      "source": [
        "# ***MODEL***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BESwU-WRHoAS"
      },
      "outputs": [],
      "source": [
        "# Define the ABU activation function for the SABR PDE\n",
        "class SinSoftplusActivation(nn.Module):\n",
        "    def forward(self, input):\n",
        "        new_act_f = 0.005*torch.sin(input) + 1*torch.nn.functional.softplus(input) + 0*torch.nn.functional.tanh(input) + 0.00*torch.nn.functional.gelu(input)\n",
        "        return new_act_f"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "r9zToy_-Hpip"
      },
      "outputs": [],
      "source": [
        "class Alternative_FCN(nn.Module):\n",
        "    def __init__(self):\n",
        "        super(Alternative_FCN, self).__init__()\n",
        "        self.bn1 = nn.BatchNorm1d(3)\n",
        "        self.fc1 = nn.Linear(3, 200)\n",
        "        self.act1 = SinSoftplusActivation()\n",
        "        self.bn2 = nn.BatchNorm1d(200)\n",
        "        self.fc2 = nn.Linear(200, 200)\n",
        "        self.act2 = SinSoftplusActivation()\n",
        "        self.bn3 = nn.BatchNorm1d(200)\n",
        "        self.fc3 = nn.Linear(200, 200)\n",
        "        self.act3 = SinSoftplusActivation()\n",
        "        self.bn4 = nn.BatchNorm1d(200)\n",
        "        self.fc4 = nn.Linear(200, 200)\n",
        "        self.act4 = SinSoftplusActivation()\n",
        "        self.bn5 = nn.BatchNorm1d(200)\n",
        "        self.fc5 = nn.Linear(200, 200)\n",
        "        self.act5 = SinSoftplusActivation()\n",
        "        self.bn6 = nn.BatchNorm1d(200)\n",
        "        self.fc6 = nn.Linear(200, 1)\n",
        "\n",
        "\n",
        "    def forward(self, x):\n",
        "        x = self.fc1(x)\n",
        "        x = self.act1(x)\n",
        "        x = self.fc2(x)\n",
        "        x = self.act2(x)\n",
        "        x = self.fc3(x)\n",
        "        x = self.act3(x)\n",
        "        x = self.fc4(x)\n",
        "        x = self.act4(x)\n",
        "        x = self.fc5(x)\n",
        "        x = self.act5(x)\n",
        "        x = self.fc6(x)\n",
        "        return x"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "PT_ANQAePmCK"
      },
      "source": [
        "# ***RANDOM DATASET GENERATION FOR PDE AND OTHER CONDITIONS***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 637
        },
        "id": "8XUewANPHllD",
        "outputId": "e4d2413c-fccd-4b36-dcfa-3e8a7b979c54"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Total points: 2190\n",
            "Interior: 365 points (S∈[0.3, 149.7])\n",
            "S=0 boundary: 365 points (σ∈[0.0, 0.5])\n",
            "σ=0 boundary: 365 points (S∈[0.8, 149.5])\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 1000x600 with 1 Axes>"
            ],
            "image/png": "iVBORw0KGgoAAAANSUhEUgAAA04AAAIjCAYAAAA0vUuxAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjAsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvlHJYcgAAAAlwSFlzAAAPYQAAD2EBqD+naQABAABJREFUeJzsnXl8FPX9/18ze+8m2U1CQkiAcB9yKnggIocoVkWxWjxaEbx+reXrgdazImA96gForbVf/Sq2tlWrFa1aFSlYpVStJyggIAE5Qg5ybDZ7znx+f0x2ySa7yR6zc+y8n4/HQnbmszOfnZ35fN73h2OMMRAEQRAEQRAEQRBJ4dXuAEEQBEEQBEEQhNYhxYkgCIIgCIIgCKIXSHEiCIIgCIIgCILoBVKcCIIgCIIgCIIgeoEUJ4IgCIIgCIIgiF4gxYkgCIIgCIIgCKIXSHEiCIIgCIIgCILoBVKcCIIgCIIgCIIgeoEUJ4IgCIIgCIIgiF4gxYkgiKxYuHAhBg0alNFnly1bBo7j5O2QSnAch2XLlqndjYxR8reYMWMGZsyYEXu/ceNGcByHl19+WZHzZ3PPysHHH38Mq9WKvXv3qtYHQnkSPWODBg3CwoULU/p81+cmF9x222048cQTc3oOgtAzpDgRRJ7CcVxKr40bN6rdVVVYuHBh3HUoKirChAkT8MgjjyAYDCral/vuuw9r166V7Xhr1qyJ+252ux2VlZWYM2cOHnvsMXi9XlnOc/DgQSxbtgxffPGFLMeTEy337c4778Qll1yC6urq2LaPP/4Y1157LSZNmgSLxZKRErtt2zaceeaZKCgoQElJCS677DLU19d3ayeKIh588EEMHjwYdrsd48ePx1/+8pesjknIwzfffINly5ahpqZGlfPfcMMN+PLLL/H666+rcn6C0DpmtTtAEERu+OMf/xj3/g9/+APWrVvXbfvo0aOzOs9TTz0FURQz+uwvf/lL3HbbbVmdPxtsNhuefvppAEBzczNeeeUV3Hzzzfjkk0/wwgsvpHUsv98PszmzIfW+++7DhRdeiHnz5mX0+WSsWLECgwcPRjgcRm1tLTZu3IgbbrgBK1euxOuvv47x48fH2mbyWxw8eBDLly/HoEGDMHHixJQ/9+6776Z1nkzoqW/Z3LPZ8sUXX+C9997Dv//977jtb731Fp5++mmMHz8eQ4YMwbfffpvWcffv349TTz0Vbrcb9913H9ra2vDwww9jy5YtMQ9XlDvvvBMPPPAArr76ahx//PF47bXXcOmll4LjOFx88cUZHZPIjB07doDnj9qwv/nmGyxfvhwzZszo5hVV4rmpqKjAeeedh4cffhjnnntuzs9HELqDEQRhCH7+85+zVB55n8+nQG/U5/LLL2culytumyAIbPLkyQwAO3DggGJ9cblc7PLLL5fteM8++ywDwD755JNu+9avX88cDgerrq5m7e3tWZ3nk08+YQDYs88+m1L7ZPfWhg0bGAD217/+Nav+ZNM3pbjuuuvYwIEDmSiKcdtra2tjv0eqz2pnfvaznzGHw8H27t0b27Zu3ToGgP3+97+Pbdu/fz+zWCzs5z//eWybKIps2rRprH///iwSiaR9TDVpa2tTuwspc/fdd/f6u/71r39lANiGDRuU6VQCXn75ZcZxHNu9e7dqfSAIrUKhegRhYGbMmIGxY8fi008/xamnngqn04k77rgDAPDaa6/h7LPPRmVlJWw2G4YOHYp77rkHgiDEHaNrvkhNTQ04jsPDDz+M//3f/8XQoUNhs9lw/PHH45NPPon7bKKYf47jsHjxYqxduxZjx46FzWbDmDFj8Pbbb3fr/8aNGzF58mTY7XYMHToUv//977PK1eF5PpZDEA2Vqaurw5VXXom+ffvCbrdjwoQJeO6557p9tmuOU7Qfu3btwsKFC+HxeOB2u7Fo0SK0t7fHfc7n8+G5556LhdZFcx68Xi9uuOEGDBo0CDabDeXl5Tj99NPx2WefZfT9AGDWrFm46667sHfvXjz//PPd+tuZdevW4ZRTToHH40FBQQFGjhwZuz82btyI448/HgCwaNGiWN/XrFkDoOd7K1muhiAIuOOOO1BRUQGXy4Vzzz0X33//fVybZDkhnY/ZW98S5Tj5fD7cdNNNGDBgAGw2G0aOHImHH34YjLG4duncn4lYu3YtZs2a1e1a9+3bFw6HI6VjJOKVV17BOeecg4EDB8a2zZ49GyNGjMBLL70U2/baa68hHA7j2muvjftOP/vZz7B//35s3rw57WMmovM4sGrVKlRXV8PhcGD69OnYunVrt/bbt2/HhRdeiJKSEtjtdkyePLlbuFg0BPX999/Htddei/LycvTv37/HfgQCASxbtgwjRoyA3W5Hv3798MMf/hC7d++OtcnFb//hhx/i+OOPjxubEtH5fl6zZg1+9KMfAQBmzpzZLZw60XOTyviUzpgMSL8xIN0rBEHEQ6F6BGFwGhsb8YMf/AAXX3wxfvKTn6Bv374ApEm8oKAAS5YsQUFBAf75z39i6dKlaG1txUMPPdTrcf/85z/D6/Xi//2//weO4/Dggw/ihz/8Ib777jtYLJYeP/vhhx/ib3/7G6699loUFhbisccewwUXXIB9+/ahtLQUAPD555/jzDPPRL9+/bB8+XIIgoAVK1agrKwsq+sRFahKS0vh9/sxY8YM7Nq1C4sXL8bgwYPx17/+FQsXLkRzczOuv/76Xo83f/58DB48GPfffz8+++wzPP300ygvL8evf/1rAFJI5VVXXYUTTjgB11xzDQBg6NChAICf/vSnePnll7F48WIcc8wxaGxsxIcffoht27bhuOOOy/g7XnbZZbjjjjvw7rvv4uqrr07Y5uuvv8Y555yD8ePHY8WKFbDZbNi1axc2bdoEQArxXLFiBZYuXYprrrkG06ZNAwCcfPLJsWMku7eSce+994LjONx6662oq6vD6tWrMXv2bHzxxRdpKRWp9K0zjDGce+652LBhA6688kpMnDgR77zzDn7xi1/gwIEDWLVqVVz7VO7PRBw4cAD79u3L6rdLdty6ujpMnjy5274TTjgBb731Vuz9559/DpfL1S1E94QTTojtP+WUU9I6Zk/84Q9/gNfrxc9//nMEAgE8+uijmDVrFrZs2RK7H77++mtMnToVVVVVuO222+ByufDSSy9h3rx5eOWVV3D++efHHfPaa69FWVkZli5dCp/Pl/TcgiDgnHPOwfr163HxxRfj+uuvh9frxbp167B161YMHTo0J7/9li1bcMYZZ6CsrAzLli1DJBLB3Xff3ev9f+qpp+K6667DY489hjvuuCP2GyULp053fEp1THa73Rg6dCg2bdqEG2+8scc+E4ThUNfhRRCEUiQK/5k+fToDwJ588slu7ROFcf2///f/mNPpZIFAILbt8ssvZ9XV1bH3e/bsYQBYaWkpO3LkSGz7a6+9xgCwv//977FtiUJXADCr1cp27doV2/bll18yAOw3v/lNbNvcuXOZ0+mMC6nbuXMnM5vNKYU5RUP16uvrWX19Pdu1axe77777GMdxbPz48YwxxlavXs0AsOeffz72uVAoxKZMmcIKCgpYa2trXL/vvvvubt/tiiuuiDvv+eefz0pLS+O2JQvVc7vdcSFVqdJTqF7nYx977LHd+htl1apVDACrr69PeoyewuF6uremT5/Opk+fHnsfDdWrqqqKu6YvvfQSA8AeffTR2Lbq6uqE16rrMXvqW9d7du3atQwA+9WvfhXX7sILL2Qcx8Xdi6nen4l47733uj0DiUg3VC/6Xf/whz902/eLX/yCAYg9s2effTYbMmRIt3Y+n48BYLfddlvax0xEdBxwOBxs//79se0fffQRA8BuvPHG2LbTTjuNjRs3Lu54oiiyk08+mQ0fPjy2LXpfn3LKKXEhhcl45plnGAC2cuXKbvuioZK5+O3nzZvH7HZ7XIjjN998w0wmU7fftev93FOoXtd7PNXxKZ0xOcoZZ5zBRo8e3W07QRgdCtUjCINjs9mwaNGibts7W/i9Xi8aGhowbdo0tLe3Y/v27b0e96KLLkJxcXHsfdTq/9133/X62dmzZ8e8LgAwfvx4FBUVxT4rCALee+89zJs3D5WVlbF2w4YNww9+8INejx/F5/OhrKwMZWVlGDZsGO644w5MmTIFr776KgApYb+iogKXXHJJ7DMWiwXXXXcd2tra8P777/d6jp/+9Kdx76dNm4bGxka0trb2+lmPx4OPPvoIBw8eTPk7pUpBQUGP1fU8Hg8AKVwn00IKye6tZCxYsACFhYWx9xdeeCH69euXsncjU9566y2YTCZcd911cdtvuukmMMbwj3/8I257b/dnMhobGwEg7rmQA7/fD0C63l2x2+1xbfx+f8rtUj1mT8ybNw9VVVWx9yeccAJOPPHE2G965MgR/POf/8T8+fNj40xDQwMaGxsxZ84c7Ny5EwcOHIg75tVXXw2TydTruV955RX06dMH//M//9NtXzRUUu7fXhAEvPPOO5g3b15ciOPo0aMxZ86cXvucDumOT+mMycXFxWhoaJC1vwSRD5DiRBAGp6qqKmF1rK+//hrnn38+3G43ioqKUFZWhp/85CcAgJaWll6P21loAI4Ki01NTWl/Nvr56Gfr6urg9/sxbNiwbu0SbUuG3W7HunXrsG7dOvzrX//C999/j02bNmHIkCEAgL1792L48OFxVa+Ao6EzqazDk811ePDBB7F161YMGDAAJ5xwApYtW5aS4pkKbW1tcUpKVy666CJMnToVV111Ffr27YuLL74YL730UlpKVLJ7KxnDhw+Pe89xHIYNG5bz0sx79+5FZWVlt+uR7Hfu7f7sDdYldyZbokaORGX0A4FAXBuHw5Fyu1SP2RNdf1MAGDFiROw33bVrFxhjuOuuu2JGjOjr7rvvBiA9750ZPHhwr+cFpLDbkSNH9ljtUu7fvr6+Hn6/P+H3HjlyZEr9TpV0x6d0xiLGWN6ssUcQckI5TgRhcBIJP83NzZg+fTqKioqwYsUKDB06FHa7HZ999hluvfXWlITnZBbhVITGbD6bDiaTKZYInSuy+S7z58/HtGnT8Oqrr+Ldd9/FQw89hF//+tf429/+lpZnrSv79+9HS0tLj0qmw+HAv/71L2zYsAFvvvkm3n77bbz44ouYNWsW3n333ZQs/tkUO0hGMmFOEISU+iQHmf6m0RyYVBWsVOnXrx8A4NChQ932HTp0CCUlJTHPUb9+/bBhw4ZugnH0s1EPbjrHzIboWHLzzTcn9ch0vU9zcV+lilJjUy5Ip+9NTU3o06dPrrtEELqDPE4EQXRj48aNaGxsxJo1a3D99dfjnHPOwezZs2UPMcqU8vJy2O127Nq1q9u+RNsypbq6Gjt37uymKEZDFTsvYJoNPVl2+/Xrh2uvvRZr167Fnj17UFpainvvvTer80XX8uotdIjneZx22mlYuXIlvvnmG9x777345z//iQ0bNvTa70zYuXNn3HvGGHbt2hVXAa+4uBjNzc3dPtvVup5O36qrq3Hw4MFuoYty/86jRo0CAOzZs0eW40WpqqpCWVkZ/vvf/3bb9/HHH8etYzVx4kS0t7dj27Ztce0++uij2P50j9kTXX9TAPj2229jv2nUu2uxWDB79uyEr548oz0xdOhQ7NixA+FwOGkbuX/7srIyOByOhN97x44dvX4+3fs2V+PTnj17sl7jjyDyEVKcCILoRtQy2dkSGQqF8MQTT6jVpTiinqK1a9fG5f/s2rWrW05CNpx11lmora3Fiy++GNsWiUTwm9/8BgUFBZg+fbos53G5XN2UAUEQuoVElpeXo7KyMmH4VKr885//xD333IPBgwfjxz/+cdJ2R44c6bYtKixHz+9yuQAgoSKTCdEKbFFefvllHDp0KM67NnToUPznP/9BKBSKbXvjjTe6lS1Pp29nnXUWBEHA448/Hrd91apV4DguK+9eZ6qqqjBgwICEyki2XHDBBd2uw/r16/Htt9/GSlwDwHnnnQeLxRL3LDPG8OSTT6Kqqiqu8mCqx+yJtWvXxuUoffzxx/joo49i17S8vBwzZszA73//+4Terfr6+pTOk4gLLrgADQ0N3X5X4OjYJvdvbzKZMGfOHKxduxb79u2Lbd+2bRveeeedXj+f7n2bi/GppaUFu3fvTlqFkiCMDIXqEQTRjZNPPhnFxcW4/PLLcd1114HjOPzxj3/UVDjKsmXL8O6772Lq1Kn42c9+FhN+xo4diy+++EKWc1xzzTX4/e9/j4ULF+LTTz/FoEGD8PLLL2PTpk1YvXp1xpbwrkyaNAnvvfceVq5cicrKSgwePBgjR45E//79ceGFF2LChAkoKCjAe++9h08++QSPPPJISsf9xz/+ge3btyMSieDw4cP45z//iXXr1qG6uhqvv/56LMk/EStWrMC//vUvnH322aiurkZdXR2eeOIJ9O/fH6eccgoASYnxeDx48sknUVhYCJfLhRNPPDHlHJSulJSU4JRTTsGiRYtw+PBhrF69GsOGDYsrmX7VVVfh5Zdfxplnnon58+dj9+7deP755+MS9tPt29y5czFz5kzceeedqKmpwYQJE/Duu+/itddeww033NDt2Nlw3nnn4dVXX+0WKrd3796YJzCqWP3qV78CIHkOLrvssljbGTNm4P333497Hu+44w789a9/xcyZM3H99dejra0NDz30EMaNGxdXoKN///644YYb8NBDDyEcDuP444/H2rVr8cEHH+BPf/pTXDhXqsfsiWHDhuGUU07Bz372MwSDQaxevRqlpaW45ZZbYm1++9vf4pRTTsG4ceNw9dVXY8iQITh8+DA2b96M/fv348svv0znEsdYsGAB/vCHP2DJkiX4+OOPMW3aNPh8Prz33nu49tprcd555+Xkt1++fDnefvttTJs2Dddee21MmRkzZgy++uqrHj87ceJEmEwm/PrXv0ZLSwtsNhtmzZqF8vLybm1zNT699957YIzhvPPOy+jzBJHXKFvEjyAItUhWjnzMmDEJ22/atImddNJJzOFwsMrKSnbLLbewd955p1up3GTlyB966KFux0SSkt1d2yQqwZ2oDPX69evZsccey6xWKxs6dCh7+umn2U033cTsdnuSq3CUaDny3jh8+DBbtGgR69OnD7NarWzcuHEJS1wn+25dy3lHSyrv2bMntm379u3s1FNPZQ6HgwFgl19+OQsGg+wXv/gFmzBhAissLGQul4tNmDCBPfHEE732OXqO6MtqtbKKigp2+umns0cffTSu5HfX/kZZv349O++881hlZSWzWq2ssrKSXXLJJezbb7+N+9xrr73GjjnmmFgZ+Oi16eneSlaO/C9/+Qu7/fbbWXl5OXM4HOzss8+OK+kc5ZFHHmFVVVXMZrOxqVOnsv/+97/djtlT37res4wx5vV62Y033sgqKyuZxWJhw4cPZw899FCsbHWUdO7PRHz22WcMAPvggw/itkevQaJX1+81adIkVlFR0e3YW7duZWeccQZzOp3M4/GwH//4x6y2trZbO0EQ2H333ceqq6uZ1WplY8aMiStpnckxu9J5HHjkkUfYgAEDmM1mY9OmTWNffvllt/a7d+9mCxYsYBUVFcxisbCqqip2zjnnsJdffjnWJpUy+11pb29nd955Jxs8eDCzWCysoqKCXXjhhWz37t2xNrn47d9//302adIkZrVa2ZAhQ9iTTz6ZcLxL9NmnnnqKDRkyJFa+PDreJrrHUxmf0hmTGWPsoosuYqecckq3tgRBMMYxpiETMkEQRJbMmzcPX3/9dcIcA4LQAqeddhoqKytjHqZ08Hq9KCkpwerVq/Hzn/88B72Th5qaGgwePBgPPfQQbr75ZrW7Q6RIbW0tBg8ejBdeeIE8TgSRAMpxIghCt3RdR2bnzp146623MGPGDHU6RBApcN999+HFF19MqZx9V/71r3+hqqoqLnyRIORi9erVGDduHClNBJEE8jgRBKFb+vXrh4ULF2LIkCHYu3cvfve73yEYDOLzzz9PuI4KQRDKQB4ngiDyESoOQRCEbjnzzDPxl7/8BbW1tbDZbJgyZQruu+8+UpoIgiAIgpAd8jgRBEEQBEEQBEH0AuU4EQRBEARBEARB9AIpTgRBEARBEARBEL1guBwnURRx8OBBFBYWxi0+SBAEQRAEQRCEsWCMwev1orKyEjzfs0/JcIrTwYMHMWDAALW7QRAEQRAEQRCERvj+++/Rv3//HtsYTnEqLCwEIF2coqIilXtDEARBEARBEIRatLa2YsCAATEdoScMpzhFw/OKiopIcSIIgiAIgiAIIqUUHioOQRAEQRAEQRAE0QukOBEEQRAEQRAEQfQCKU4EQRAEQRAEQRC9YLgcJ4IgCIIgCELbMMYQiUQgCILaXSHyAIvFApPJlPVxSHEiCIIgCIIgNEMoFMKhQ4fQ3t6udleIPIHjOPTv3x8FBQVZHYcUJ4IgCIIgCEITiKKIPXv2wGQyobKyElarNaVqZwSRDMYY6uvrsX//fgwfPjwrzxMpTgRBEARBEIQmCIVCEEURAwYMgNPpVLs7RJ5QVlaGmpoahMPhrBQnKg5BEARBEARBaAqeJxGVkA+5vJZ0VxIEQRAEQRAEQfQCKU4EQRAEQRAEQRC9QIoTQRAEQRAEQeiYjRs3guM4NDc3q92VvIYUJ4IgCIIgCILIkoULF2LevHkpt+c4DmvXrpXl3CeffDIOHToEt9sty/GIxFBVPYIgCIIgCCLvYIyhuT2MYESEzczD47TkZWnzcDgMq9WKioqKrI4TCoVgtVpl6lV+Qh4nNRFFoGkvcPhr6X9RVLtHBEEQssEYQ5MvhNqWAJp8ITDG1O4SQRAGoa41gA3b6/HGVwfx5paDeOOrg9iwvR51rQFFzj9jxgxcd911uOWWW1BSUoKKigosW7Ystn/QoEEAgPPPPx8cx8XeA8Brr72G4447Dna7HUOGDMHy5csRiURi+zmOw+9+9zuce+65cLlcuPfeexOG6r3yyisYM2YMbDYbBg0ahEceeSSuj4MGDcI999yDBQsWoKioCNdcc00uLkVeoQnF6be//S0GDRoEu92OE088ER9//HHStmvWrAHHcXEvu92uYG9lon4H8OFKYMN9wPsPSv9/uFLaThAEoXPUFloIQuuQYSF31LUGsHFHPXbXe1Fkt6C/x4kiuwW7673YuEO5cei5556Dy+XCRx99hAcffBArVqzAunXrAACffPIJAODZZ5/FoUOHYu8/+OADLFiwANdffz2++eYb/P73v8eaNWtw7733xh172bJlOP/887FlyxZcccUV3c796aefYv78+bj44ouxZcsWLFu2DHfddRfWrFkT1+7hhx/GhAkT8Pnnn+Ouu+7KwVXIL1QP1XvxxRexZMkSPPnkkzjxxBOxevVqzJkzBzt27EB5eXnCzxQVFWHHjqMKhu7crvU7gP88CbQ3Au4qwOICwj7g0FdAywHgpJ8CZSPV7iVBEHmIEqErUaGlxR9CeaEddosJgbCA3fVeNLQFMWNkGcqLdGjwykOMEsqkNepaA9h6oBUHmtsREkRYTTyqPE6MrSqiZyNLGGPYeqAVLf4QBpW6Yvezy2bGIKsLNY0+bD3QipmFtpzf6+PHj8fdd98NABg+fDgef/xxrF+/HqeffjrKysoAAB6PJy7Ebvny5bjttttw+eWXAwCGDBmCe+65B7fcckvsWABw6aWXYtGiRbH33333Xdy5V65cidNOOy2mDI0YMQLffPMNHnroISxcuDDWbtasWbjpppvk/eJ5jOqK08qVK3H11VfHfvwnn3wSb775Jp555hncdtttCT/DcVzWcZyqIYrAtr9LSlOfkUCoVfrbbJXeN+wAtr8BlA4HaPE3giBkRAlhTUtCC9EzJLyrAxkWcktzexgHmttRXmjvNsZwHIfyQjsONLejuT2MYldu83nGjx8f975fv36oq6vr8TNffvklNm3aFOdhEgQBgUAA7e3tcDqdAIDJkyf3eJxt27bhvPPOi9s2depUrF69GoIgwGQypXQcIh5VFadQKIRPP/0Ut99+e2wbz/OYPXs2Nm/enPRzbW1tqK6uhiiKOO6443DfffdhzJgxCdsGg0EEg8HY+9bWVvm+QCa0fA807ASsDuD7/wDeQ4AQBkwWoLAfUFQJ1H8rtSuuVrevBEEoTq48AEoJa1oSWojkkPCuDmRYyD3BiIiQIMJuMSXcb7eY0OALIhjJfV65xWKJe89xHMRe8tnb2tqwfPly/PCHP+y2r3NqisvlkqWPch3HKKiqODU0NEAQBPTt2zdue9++fbF9+/aEnxk5ciSeeeYZjB8/Hi0tLXj44Ydx8skn4+uvv0b//v27tb///vuxfPnynPQ/I0JtgK8eaNkP+BoAJkheKJ4H2o8AbYcBd3+pHUEQhiJXHgAlhTUtCS1EYkh4Vw8yLOQem5mH1cQjEBbgsnUXcwNhAVYTD5tZ/agei8UCQRDith133HHYsWMHhg0bltWxR48ejU2bNsVt27RpE0aMGBHzNqkFYwyCyMAYwHGAied0M9aoHqqXLlOmTMGUKVNi708++WSMHj0av//973HPPfd0a3/77bdjyZIlsfetra0YMGCAIn1NiMUJNH8PtB4ARAGI3iciAAYgEgAYk9oRBGEYcukBUFJY05PQIid6yhUi4V09yLCQezxOC6o8Tuyu92KQ1RV3jzPGUOcNYGhZITxOSw9HUYZBgwZh/fr1mDp1Kmw2G4qLi7F06VKcc845GDhwIC688ELwPI8vv/wSW7duxa9+9auUj33TTTfh+OOPxz333IOLLroImzdvxuOPP44nnngih9+od8KCCH9IQFgQITKA5wCLiYfDaoLFpP15QdUe9unTByaTCYcPH47bfvjw4ZRzmCwWC4499ljs2rUr4X6bzYaioqK4l6owJuU0RQIAGMDxAPiO/5m03d8otSNyAlUyIrQEYwxH2oL4YGcDalv8qC51wmUzw8Rzkgeg1IUWfwhbD7RmfK+mIqyFBFEWYS0qtNR5A936GxVaqjxOTQgtcqG3CoJK3g9EPJ0NC4nIV8OCknAch7FVRXA7rKhp9MEXjEAQGXzBCGoafXA7rRhbVaQJw8YjjzyCdevWYcCAATj22GMBAHPmzMEbb7yBd999F8cffzxOOukkrFq1CtXV6aVvHHfccXjppZfwwgsvYOzYsVi6dClWrFgRVxhCacKCCG8ggmBEgInnYDXzMPEcghEB3kAEYUH7Y46qHier1YpJkyZh/fr1sZWWRVHE+vXrsXjx4pSOIQgCtmzZgrPOOiuHPZWRxl1AJAiAA8SI9IqDA8JBqV3pEDV6mNfoLRlaT1ZsIn2i9+POulZ88X0zXDYLIiJQXeqA2yFZ+uXwACjpBYoKLQ1tQdQ0+uK8Z3XegKaEFjnQY66QUb2CWkBP3hA9U15kx4yRZbH5vsEXhNXEY2hZYU7n+86lvjdu3Nht/9q1a+Pez507F3Pnzu3Wbs6cOZgzZ07S8yQyos2YMaPb9gsuuAAXXHBB0uPU1NQk3Sc3jDH4QwIEUYTNfNRow3EcbGYTghEB/pAAs13bYXuqh+otWbIEl19+OSZPnowTTjgBq1evhs/ni1XZW7BgAaqqqnD//fcDAFasWIGTTjoJw4YNQ3NzMx566CHs3bsXV111lZpfI3V8DZKyxPNSqB6LxuhxkteJ56X9vga1e5p36E3A0ZuSR6RH5/vRbjahwGpBkd2MQy3taPWHMbaqEGbehLAogucki1ymHgClhbWo0LLlQAt21bWhPSTAaTVhWHkBxlW58+b+1WuukJ6Fd70bk4xmWFCT8iI7ZhbadH2/5BOCyBAWxKTheBYTj7AgQhAZzCbt/kaqK04XXXQR6uvrsXTpUtTW1mLixIl4++23YwUj9u3bB75TWe6mpiZcffXVqK2tRXFxMSZNmoR///vfOOaYY9T6CunhLAbAJOWIdRaCWEehCAbwlo52hFzoTcDRm5JHpEfX+9EXFGC18OA4Dn0L7ag54sP73wZR6LBAEESIIoPNYkKrP4wKd/q/u2rCGov+0/HKs6hYveYK6VV4zxdjklreECPCcZymnj0jw5gk4pqTjCscx0FkTPOZKqorTgCwePHipKF5XV2dq1atwqpVqxToVY6wdeRYsSSW4+h2m8q5WHmGngQcvSl5ekMLFuvo/VhWYIMvKCAkCHBYTWhuD6HAakarPwJvIIKxTgs8TisOtPjB8Tw+/74JHqclI8FKSWGts+JfUeSICeXfNbSh0RfKG8Vfz4n+ehPe882YRN4QwmhwnFQIgjGW8D5njIHnpHZaRhOKk6GwOKQQvZ4QBakdkZR0hV89CTh6UvL0hlYs1sGIiEZfEIdbgmjyhxARRIQjIlr8YewNtgMAHFYOgshQ7wui2GXD2MpCNLWHs1KaywptmDjAjSqPAwBDWaENxS6rrMKakRR/vecK6UV4z9d7irwhhJEw8RwsJh7BiBCX4xQlLEi5TyZe288wKU5Ks/+/yb1NUZgotas6Tpk+6YxMhF89CTh6UvL0hJYs1q3+MPY2tEMEUFZgg9VuQUgQ0RaKoMUfgstsgiDyCEVEVHqcsWIRFpMpY6VZKaXRSIq/nnOFouhBeDfSPUUQ+QrHcXBYTYiIDMGIAItJCk9nTMp9MvFSSXKtGz/UlxKNRsQPadGmnmAd7YiuRIXf3fVeFNkt6O9xoshuwe56LzbuSF7+V08lkqlcrfx0tVjLXe473b5839QOi9kECw/YzTx4noPdYkKl2wG72QSzhceEKjemDuuDcf2LYhX2Mi0TnelzkwlGKnWtp7LHeiaf7ilaDoMwMhYTj0K7GTazCYLIEIpIxSBsZhMK7WZdrONEHielMaVi2WUptjMW2YRr6CkZOh+s2FpDSxbr5vYwDjb7Ma6qELvr2nHYG4DHYYXFzEsrqXNSEu3gMhcK7fG/cSZKs9JhTlr27uYiv01vuUJ6RMv3VDpoJVSYINTEYuJhtkuh6IxJOU0mXtslyDtDipPSeAZCcvT1ZBnjO9oRnclW+NWLgKMnJU8vaCn8MdqX/h4nnFYz9jb60egLIhIMw8RxGFjshDcQ6dbXTJVmpZVGrSr+uRRa9ZIrpFe0ek+lg5ZChQlCbTiO03TJ8Z4gxUlpeBNgtgKRHkJjzFapHRGHHMKvXgQcvSh5ekFLFuvOfXE7rBjX3wJfUIitb9HqD+Hzfc041BKAzWzKWmlWWmnUouKvhNCqh1whvaLFeyod8rW4RVe0ULGUIHINKU5KY3VKYXiiCIih7vt5i7Tf6lS+bxpHLuFXLwKOXpQ8PaAli3WivhR03M+MMdR7RZw6ogxFdgsOtvizVprVUBq1pPgbRWjNd3J1Tykh7GspVDhXaDEMkTGm23CwbNi4cSNmzpyJpqYmeDwetbvTjTVr1uCGG25Ac3Oz2l3JCFKclMbmBmwFQLA58X4xDNgLpXZEHFoSfpVCL0qe1tGSxTqVvkwd1gdlMinNaj03WlH8jSC0GgW57ymlhH0thQqnQrrKpBwe3c7n5IQERuU0CQsi/CHJky8yaf0gi0mq2pbLAgT19fVYunQp3nzzTRw+fBjFxcWYMGECli5diqlTp2Z0zK+++go///nP8cknn6CsrAz/8z//g1tuuUXmnhOpQoqT0tgKgZCv5zbBNqkdEYeWhF9Cf2jJC5JqX+QQ5NV8brSg+OtNaCV6Rq57SsmcIy2FCvdGusqkHB7drucsMDGMcElKTya/QFgQ4Q1EIIgiLDxgaTsABL0Im5yIeAai0GHNmfJ0wQUXIBQK4bnnnsOQIUNw+PBhrF+/Ho2NjRkdr7W1FWeccQZmz56NJ598Elu2bMEVV1wBj8eDa665Rube64dQKASrVZ25Rf2n1GhEAkCguec2geaec6AMTFTgHFpWiNZAGPub29EaCGNoWSFmjKDkWqJnyovsmDmqDOeMr8TZ4ypxzvhKzByV+L7JddngdPoix7mM+txQeX+iK0ovT6CX5TAyWbYgHY9uqucssJkRFkT4ghGEhfQMGowx+EMCBFGEo3k37B89BvsHD8Dx70dQuPkhWP+zGsGD23JSBr65uRkffPABfv3rX2PmzJmorq7GCSecgNtvvx3nnntuRsf805/+hFAohGeeeQZjxozBxRdfjOuuuw4rV67s9bObNm3C+PHjYbfbcdJJJ2Hr1q1x+1955RWMGTMGNpsNgwYNwiOPPBK3n+M4rF27Nm6bx+PBmjVrAAA1NTXgOA5/+9vfMHPmTDidTkyYMAGbN2+O+8yaNWswcOBAOJ1OnH/++d2UyN27d+O8885D3759UVBQgOOPPx7vvfdeXJtBgwbhnnvuwYIFC1BUVIRrrrkGs2bNwuLFi+Pa1dfXw2q1Yv369b1en0yhmUJpvnwBQG8PLOtoRyRCSYGTyD+iFusKtx3FLmtCK2hdawAbttfjja8O4s0tB/HGVwexYbu86x2l2he5MOpzk0hoZWBoC0ZwxBfE3kYfKj0O1YVWQjmyFfbTRQ/rfWWqTGazxlayczqsJphNPMQOJSgdJUcQpcVUbc27YPn0f8Ef/grMUQKxZBiYowTWuq0w/ff3EA5vT+8CpUBBQQEKCgqwdu1aBIPBpO1+8IMfxNomeo0ZMybWdvPmzTj11FPjvCtz5szBjh070NTU1GN/fvGLX+CRRx6JhfjNnTsX4bB0T3/66aeYP38+Lr74YmzZsgXLli3DXXfdFVOK0uHOO+/EzTffjC+++AIjRozAJZdcgkgkAgD46KOPcOWVV2Lx4sX44osvMHPmTPzqV7+K+3xbWxvOOussrF+/Hp9//jnOPPNMzJ07F/v27Ytr9/DDD2PChAn4/PPPcdddd+Gqq67Cn//857hr/fzzz6OqqgqzZs1K+3ukCoXqKc2RGnnbqYAWKudoIQSIyE/yuWywEZ+brqGKdguP2uYg9jW3o8kXQpHdgiqPA/XeoG5/VyI91Ajf1FKocCIyzQXsGobIwOKqhAIsqUe3x3MCMPMcwoK0QGqqpasZA0RRhGXnW+D8jWClI6XKEABgK4TYZyS4+u3gdrwFlI8EePn8B2azGWvWrMHVV1+NJ598EscddxymT5+Oiy++GOPHj4+1e/rpp+H3+5Mex2I5asSpra3F4MGD4/b37ds3tq+4uDjpce6++26cfvrpAIDnnnsO/fv3x6uvvor58+dj5cqVOO2003DXXXcBAEaMGIFvvvkGDz30EBYuXJjW97755ptx9tlnAwCWL1+OMWPGYNeuXRg1ahQeffRRnHnmmbGcrBEjRuDf//433n777djnJ0yYgAkTJsTe33PPPXj11Vfx+uuvx3mUZs2ahZtuuin2vqqqCosXL8Zrr72G+fPnA5C8WwsXLsypTEqKk9LwKf6YqbZTGC1WziEIuaAKbPlJVGjdtKsB735di4MtAfAc4LKawXMcPq45gqb2MM6dWEnjmAFQK+dIKwVTEpGpMtm5+EyxYMG+IwFpXTpRhInjEBGBKUNKEnp0ezsnx3EQmaQMpQrHAWbvfpgad4IVVh1Vmo62ACusBNewA2j5HiiuTv3gKXDBBRfg7LPPxgcffID//Oc/+Mc//oEHH3wQTz/9dEwhqaqqkvWcyZgyZUrs75KSEowcORLbtm0DAGzbtg3nnXdeXPupU6di9erVEAQBJlPqS+J0Vgr79esHAKirq8OoUaOwbds2nH/++d361Vlxamtrw7Jly/Dmm2/i0KFDiEQi8Pv93TxOkydPjntvt9tx2WWX4ZlnnsH8+fPx2WefYevWrXj99ddT7nsmUKie0phs8rZTkEzinwlCTygdwkMoR1mhDaLIEBEZ+hc7MLbKjfFVblS47RAZwxffN+HDnQ05yX1IRK5z6IjkqJlzpGR4bjpkmgsY9ejyHIcNOxqwt7ENdjMPl9UMX0hAezCMxrYQ6r3dQ9d6OydjDDyXQPfpARPPwSK0Qwz7AUv3ZV0ExsDbXOCEIBBqS/3AaWC323H66afjrrvuwr///W8sXLgQd999d2x/OqF6FRUVOHz4cNzxo+8rKipy0v8oHMd1ez6ioX6d6ewhi97Popi6t/bmm2/Gq6++ivvuuw8ffPABvvjiC4wbNw6hUHx1RZfL1e2zV111FdatW4f9+/fj2WefxaxZs1BdLa8y3BXyOCmNpfsPn1U7hSBLPGEEqAJb/tLkC+Hz75vhtJnR3+OIjVN2E2Az27G/2Y/P9jVhxsgylBTk1nBFnnt1oQqt3clm2YKyQhuKnVYU2Eww8TzaghGYTTwGljgxsNiJ5o78qK7yQY/nBBARGewmHqY0InA4joPN5YZodkAI+sDbi6S4P9ahNHEczJEAOLMdsBZkdK3S5ZhjjokrspBOqN6UKVNw5513IhwOx7avW7cOI0eO7DFMDwD+85//YODAgQCApqYmfPvttxg9ejQAYPTo0di0aVNc+02bNmHEiBExb1NZWRkOHToU279z5060t7en8I2PMnr0aHz00Ufd+tX1vAsXLox5ptra2lBTU5PS8ceNG4fJkyfjqaeewp///Gc8/vjjafUvE0hxUprqKcCnT6fWTkPQWiiEEdBT2WAiPeq9ITT6gujndiQcw0pdVhxq8aPeG8qp4pTPOXR6Qus5R0qTjTLZ3B6GLxTBlCGlADiERREWnofLZgLHcbCa+YTyQbJzBkMCCjgRPCcVikhXgbUUD4TQdyS4g18gYi0A47hYzpSZ52BqOghUTgDcA7K8avE0NjbiRz/6Ea644gqMHz8ehYWF+O9//4sHH3wwLiwunVC9Sy+9FMuXL8eVV16JW2+9FVu3bsWjjz6KVatW9frZFStWoLS0FH379sWdd96JPn36YN68eQCAm266CccffzzuueceXHTRRdi8eTMef/xxPPHEE7HPz5o1C48//jimTJkCQRBw6623xil1qXDddddh6tSpePjhh3HeeefhnXfeiQvTA4Dhw4fjb3/7G+bOnQuO43DXXXel5bG66qqrsHjxYrhcrm5hgbmAZn+lGXUWwPWir3JmqZ2GyKZyDkHoBb2UDSYygQFMMj4nguto0nvV0yx6oHAZbKJnjFppMhmZLlsQlQ8cVjMK7GbJ+2Q3H/Xq9iAfJDpnWzACi4mHy2bObL0lnofpmLmwFPSBvWUn7IIPdhODNdIGU8MOwFUKjDpH1sIQgFRV78QTT8SqVatw6qmnYuzYsbjrrrtw9dVXZ+wJcbvdePfdd7Fnzx5MmjQJN910E5YuXZrSGk4PPPAArr/+ekyaNAm1tbX4+9//HqvOd9xxx+Gll17CCy+8gLFjx2Lp0qVYsWJFXGGIRx55BAMGDMC0adNw6aWX4uabb4bT2T38sSdOOukkPPXUU3j00UcxYcIEvPvuu/jlL38Z12blypUoLi7GySefjLlz52LOnDk47rjjUj7HJZdcArPZjEsuuQR2e+6fXY4ZbIRubW2F2+1GS0sLioqKlO9AzYfAH88HeloZ22QFLnsVGHSKcv3qhSZfCG98dRBFdktCS7wvGEFrIIxzxleSx4nQNck8AlGra76ve5SvHGkLYuW6b+ENhDGg2BmfOMEYvm9qR6HdgiWnj8iZx4nGUUIPpFs5V477uvM5OSGEI4cPYPDgwdkJwvU7gG1/Bxp2Smtjmu1A2QhJaSobmflxCU1RU1ODoUOH4pNPPulR4QoEAtizZ0/C+yod3YBC9ZSmbhsgipCcfYm8M5y0v26bphSnbOKfCUJPUAhPflLssmJSdTHe21aH2lY/ip02WMw8whERTe1BRERgUnVxThUWyqEjlCKbZUPSXbZADvmg8zkDAeBIymfvgbKRQOlwqXpeqE3KaXIPkN3TRKhDOBxGY2MjfvnLX+Kkk05Ky0uVDaQ4KU3YDzAB4HgApvg6m9HBhglSOw1BybTqooW1s4yElssGE5nBcRymDuuDI74QdhxuQ5M/DI5jYIwDz5tw3MACTB3WJ63fuKfnMtE+yqEjlEDp4iOalg94XvaS44Q22LRpE2bOnIkRI0bg5ZdfVuy8pDgpTekwSWliIsCZgM618kXxqFJVOky9PiaBLPHqQBW41MGIi8XmO+VFdsydUIlBB1qwq64N7SEBTqsJw8oLMK7Kndbz1NNzCSDhvjGVheS5J3KKWsVHSD6QH8YYBJGBMcmubuI5Mt51YsaMGarkg5LipDT2IsBsO+p5EkXEamVGbwCzTWqnQcgSryxUgYsg5KW8yI5ZhTYcN7A44zGsp+fyu/o2cBwgMpbwmdWsZZ7QPWovG0LygXyEBRH+kICwIEJkAM8BFhMPh9WUWcEMQjZIcVIamxsoqABa9gNiqPuS2LwVKKyQ2mmAZKEoZInPPWpPggSRr2QzhvX0XFZbnFi/vQ4MHGaPLgPP8bF90We2tiWI6SP64OuDXrLME7KihWVDSD7InrAgwhuIQBBFWEw8zB0L0QYjAiIiQ6E9w2qDhCyQ4qQ09iLAUQw070PCwrhMBOzFmvA4UYiYumhhEiQIIp6ensv2kAhRZGCc9HeB7ahw0/mZPXagBzNHlZFlnpAVKj6ifxhj8IcECKIIm/no78hxHGxmE4IRAf6QALOdwvbUghQnpSnsB/iPSAGrzASpsh6DpETx0vZAk9RORShETH1oEiQI7dHTcxnuCL3mOIaw0P257PzMkmWekBsqPqJ/BFEaO5J5lCwmHmFBhCAymE2kOKkBPT1Kc+C/QLBN+puLKk2Q/uc6JtqAV2qnErRIozboPAkmgiZBglCenp5LC88DkCr1JRJ86Jklcgkt4K1/GANEhqTeJI7jILLuWR6EctDorTTeOiDsk+56xiApTh2v6LawT2qnEumEiBG5Q2+TIGMMTb4QalsCaPKFIIpi3HtStIl8oKfn0mnlwfMceI6D0xo/vWrxmSXyi2hZcLfDippGH3zBCASRwReMoKbRR8VHdADHSYUgks2XjDHwXPz63YSyUKie0jABiISk/9H1wWBd9qsDhYhpA02vjdGFrvlwwbCIYESAzczDZjFRfhyRN/T2XA7vWwgOwN7Gdk0/s0R+QmXB9Y2Jl7zV0vyZIBxYkHKfTHzyMWTjxo2YOXMmmpqa4PF4ctjbzFizZg1uuOEGNDc3q92VjCDFSWksDqkARDelKQqT9lscSvYqDoqTzhy5F6rVwyTYNR8uGBGw63Az6rxBlBfacOyAYtgsPOXHEXlDb88lAE0/s0R+Q2XBjyIyEYd8h+AL++CyuNDP1S9W7VKLcBwHh9WEiChV0bOYeHy9dQtuvvF6fP7pf1HapwyLFy/G7bfdqnZXDQspTkrjP4LkSlMU1tFOHaKhKLRIY3rkqgqhlifBrvlw4IDd9T5ERBGj+hagzhfC983tGF/lxqBSKqFO5A+9PZdafWYJY0DFR4Dvmr/D+n3rsadlD4JCEDaTDYPdg3HawNMwxDNE7e4lxWLiUWg3wx8ScKSpGefPPRvTZ87E6scex84d3+Caq65CaUkxrrnmGrW7qhqhUAhWqzr3t3bV7nxFSBSi1xXW0S73dM1LYYxRnHQGRL0uu+u9KLJb0N/jRJHdgt31XmzcUY+61kBWx49OghVuO4pdVs1c+675cL6ggEZfEB6HFRzPw2234IgvBF9QoPw4Iu/o6bnU6jNL5I5E8ymhDt81f4c/bfsTth3ZBo/Ng0FFg+CxebDtyDb8aduf8F3zdzk5b0NDAy666CIUFxeD47i415o1a1I+TlR5euPVlxAJh/Dcs8/ihOMm4CeXXorrrrsOK1eu7PUYmzZtwvjx42G323HSSSdh69atcftfeeUVjBkzBjabDYMGDcIjjzwSt5/jOKxduzZum8fjiX2PmpoacByHv/3tb5g5cyacTicmTJiAzZs3x31mzZo1GDhwIJxOJ84//3w0NjbG7d+9ezfOO+889O3bFwUFBTj++OPx3nvvxbUZNGgQ7rnnHixYsABFRUW45pprMGvWLCxevDiuXX19PaxWK9avX9/r9ckUUpyUxt/Ye5t02mVBXWsAG7bX442vDuLNLQfxxlcHsWG7JORHQ1GGlhWiNRDG/uZ2tAbCGFpWiBkjKNSqM0auQtg1Hy4siIiIIiwdYZxWE4+IIHaUaZby40KCSPlxBEHkFT3Np4SyiEzE+n3r0RRswlD3UBRYC2DiTSiwFmCoeyiagk1Yv289RCb/PHT99ddj8+bNePHFF/HNN9/gqquuAgD85je/wamnngoA+MEPfoCCgoKkrzFjxgCQFJePP/oIp556KpyOo8W65syZgx07dqCpqanHvvziF7/AI488gk8++QRlZWWYO3cuwmHJaPnpp59i/vz5uPjii7FlyxYsW7YMd911V1rKXZQ777wTN998M7744guMGDECl1xyCSKRCADgo48+wpVXXonFixfjiy++wMyZM/GrX/0q7vNtbW0466yzsH79enz++ec488wzMXfuXOzbty+u3cMPP4wJEybg888/x1133YWrrroKf/7znxEMBmNtnn/+eVRVVWHWrFlpf49UoVA9pREi8rbLkFTXaaJwk94x8kK1XfPhLCYeZp5HOCLC1qEkmU18R5lmyo8jCCL/oHUPtcUh3yHsadmDCmdFwjm5wlmBPS17cMh3CFUFVbKdt6WlBX/5y1/wl7/8BWeccQYA4He/+x3+8Y9/IBwOY8gQKTzw6aefht/vT3oci+VoGkRtbS0GDx4ct79v376xfcXFxUmPc/fdd+P0008HADz33HPo378/Xn31VcyfPx8rV67EaaedhrvuugsAMGLECHzzzTd46KGHsHDhwrS+980334yzzz4bALB8+XKMGTMGu3btwqhRo/Doo4/izDPPxC233BI7z7///W+8/fbbsc9PmDABEyZMiL2/55578Oqrr+L111+P8yjNmjULN910U+x9VVUVFi9ejNdeew3z588HIHm3Fi5cmFM5laQXpSmqhLTYbU9wHe1yQzoeEgo36Z1UqhDmq5ela2lml82EUpcNzf4QmCiiJRBGicsKl81E5ZgNAoUrEUbCyBEHWsUX9iEoBOEwJy6y5TA7EBSC8IV9sp73u+++A2MMJ598cmyb2WzGCSecgK+++iq2raqqCsOGDUv6qq6ulqU/U6ZMif1dUlKCkSNHYtu2bQCAbdu2YerUqXHtp06dip07d0JIM1Vk/Pjxsb/79esHAKirq4ud58QTT0zaL0DyON18880YPXo0PB4PCgoKsG3btm4ep8mTJ8e9t9vtuOyyy/DMM88AAD777DNs3bo1bcUvXcjjpDTF1ZD01Z5uTL6jXW4wsockFxi5CmGi0sz9i+2o9waw/XAb+hbaMMDjRHtIm+WY5a6CaHRyVSCFILQKzafaw2VxwWaywR/xo8Ba0G2/P+KHzWSDy+KS9bxRT1FXxUMQBJhMRw2rP/jBD/DBBx8kPU51dTW+/vprAEBFRQUOHz4ctz/6vqKiQpZ+J4PjuG4KfzTUrzOdPWTRZ0AUUzcU33zzzVi3bh0efvhhDBs2DA6HAxdeeCFCoVBcO5er++911VVXYeLEidi/fz+effZZzJo1SzbFMxmkOCmNxSk5nHoyPnEd7XIErdMkL0avQti1NHNIEDGgxInyIhtsZh7eUBhBQXvlmEnIlxcKVyKMCM2n2qOfqx8Guwdj25FtGGoZ2m1Orm2vxeiS0ejn6ifreYcOHQq73Y5NmzZh0KBBAKTqb//973+xZMmSWLt0QvWmTJmCO++8E+FwOLZ93bp1GDlyZI9hegDwn//8BwMHDgQANDU14dtvv8Xo0aMBAKNHj8amTZvi2m/atAkjRoyIKXllZWU4dOhQbP/OnTvR3t7e22WIY/To0fjoo4+69avreRcuXIjzzz8fgOSBqqmpSen448aNw+TJk/HUU0/hz3/+Mx5//PG0+pcJpDgpzYFPe1/clglSu/6TctIFI3tIcoGeFqrNFYny4dwOM1r8EU16c0jIl5eu4UrR39llM2OQlcrQE/KhNS8xzafag+d4nDbwNNT6arG7ZTcqnBVwmB3wR/yoba9Fsa0Ypw08Tfb1nBwOBxYvXoxbbrkFpaWlGDhwIB588EEEAgFceeWVsXZVVannVV166aVYvnw5rrzyStx6663YunUrHn30UaxatarXz65YsQKlpaXo27cv7rzzTvTp0wfz5s0DANx00004/vjjcc899+Ciiy7C5s2b8fjjj+OJJ56IfX7WrFl4/PHHMWXKFAiCgFtvvTVOqUuF6667DlOnTsXDDz+M8847D++8805cfhMADB8+HH/7298wd+5ccByHu+66Ky2P1VVXXYXFixfD5XLFlK9cQk+y0oS88rbLgK55KZ1RMg8ln3IhqAph9/LLPM9rMj+OchLkJ51wJYIAMhv/tVi5TivzKRHPEM8Q/Hj0jzG6ZDSag82oaa1Bc7AZo0tG48ejf5yzdZzuvfdezJ8/HwsWLMBxxx2HXbt24Z133oHH48noeG63G++++y727NmDSZMm4aabbsLSpUtTWsPpgQcewPXXX49JkyahtrYWf//732NrHx133HF46aWX8MILL2Ds2LFYunQpVqxYEZcf9Mgjj2DAgAGYNm0aLr30Utx8881wOtOLhjrppJPw1FNP4dFHH8WECRPw7rvv4pe//GVcm5UrV6K4uBgnn3wy5s6dizlz5uC4445L+RyXXHIJzGYzLrnkEtjtuZe1OGYw6aC1tRVutxstLS0oKipSvgP/uA346He9tzvxZ8APHshZN5JZ3KMeklwL+/kaJqU1a2gi9NDHXNLkC+GNrw6iyG5JaCH2BSNoDYRxzvhKyklIkdqWAN7cchD9PU6Y+O73kiAy7G9ux9njKlHh1u/zTchDJuN/j3OWw6qql1jt+TTfCAQC2LNnDwYPHpy1ICwyEYd8h+AL++CyuNDP1U92TxOhLjU1NRg6dCg++eSTHhWunu6rdHQDCtVTmsIUk/lSbZchXfNSGnxBWE3K5KHkc5iU1ldrz1eFNR0oJ0F+KFyJSJVMxn+th4KqOZ8SPcNzvKwlxwntEA6H0djYiF/+8pc46aST0vJSZQMpTkqTpDxmxu2yQI11mrQ+AeYz+aywpgMJ+fJj9AIpRGpkOv7roXIdrXtIEMqyadMmzJw5EyNGjMDLL7+s2HlJcVIadxVSKqvnVsZCorSHRA8TYD5CCutRSMiXHyqQQqRCpuO/XrzEWo84IIh8YsaMGarkIpNJVWkCLQBnQvJFcDlpf6BFyV4phpEXi1UTSt4/SlTIdzusqGn0wReMQBAZfMEIahp9JORnCBVIIXoj0/G/s5c4EeQlJghCKcjjpDSuMsDqBCIBQAgj3vPEAbwFsNildnkIhUmpg14stkpBOQm5gcKViJ7IdPwnL7ExMVjtMiLHyHU/keKkNH2GA/ZiwHsA3cP1GABR2t9nuAqdyz00AaoDKazdISE/N1C4EpGMTMd/CgU1FtG1gtrb2+Fw5D7fmzAGoVAIAGIL/GYKKU5K4x4A2IuA1v0dG3hIChMHQAQYAxxuqV0eQhOgOpDCmhijCvlGL0lPqEM24z95iY2DyWSCx+NBXV0dAMDpdNL4RGSFKIqor6+H0+mE2Zyd6kOKk9K07AciQYAzA0wEEA2N6lCeODMQDkjtSgap10+Z6SqoTR/RB18f9NIEqBCksBJRqCQ9oSbZKEDkJTYOFRXSkixR5YkgsoXneQwcODDr8YIUJ6Vp3Am0NwJMQMJQPSYA7UekdnmiOCUT1MZUFuLYgR6aABWCLLYElaQntEA2CpBRvcRGg+M49OvXD+Xl5QiH879oEZF7rFYreD77dARSnJSGCUCwFWARHK2sx47+zSJAsKVDsdI/qQhqFW4S1JSCLLbGhUrSE2qQLCyUFCAiFUwmU9Y5KQQhJ6Q4KU3AC4iRjjcMUo5TVEjpCNsTI1I7nUOCmjYhgcWY0BpqhNJQWChBaA/Kcc0OUpyUxt+EoyF6XRfCjb5nHe30DQlqhNHR0gRFJekJJaGwUILQHmTMyB5SnJQmEsDRSnqJ4KRXJKBcn3IECWqEkdHaBEUl6QmloGgDgtAeZMyQB5ohlabPCMBkATgegAlHw/Q4gDNJ200WqZ3OodXe8wfGGJp8IdS2BNDkC9HChL0QnaB213tRZLegv8eJIrsFu+u92LijHnWtyhtGoiXp67yBbr9ftCR9lcdpuJL0hPykE21AEETu6WrMcNnMMPGcZMwodaHFH8LWA600t6cAeZyUpmwkUFDRsY5TpNMOJpUn50zS/rKRavVQNmjtoPxAa54TraNVazuVpCeUgqINCEJbUOqEfJCpX2k81UDfY6SFbhPBmLTfU61sv3JAVFBzO6yoafTBF4xAEBl8wQhqGn0kqKWBWh4fLXpOtI6Wre3RkvRDywrRGghjf3M7WgNhDC0rxIwRFKZByANFGxCEtkjFmBESRDJmpAB5nJSGiUDLge51IaJwkPYzEfmg19LaQdmjlsdHq54TraN1azuVpCdyDUUbEIS2oBxX+SDFSWm+/who3gfwFkAII1aCHADAS9tb9kntBk1Vq5eyQoJa5qiZzEmu/czQwwRFJemJXEJhoQShLciYIR+kWipN3TYg7OtYyym6jlP0xaTtIZ/ULo+ICmoVbjuKXVaaMFNA7WROvbj2tVa4goowEASFhRKElqDUCfkgj5PSmKyAKOBonF4XIY+JUp6TiazBRkdtj48ePCdaLFxB1naCkKBoA4LQDpQ6IQ+kOCmN1YnYIre9tiO0hNKLmaqdK6N1176W16SgCYowOl3Hy75FlAtJEGpDxozsIcVJaTiT9GKR3tsQmkENz4baHh8te070ULhCyxOU0kYAwlho0RNMEIQE5bhmBylOBNELank2tODx0arnJJMwRjWUBS1NUNHvf6DZj+/q29DSHkZIJKGWkBcte4IJgiCyhRQnpSmq6tnbBEj7i6qU6Q/RIz15NqotTmyr9eKDbxswc1SZ7EUvtOLx0aLnJN0wRqNbwKPff3ttC7455EVEEDGwxIVh5S7YzCYSaglZ0IMnmCAIIhtIcVKaXe+l3m7gCbntC9EryTwbze0h7D3SjtpmP7YfakWDL4jh5fJ7YbTi8dGS5wRIL4zR6Bbw6Pdvbg+iuT0Mu5mHp9CGpvYgvjkoYlz/IgwqJaGWyB61C9oQ8kIhvQTRHVKclKbtkLztiJySyLPR3C6VAfeFIyh0WAAesFv4nAniWvT4qE2qYYxuhxkbdzQY1gLe2QNQVmjH3iN+eJxW2C0m2C0mHPYGsLfRj3H9LSTUElmjdkEbQj6M7qXPV0gZzh5SnJTGUSpvOyKndPVsMMaw90g7fOEIygtsCEVEWE0muB1WuKymnAniWvP4qE2qYYwt/oihLeCdPQAhQUREEGG1d+TEcRw8DisafUH4ggIcJNQSWaJ2QRtCHozupc9XSBmWBxq9lGbIDHnbETml62KmvqCAI74Q3HYLOADN/hBKXTa4bKZugjiRW1JZYFMvi/jmis7f38LzMJt4hISj39Vi5hERRYQFkYRaImto8Wf9o/bC60RuiCrDu+u9KLJb0N/jRJHdgt31XmzcUY+61oDaXdQN5HFSGkcJYHYAEX/yNmaH1I5Qna6eDauJRygswm7mcdgbgMtmQXWpAxwkbwaFoihLb2GMRreAx39/E0pcVtS2BmAz8+A4DuGICDPPw8xzqq/LRegfrRS0ITKH8tT0RSqhd1S0RV5IcVKacBtgLQAiQQCJhGte2h9uU7pnRBI6F2jYWdeKtlAYjAMq3U5UlzrgdhydPPJdEAe0FyPdUxijFkq6q0nc9y91obrECa8/grq2INw2M5r8IZS67KhvC8JDQi0hA1opaENkBuWp6YdUQ+9IGZYXUpyUxuKS/jeZASEMoLO7m5O2c9zRdoTqMMZgMfEY3a8Qg0odKHXZcLDZj1H9CsFzfFy7fBfE9RYjbXQLeKLvf0y/Iuyq92LvkXZYTJLiO4yEWkJGqKCNfjG6l14vpJOHRsqwvJDipDRhHyBGACECSWniOl5MegkRSaEK+1TtJiGRSFEosJnhtJqxt7HdUIK4XhOGjW4B7/r9Q4KI/sUOjK30YEi5M5Zzko/3LKEeVNBGnxjdS68H0g29I2VYXkhxUhqLAxCCkBQlHlK4XtTrxEt/C0GpHaFqWFgyRaHOGwDPcShx2tAaCBtCENd7jLTRLeBG//5aQWthrgTRFaN76fVAuqF3pAzLCylOSnOkRvI4cRzAGAATjnqcRGm7GJHaVR6rZk9VR82wsFQUBbfTghkjyxASWN4LQfkQI62mBVwLAjN5ANRFb2Gu+YoWnkWtY3QvvdZJN/SOlGF50YTi9Nvf/hYPPfQQamtrMWHCBPzmN7/BCSec0OvnXnjhBVxyySU477zzsHbt2tx3VA4Y63Aw8QDf4XFikBQmWADW8d7gpT7VDgtLRVE42OzHcQOLUeG25awfWoFipDOHBGZC7fGMkKBnMXXIS61dMgm9S0UZJqNCaqiuOL344otYsmQJnnzySZx44olYvXo15syZgx07dqC8vDzp52pqanDzzTdj2rRpCvZWBjgO4E2AyHX8bUbM4ySK0t8836FIGRMthIWRohAPxUhnBgnMhBbGM4KexUwgL7U2yTT0ridlmIwKqaO6lLNy5UpcffXVWLRoEY455hg8+eSTcDqdeOaZZ5J+RhAE/PjHP8by5csxZMgQBXsrAyVDpXLjPA+YOjxMYkT632SVttsKpHYGJZ2wsFzRWVFIhNEUBaUWtmSMockXQm1LAE2+kK4XWaSFJAlAG+NZZ/LpGUsVehaJfCIaeud2WFHT6IMvGIEgMviCkY40guShd1FluMJtR7HLGlOaaHHc1FHV4xQKhfDpp5/i9ttvj23jeR6zZ8/G5s2bk35uxYoVKC8vx5VXXokPPvigx3MEg0EEg8HY+9bW1uw7ng0ON1A+Cjj0JRDudDMyBogBwGIHykZJ7QyKFrw9lEwZjxIx0vlm8cqHvDAie7QwnkXJt2csVehZNC75Gn4mVx4aecTTR1XFqaGhAYIgoG/fvnHb+/bti+3btyf8zIcffoj/+7//wxdffJHSOe6//34sX748267Kh3sA0HcsUL8DiIQkT1O0LDlnAsx2oO84qV0W6Hmw0EJYGCVTdieXCcP5GEajJYGZUI90xrNcjtv5+IylCj2LxiTfDQVy5KGlZFRoakdNgw8Oq1l38mQuUD3HKR28Xi8uu+wyPPXUU+jTp09Kn7n99tuxZMmS2PvW1lYMGJCdUpI9DLA4AbunI72JdVTZAyCEAC67cAG9DxZa8fZQZaHu5CJhOF8tXlowABDqk+p4FooI2LC9OSfjdr4+Y6lCz6LxMIqhINs8tN6MCsGIgK8PtaI1EIbdatKdPJkLVFWc+vTpA5PJhMOHD8dtP3z4MCoqKrq13717N2pqajB37tzYNlGULERmsxk7duzA0KHxuUE2mw02m4aqnrV8D/ibgeqTgJaDQHujlOPEmwFnH6CoH9DeJLUrrk778PkwWGjJ20OVhbojd8JwvobRaMUAQKhLKuNZhduG979tyNm4na/PWKrQs2gslDAU6DmqpzM9GRVa/CF8vq8ZTe0hjK9yo7TApjt5MheoqjhZrVZMmjQJ69evx7x58wBIitD69euxePHibu1HjRqFLVu2xG375S9/Ca/Xi0cffVQDnqQUCLUBkQBQOhwoHAA07gCCXsBWCJSOlLxNjbukdmmST1ZFLXl7qLJQbsnXMBotGQAIdelpPBtTWYivD3rjxm0GBgbA7bCgtsWPLQdaMCuLcTtfn7FUoWdRIl+E/d7ItaFA71E9nUlmVGBgqGloR503iGP6FaGsY/zRozwpN6qH6i1ZsgSXX345Jk+ejBNOOAGrV6+Gz+fDokWLAAALFixAVVUV7r//ftjtdowdOzbu8x6PBwC6bdcs1gIpj6luK1D7DeA/AoiCVKL84JdA32MAu1tqlyb5ZlUkb48xyOcwGi0ZAAh1STaedR23W/wh7G30o9EXREQUIYhAnTeIAcVOjKgozOjc+fyMpYrRn8V8EvZ7I5eGgnyI6ulMMqNCoy+InXVe9C20obrUGSd36VGelBPVFaeLLroI9fX1WLp0KWprazFx4kS8/fbbsYIR+/btA8/n0WDuHgCAAd+9L4XooeNmFASg7RDQXg8cc25GxSHy0apI3p78hjEGxhicVjP2Nvowql8heI6P259KGI2WLaldBWarSepXSJDKQmupr0RuSTSedR63W/whbNnfCl8oDI/DCovZgmBYwN4j7Xj/23p4nJaMhDIKVZMwqjEu34T93siVoSCfono6k8ioEAiL8DgtmDigGB5ndxlMj/KkXKiuOAHA4sWLE4bmAcDGjRt7/OyaNWvk71AuYSJweBsQCSK22G1HUT2IIiAGJU8UE5HuMltkVST0RGcLaKMviL0N7djfHMC4qkKUFzpSDqPRgyU1KjDXtQbwxfctmu4roSzRcdsfjmBvox++UBh9C+2xRdCj1t32UCRjoYxC1Y5iNGNcvgr7PZErQ0G+RfV0pqtRwR+K4IOd9bBZEsuLRpYnjfeN1eb7/wDN+6TS4ywiVdETQ9L/LCJtb94ntUsTpRYp1QJGXMQxn+i64N7oCjeOHVgMDgyf7W3G9lqpis/QskLMGJHcGqqnhfv01FdCOaLj9r7GdjS0BeBxWGNKE2MMLYEwSgusqC5xZrVQbtSqPLSsEK2BMPY3t6f0jBH6JtsFmPU412azQGxPpBLVExJE3XphOi+OO6iPC/2LXYaQJ9NFEx4nQ1G3Awi3dYTpAbFQPQAAk5SosCi1G3RKWoc2ilVRDx4GIjnJLKCVHgcqimzYVutFf48TM0eVxVY2T+c4WrSk6qmvhLJEx+3d9W2o8wYxsMQEUWQICSJaAmG4LGZUlzjhsJrR2B7KSigzaqiakckmhF/Pc20uctqMFNVjFHkyE0hxUhre3Elp4rvoTRwA8Wh58gzI9wRYo8Vq5yM9WUB5nsegUhdaA2FwHNfjoKynsAk99ZVQnvIiO6aPKMPeRh+8/jB8fARmE4+KIjuqS5zwOK3wBSMZ52V0VZToHjMOmQr7+TDXym0oMFquYL7Lk5lCipPShNs7vRGl/KZe26VHvloVyWqfH/RmAbWZeTT7Q/i+SXoGkt27eiqGoqe+EuowvG8BZo4sx9aDLejntsNqMsFlM0nlyTMUyvTsMdA6Wi5I05lMhP18mmvlzGkzohcmX+XJbCDFSWlilfR6ihPmOnmlMiMfE2DJap8f9GQBbW4P4dvDXhxsCQCMi036iQQ9PYVN6KmvhDpwHIdx/d1o9IU6rPwmiAwIhCIZCWX54DHQKnpSSDMR9mmuTY4RvTD5KE9mAylOSuPu3xGu10OCL2+W2hFxkNU+P0hmAW1uD2HLgRbsb/JjaFkBhvctQDAsJhX09BQ2oae+qoFerPe5Ri6hLJ88BlpDTYU00+ck3fuK5tqeIS+MsSHFSWlGzAG4XqzKvElqR8RBVvv8IJEF1Gbm8e1hL/Y3+dG/2IGRFQUw8zzMNj6poKensAk99VVp9GS9VwI5hDLyGOQGNRXSbJ+TdO4rmmt7h7wwxoUUJ6U59AVgtgNCsNPGLqF7JpvUrvpkZfuWJkpbiclqnz90tYA2+0M42BLA0LICjKwogNtxdELqSdDTU9iEnvqqFHJa7/PJa5WtUBYIC2j2h2Ax8WAMsVypKEb3GGSKWgqpXM9JqveVWnNtPj3DRP5CipPSeOukxW1NDqn0OBMQU5o4E8Bbpf3eOlW72RtqWInJaq8/epoIO1tAv29qBxiH4X0lT1NXehL09BQ2oae+5ho5rfda8FppReiraw3gk5oj2FHbhu94H5w2M0pc1lh1PoA8BpmiRgibGl4uNeZaLTzDBJEKpDgpDpOUJasTsJQCobaj5cetBUDYD0T86Ll4hLqoGeNNVnv9kMpE2NkC6nFaEAyLMNu6C3O9CXp6CpvQU19ziVzWey0UQdCK0Be9Fs3+ECrdDjT6AnCYedS2BuD1RzoWBbWQdz5D1AhhU8vLpeRcq4VnmCBShRQnpSkdAlhc0iK4kRDAwgBjkvIkCAAikgJVOkTtniZEC0nHZLXXPulOhBSGaTzksN5rYTzSitDX+VoMLnWh1GXFlv3SIrpuuwXN/jC+PexFnwIrPC4beeczQI1xKtvnJBtPqBJzrRaeYYJIB1KclMbuATwDgdqvADGA+BVwgx0V9QZK7TSIVpKOyWqvXTKZCCkM03jIYb1XezzSktDX9Vq4HVaM61+EvY1+NPqCEBjDwZYAxlZ6cNLQErLgZ4Aa41Q2z4kcntBcz7VqP8MEkS4U4Kw0RVVS1TyO61RdL5rjxEvbTWapnQZJxfoVEkRKOtYpjDE0+UKobQmgyRcCY+mHjKYzEXYmGhoytKwQrYEw9je3ozUQxtCyQswYQaEa+UbUel/nDXS7z6LW+yqPs0frvdrjUab3ei5IdC2iytPxg0pw4uBSjOxbiOMHF9OzlAVKj1OZPidRT+juei+K7Bb09zhRZLdgd70XG3fUo641IGs/M0XtZ5gg0oU8TkrTsh/wN3es5QSAEyEpThwAXtre3gTW8j2abVWaC0WjMqX5i1x5GtmEllAYpnGQw3qv9nikpfVukl0LDhwKbGZwkITwZH0lUkfJcSqT50RLntDeUPsZJoh0IcVJaRp3AsEWACYAIamCHgCAdUTtmSD4W7Dli0+xxcFprroM5aLkJ3LmaWQ7EVIYpnHINgFd7fFIS0Kf2tfCaCg5TqX7nOgp/I3uW0JvkOKkNIwBwTZADAMmixSaF3U4MQZRCEIQBBxs9qGo2KK56jKUi5J/yG2dpIkwHq2UqdYq2Vjv1R6PtHSvq30tiNySznOiJU9ob9B9S+gNUpyUxmKXKuiJImC2Ap3WrGGiCMZCADj08bjR2mHB1Jp7nUqC5xdyWydpIjyKVspUa51srPdqjkdau9dpbM5vUn1OtOQJTQW937dkHDMWpDgpTTgA8BbJ88QiADOjw90EiBEwxoMzmWAWg3Ef05p7nXJR8odcWCf1PhHKgVbKVBsBNccjrd3rNDYTWvKEpope71syjhkPUpyUhuMAmwsImwEhKHmfOmAch4jJAZhtnSruHUVL7nWAclHkQAuWqlxZJ/U6EcqBnpKz8wU1xyOt3es0NhsbrXlCU0Vv9y0Zx4wJKU5KUzoccJUD/iYAhUCwFWACwJnArEUIh8IQbB60Fw7q9lGtudeJ7NCKpSqX1snOE6EWlESl0FNyNiEPehP6iPxGa57QfIOMY8aFFCel8QwEBp0CfPOaFLYXXZeBMfBhH8y8FXuKjoPfWRW3NK5W3etEZmjJUqWEdVIrSqJS6Ck5myCI/ERrntB8goxjxoVcF0rD88CQGVLIXrAVCHmBUBsQ8oILtsJi5tFccTJqjvjhC0YgiAy+YAQ1jb6UBFg5FjAlcktXS5XLZoaJ5yRLVakLLf4Qth5oVfS3y+WijnpZiFFOOoc/JoK8xwRBKEHUE1rhtqPYZSWlSSZo4V7jQh4npRFF4LuN0iK4LNJph1QswhxowSThK0T6nI4DLYG03OtGs+rrFa1aqnJhnTRqOIMek7MJgiCI1NBb5UJCPkhxUprmfcCWl4GwL/H+sA+uHa9i5rRr0VxdhUBYQCAswG4xwWLiwRhLKGAqFfplpDyVXKHlMC658zS0qiTmGr0mZxNHobGOIIhkkHHMuJDipDSHtwLtDZ02dLZGdAjK7Q3gDn+NcFU/bDvk7dWDpJRVnzxa8mAkS5WWlcRcQ8nZ+oXGOoIgeoKMY8aFFCel2b0BQOfclUQCI0PbtvewsW1CSh4kJaz6WipmoHeMZKkykpKYCErO1h801hEEkQpkHDMmpDgpjRDqtQkD0OxtS9mDlGurvlHzVHKFkSxVRlISk0FlqvUDjXUEQaQDGceMR36aebVM37EpNdtvHZySBwnIfQWvdDxaRGrksoqdlogqiW6HFTWNvowqRRKEUtBYpx2oQiyhF6hyobEgj5PSDJkOgEN8uF48DBz2uo+HJ0UPUq6t+kbOU8klRrFUUTgDoRdorNMGlGNGEIRWIcVJaZr3ArwJECPJ23AmlEZq4QuPSSkvJNehX0bPU8klRgnjMoqSSKhLtpXwaKyTULOiIOWYEQShZUhxUpq2emktpx7gmIh+pjb82xtI2YOUS6s+5akQcmAUJZFQBzm8FMnGOsYY2oIRfNfQhuFlRXA78nfqVNPbQzlmBEFonfwd/bUKiyBxJb2jcBDR322B22ZNy4PUk1U/XQti1/ZjKgsNUcyAIAj9IZeXIpH3PhgWsavei71H2mEx8XBYzNi4oyEvw8bU9vYYdd03giD0AylOStPelFIzN2vLyIOUyKqfrgWxp/a1LUHKUyGINKCFVHOL3F6Kzt777bUt+OaQFxFBRHWJC8PKXbCZTXkZNqYFbw/lmBEEoXVIcVKasD/ldnLkhaRrQeyt/fQRfXDsQA8JgUQcpBwkhpLcc08uvBTlRXbMKLCiLRhGIMwwuI8TBXYzOEjHz8ewMS14eyjHjCAIrUOKk9KksI5T53bZ5IWka0FMpf3XB72YOaosLwQFQh5IOUiM2mFPRiFXXooWfwQt/jCGlrm6CfH5GDamBW8P5dMS+QAZEvMbUpyUxmSTt10PpGtB1ILFkdAXpBwkRgthT0YhV14KLSgSSqIFb4+RFgcncofaVSHJkJjfkOKkNIXl8rbrgXQnfqMJCkR2kHKQHDJCKEeuvBRaUCSURCveHlr3jcgGNRUXMiQaA1KclCbULm+7Hkh34jeaoEBkBykHySEjhLz0ZEHOlZdCK4qEUmjJ20PrvhGZoKbiQoZE40CKk9Ic+kLedj2Q7sRvNEGByA5SDo7SVbC3mjgyQshEKhbkXHgptKRIKIWWvD207huRDmorLmRINA6kOClNywF52/VAuhO/EQUFInPIQymRSLCv9DjgsppRl8Yi1kR30rEg58JLoSVFQinI20PoEbUVFzIkGgdSnJSmqL+87Xoh3YnfiIICkRnkoUwu2H9X3wae48CBIyNEhmRiQc6Fl8KIigR5ewi9obbioidDIlX9yw5SnJRmxGnA139NrZ1MpDvxG1FQINLH6B7KVAT7PgU2FNktONjiJyNEmqhtQe56PlIkCEK7qK246MWQSFX/socUJ6WpnASAA8B6aMR1tJOPdCd+EhSIVDCyhzIVwb41EMb0EWU4jismI0SaqG1BJrQDWciJ3lBbcdGDIZGq/skDKU5K07QXMFkBIZi8jckqtSsboVy/CCJDjOqhTFWwDwkMFe7s12UzGmpbkAltQBZyIhW0oLikakhUwxCgdvGMfIIUJ6Xx1QHgAN4MiJHu+3kzwHEd7QhCHxjRQ0mCfW5R24JMqA9ZyIl00EIERG+GRLUMAVoKfdY7pDgpjbMUAANEEd1D9jhpO8c62hEEoVVIsM8tWrAgE+pBFnIiE7QQAZHMkKimIYBCn+WDFCelsRVIHiV0vjmjClTHi+OkdgShMSjX4Cgk2OceLViQCXVQ00JO45y+0WIEhNqGgHQiJOj+7xlSnJTGUpCgLkTXDZzUjiA0BOUadIcE+9yjBQsyoTxqWcjTGedIwCRSRe1QuVQjJEIRARu2N9M83wOkOClN0x7Jo8RZABZBt1A9zny0XdVEFTpIEN3RQq6BVoUUEuxzjxYtyERuSWQhZ2DwBQWEBRFhQYSVzz6HMDquBMICDjS147PvmxEICRhY6oTDYk46zpEhiUgHtUPlUomQqHDb8P63DZRT2AukOCkNx3W8WOKK5Bw72oYgNIDaIQaA9oUUEuwJQl66WshbA2HsbfSj0RdEWBDQ6o9gZIVkIc+U6LiyvbYFext9+K6hHWFBxOBSFyIiUF3qgNth7TbO1XuDqhuSCH2hhWJCPUVIjKksxNcHvZRTmAKkOCmNq4/0v9gx2HOdrA9MlLabOrVTEa1a+AllUTvEQAveLoIglKWzhXzrwVbUtQYQEgS4rGYERaDEaQVjwPvfNmQ0BkTHlf1N7aj3BtEeEsADsPAcGn0hRESGVn8Y4/oXwe2wxsa5Jl9IdUMSoT+0UkwoWYSE2vO8niDFSWkKKiAVg4D0PxMhuZ44xIpEcHxHO/XQuoWfUA41Qwy04O0iMoMML0S2lBfZMX1EH/z543040h6C226BwIB+HgeqS5xwOywZjQHRcaW5PQjGgAhjKHHZ0NQeRqHNjNZAGIwBvpDk5RrX3xIb5+q9Qc0ImFp7xrTWHy2hpWJCiSIk1A4l1BOkOClN0x7AZAHCwFGFicfRqnqQ1nJq2gP0GaZKF8nCT3RGzRADsoLpEzK8EHJhNZtQ6rJi+vAyWMw8LDwPl80UGw8yGQOi40qBzYK9R/xw2y1gAEwcB4EBLqsF3mAYxS4nGn1B+IICOABWEw+A04SAqbVnTGv90SK5LiaUjeKqhVBCvUCKk9IwJnmZTDZACAPoHJ9tkpQqJkrtVOkeWfiJeNQMMSArmP4gwwshJ8GIiLDI0LfIBhPffc7JZAyIjisuqxkRQYTVbgHHAQV2C5rbQyiymyFEGDiOQ0QQEIoIaPGHMbSsEGWFVtUFTK09Y1rrj5bJVTGhbBVXrYQS6gFSHZXG6pSUIjFaUU+yYMW8TmJE2m91Jj0EYwxNvhBqWwJo8oXAZFSy0rHw64lcXrN8Jxpi4HZYUdPogy8YgSAy+IIR1DT6chpi0NkKlgiygmmLroYXl80ME89JhpdSF1r8Un4IPX9EquRiDIgeUxQZzCYeIUHsmN9ssJl5HGkPQxQZBFGEIAK1LUdDqYpdVlR5nKjzBrrdx1EBs8rjzJmAqbVnTGv90QPRULkKtx3FLqssStPGHfXYXe9Fkd2C/h4niuwW7K73YuOOetS1BlLqk1rzvN4gj5PSWIsg5TZFuuzoGFSYCIDvaNedXLvD89HCTyEE2aPWekVkBdMXFFpJyE0uxoDoMXfVtaLEaUWtNwCbmYfLZkZ1iRPf1nth5ngcbg2iosiOMVVujKtyx8Y5NXNVtPaMaa0/RkPOKCFalzA1SHFSmpA3gdLUBRaW2nVBCXd4vsW5UgiBfJQX2TGjwIq9je3wBiMotJlRXeoEz+fuXtBSQi3RO/loeCHUJRdjQOdjtgXbYeY4HG4NwGk1wReKYECxE0UOK8oKbZg+vAzD+xbEHV9NAVNrz5jW+mM05FZcaV3C3iHFSWmCbR25TT0ghKV2nVAq9yifLPyUryUviTx3expy77kjK5h+yDfDC6EN0hkDUk2Q73zM7bUt2HekHUfawyiwmTGwxIlRFUU9ji9qCZhae8a01h+jkQvFldYl7BlSnJTGV3d0DadkiILUrhNKucPzycJPIQTyobbnjqxg+iCfDC+EtkhlDEg3LDt6zGMHehAICwiEBdgtJtgtppTGFzUETK09Y1rrj9EgxVV5SHFSGlEE0JvmL3a0O4qS7vB8sfBTCIE8KOm568laTFYw7ZNPhhdCe/Q0BmRq3NHbuKK1Z0xr/TEapLgqDylOShNozqid0laFfLDwkyVGHpTy3FERj/wgXwwvhH4wWli21p4xrfUnihEW5NWi4prv150UJ6WxOCCVH++pNCfX0e4oalgV9GaJ6wpZYuRBCc+d2qGAhLzkg+GF6BktCUdGDMvW2jOmtf4YyRCnJcXVCNedFCelcZYCnAlgAhIrT5y031kav1WDVgWtQ9dMHnLtuTOatdgo6N3wQiRHa8KREcKykymqWnrGtNIfIxritKC4GuW6k+KkNH2GARZnwnLjMaxOqV0XtGRV0At0zbIn1547I1qLCUKvaFE4yvewbK0pqlrGKIY4rSnSRrnuAClOymMrAmwFQKg1SQMGWAukdgnQglVBb9A1yy6sJteeOyNYiwkiH9CqcJTPYdlaVFS1jBEMcVpUpI1w3aOQ4qQ0jElheiab9LcYgRSyxwG8GeA4aT9LngOlFXe4njDyNZNjkM2l5y7frcV6Q0u5K4S20KpwlK9h2VpVVLVMvhvitKpI5/t17wwpTkpzZLf0v7WgQzkSpf85DgDf8T8ntSsdomJHiXxAzkE2V567fLYW6w0tWjIJ7aBF4Siq6IsMmDjAg++b2nGw2Z8XYdlaVVS1TD4b4rSsSOfzde8KKU6KwwG8FbAUAO31QNgPMBHgeKmSnqMMEEJSO4LIglwMsrnw3GnRWqym10Wtc2vVkkloB60JR4kU/Uq3AycOLkWRw6J7j6kWFVWtk8+GOC0r0vl83btCipPSlA6VFKSW74FICFKYHpO8TkEfIIQB9wCpHaErtBbipOVBtitaKuKhptdFrXNr2ZJJaActCUfJFP3vGtrQ6Athxsgy1ce1bNGaoqoH5DTEaW1O17IirUUDaK4gxUlp3AMAMCASAAAwdITogYFBBBcJSNF67gEqdpJIFy2GOGl5kE2EFop4qOl1UfPcelKyCfXQinBkFEVfS4qqnpDDEKfFOV3rirSWDKC5hBQnpWneC7QfAQCIYODA4lZzYuAgtDXA3LyXvE46QU2BtyeLmNYH2UQYtZyq2oKg3pRsrVmCjYQWhCOjKPpaUVT1SDaGOK2GLetBkdaCATTXkOKkNPs+AkI+iLwZEMPRenoApKA9AWYg2IaWHR/CfTIpTlpHTYG3N4uYHgZZLaGmMKa2IKgnJVuLlmCjobZwpDdFPxu0oKjqlUwMcWobsXpCL4p0vlcxJsVJaUJtYEK4w8/EgwPiPE48BIABhxoaUcSY6g8A0TNqCbypWsT0MMhqBTWFMbUFQb0o2Vq1BGsFJT1xagpHelL05UBNRdVo3l21jVi9QYq0+mhiVPntb3+LQYMGwW6348QTT8THH3+ctO3f/vY3TJ48GR6PBy6XCxMnTsQf//hHBXubJY4SSAF5IjiIQJeXtJ3hcNiB5vawql0leicVgTckiLIKvF0tYi6bGSaekyxipS60+EPYeqAVjLHYIDu0rBCtgTD2N7ejNRDG0LJCzBhhbCGzK52FsUTkUhhT89zAUUum22FFTaMPvmAEgsjgC0ZQ0+hTTclmjKHJF0JtSwBH2oLYcqAlpfveiNS1BrBhez3e+Oog3txyEG98dRAbttejrjWgdtdkJ6ro13kD3X7vqKJf5XGqrujLSVRRrXDbUeyyKlZp0yj3VBQ15vR0KS+yY+aoMpwzvhJnj6vEOeMrMXMUzedKobrH6cUXX8SSJUvw5JNP4sQTT8Tq1asxZ84c7NixA+Xl5d3al5SU4M4778SoUaNgtVrxxhtvYNGiRSgvL8ecOXNU+AZpYisE43ipBDnii45Hw/ZEmODnnXkRZqB1srWmqWH5TNcipnZYjV5Q0+uiBY+P1iyZXUPyIoKI74/4MbKiQJOWYDUxmidOLyFLesZo91QUvXgz8z0cTsuorjitXLkSV199NRYtWgQAePLJJ/Hmm2/imWeewW233dat/YwZM+LeX3/99Xjuuefw4Ycf6kNx4gDwJkCIdFupKRq2J3I8zCZO9Qcz35EjV0INgTeTsC4aZHtHTWFMK4KgVpTsREJbbYsfta0B8BwHp9UMtyP+fs6nvJZ00HJORi7RmqKfTxj1ngK0YcQitI2qilMoFMKnn36K22+/PbaN53nMnj0bmzdv7vXzjDH885//xI4dO/DrX/86YZtgMIhgMBh739ramn3Hs8HiBMeST+wcAI6JKC7y0IOZQ+Sypqkh8OrFIqZH5BDGMvVipnvuXOUedFay1chvSCa0uR1WlBfa0eIPYW+jH+P6W8B1Mj8Z9b7Xek5GLtGKop9vGPme0ooRi9AuqipODQ0NEAQBffv2jdvet29fbN++PennWlpaUFVVhWAwCJPJhCeeeAKnn356wrb3338/li9fLmu/syLUBk4U0FMUPg8RQ9xUGCIbehL45LamKW35JItYbsm2jG02XsxUz61EZTm1qtclE9pcNhNKC6zwhSJoaAvAF3ShoMNwYOT7Xu3CImpD3nT5Mfo9Rd5MoieyUpyCwSBsNptcfUmZwsJCfPHFF2hra8P69euxZMkSDBkypFsYHwDcfvvtWLJkSex9a2srBgxQcXHZhp2QikAgqfLEQURx+14FO5Vf9Cbw5cKapqTlkyxiuScTYUxOL2ZP51Yi96DzOcoKbBAY0BYIY8uBZtR7A5g5qjxnwkMyoY3jOFSXONHSHsbBFj9a/CE46L5XzANttOpqRoaiGsibSSQnLcXpH//4B1544QV88MEH+P777yGKIlwuF4499licccYZWLRoESorK1M+Xp8+fWAymXD48OG47YcPH0ZFRUXSz/E8j2HDhgEAJk6ciG3btuH+++9PqDjZbDZVlLuk8EcveTLlievSjoinpwk8FaFSZMiJNU1JyydZxLSFUjkBSpyn8zk8Dit2N/hwxBdCRBBh4nkcbPbDYuJx/nFVOREiehLaPE4rhpUXQGQMgbCI/c3thr/vlfBA5+PaWaQIJoeiGiTIm0kkIiXp/NVXX8Wtt94Kr9eLs846C7feeisqKyvhcDhw5MgRbN26Fe+99x7uueceLFy4EPfccw/Kysp6Pa7VasWkSZOwfv16zJs3DwAgiiLWr1+PxYsXp/wlRFGMy2PSNP6muLdJh+ku7QiJnibwskJbSkLlxAFuXVjTepvYySKmHZTKCVDiPNFz2MwmfH2wFb5wBG67BVa7BSFBRH1bBB/srMfYKjdGVBRm/F2S0ZvQFowImDmyHMcO9CAkMMPf97n2QOdLdbXO42mrP4zvm9pxsNmfN4qgnFBUA0EkJyXF6cEHH8SqVavwgx/8ADzfXZicP38+AODAgQP4zW9+g+effx433nhjSh1YsmQJLr/8ckyePBknnHACVq9eDZ/PF6uyt2DBAlRVVeH+++8HIOUsTZ48GUOHDkUwGMRbb72FP/7xj/jd736X0vlURwjJ285A9DaBTxzgSUmonDjArXlrWqoWXrKIaQOlcgKUOE8wIiIYEdDsi8AXjqC84Kj3ys6bUOm2Y2ddG7YcaMHwvt1Lg2dLKkLbuP5ulBRoKJJAZXLlgc6X6mqdx9NGXxB7G9phMZswrqoQ/T1OXSqCuYaiGggiMSkpTqlUuAOAqqoqPPDAA2l14KKLLkJ9fT2WLl2K2tpaTJw4EW+//XasYMS+ffvilDWfz4drr70W+/fvh8PhwKhRo/D888/joosuSuu8qhFokbedQUhlAt+yvwWhSO9CZUhgmram6dXCa+TQF6VyApQ4j83MQxAZDrf64XZ2X2gzIjB4nFY0tAVzVlWLhLb0yYUHWm4PpxpjRNd8vcMtQWm5eVHA7rr2WGl7PSmCSkFRDQTRnbQTaVasWIEf/vCHGDt2rGydWLx4cdLQvI0bN8a9/9WvfoVf/epXsp1bcZzdF/XNqp1BSGUCr231A+BSEiqLXVZNCmZ6tfDmYw5EOiiVE6DEeTxOC/q47PjE34Syrl4dxtDsD6Gi0AEzz+W0qhYJbekjtwdaTg+nGmNE1/HUFxTQ1KFA2c08DnsDR0vb53mZ7UyhqAaCiCdtxWnZsmUAgP/7v//DV199BZPJhNGjR+OGG27A4MGD5e5f/mF1yNsuz0hmkUxlAjfxHIqdNtR5AykJlVoUzPS4foZePWRyolROgBLn4TgO4/q78eGuehxo8aO80A6LmUc4IqLZH4LLZkFftxVA7hfpJqFNXeTycKo1RnQdT8OiiIggwmq3ABwHj8OKRl8QvqCAAps578tsEwSRPRnNesuXL8fmzZsxceJEHHPMMdi8eTNGjx6N9evXy92//MNWIG+7PKKuNYAN2+vxxlcH8eaWg3jjq4PYsL0eda2BuAk8EYGwAJvZhHFVbrgdVtQ0+uALRiCIDL5gBDWNvoRCZVQwq3DbUezqHpakNKkoiCFB1MzE3tWi67KZYeI5yUNW6kKLP4StB1rBWE8rl+UH0fCyoWWFaA2Esb+5Ha2BMIaWFWLGCPkEQyXOM7xvAU4dUQabxQxfKIJGXxDtYQH93E6MrSxEICyiyuPM+6paRifq4azzBro9w1FjVG/3gZpjRNfx1MLzMJt4hARp/LSYeUREEeGO91opDEQQhHbJqOb1XXfdFfM8Rbnttttwyy234NNPP5WjX/lL3TdJd3WeNgIHtsLOjLMIbm8Wyekj+qQUojS8bwE8TovmQvBSRW/rZ+jRQ5ZLlPJi5vo8HMdh6rA+CAkiDrcE4HZaUGCzwMQD9d6g6nmAhESuc4bk8HCqOUZ0HU9dNhNKXFbUdhjjwhERZp6HxcRrpjAQQRDaJm3FieM4/OQnP+m2/YorrsDq1avl6FN+Ewkn3NzV1ravrgkHttfrQtjPllTyer4+6MWYysKUJnAthuClit7Wz8hllbeoUBgICwiEBdgtJtgtJs3/lkqFl+X6POVFdswcWR4zQjT7Q7oyQuQ7SuUMZVuoQ6mKk4lINJ5Wlzjh9UdQ5w0gFBExoNgFgCWNSiCIdDFyoSQjkLbi1KdPH2zZsiW2AG2UL774AuXlVNCgV6yubpsSLoJrLzRMjkiqFsljB3pSnsD1mhuht/UzcuUhiwqF22tbsO9IO9o6chAGljgxqqKIBHeF0LMRIp9ROmcom/tATS96ovG00G7BkDIXvj7YAp7jYDFz8AYiZBAgZEHrhZJIqcuetBWnefPm4aqrrsLu3bsxZcoUCIKATZs24cEHH8Qtt9ySiz7mFwMmAx8ffZtIaWIA/GUTMahUu1XU5CQdi2SFO/8FOT2VYs6FhywqFO5vake9N4iIwFDitMAXiuD7I+0IRkRDGBS0gl6NEPmKWpU3M70P1PaiJxtPzzimAgNKnChyWPJyHiGUR+uFkrSu1OmFtBWn1atXo0+fPnjggQdw5MgRAMDAgQNx77334tprr5W9g3lHURVgcQFhX9ImEZMTIVelYXJE0rVIGkGQ04ulX24PWVQobG4PgjEgwhj6FkmeyCK7BYe9AYiiVBI73w0KBJEIveUVasGLrpfxlNAvWl9KROtKnZ5I2zfucDhw7733oqGhAUeOHIHX60VNTQ0pTalSNRlwFCfdzQBErG60lIwHoL0qarlAjspN+YjWKv4lQ84qb1GhsMBmwZH2ENz2TsJNR/ngI+0hFNjMMeGQIIyE3ipvAspVnOwJvYynhD5Jx6ChNFT9Vl4yqqoXxePxyNQNA9F6EIgEe2zCiyHY/bUIFAzUXBW1XKAFiySRHXJZdKNCoctqPrreSicsZh6RYBg8x8EvCAhGRIrZJgyF3ipvRiGvD5HPqFkEpTf05qXWOikpTmeeeSaWLVuGk046qcd2Xq8XTzzxBAoKCvDzn/9clg7mHfXbAX9T0t0cAEuoBc7W3fC7Bmiuilqu0FNeD5EYOUIoo0KhKLLYeit2/uhEFC0fLDIGq4lHqz+Mbw5SzDbRM/mkXKudM5QNRgizJoxJSgYNnoc/FEFtS0DRcUjLSp0eSUlx+tGPfoQLLrgAbrcbc+fOxeTJk1FZWQm73Y6mpiZ88803+PDDD/HWW2/h7LPPxkMPPZTrfuuXum0Ai8TecuheIIJnEVgat6PGeryhvC1kkSSiQuGuulaUOK2o9UoTDMdxAJNymyqKHGgLRlBWYMPn+5rQGghTzDaRFL0mRCdT9shDTxDaozeDxncNPgAMH+ysR1hkio5DevVSa5WUFKcrr7wSP/nJT/DXv/4VL774Iv73f/8XLS0tACQL0jHHHIM5c+bgk08+wejRo3PaYd3TerDbpkTKE9d6CEPHG8/bQhZJY9NZKGwLtsPMcTjcGoDTaoIvFIHVbALPc/A4LGAMaA2ENZmIS2gDvSZE96bskYeeUIJ88tTmmp4MGt81+HCwqR39PA64HVbFxyE9e6m1CMcyzAZraWmB3+9HaWkpLBb9XOzW1la43W60tLSgqKhI+Q68cBmw/fWEuzr/EKGh58D6k+dpkCIMSW/rOPUvduCjPY0oslsSWtB8wQhaA2GcM76SFHGDwhjDhu31krBQ2l1YqGn0YWhZIWaOKtPUOJtM2avzBuB2WOOELBJsiVyhV0+t2nS7bjyPBp9UJXZclVu1cajHccVpVaxIi1ZJRzfIuDiE2+2G2+3O9OPGJeBNuqvzI2MTfABNgIRBiYZtHjvQg0BYQCAswG4xwW4xweO04HBrkGK2iR7RY0J0uiWNyUNP5AK9emq1QNeUA38ogg921sPt6F7JUclxSCte6nww9mRVVY/IAEuKN2eq7QgiT+lJKKSYbaI39JgQrUdlj8gvtL4ekR7oPHfVtgQQFpkmxiG188jzxYtJipPSuMrlbUcQBoRitone0KNyrUdlj8gvSHmXF62NQ0p5qbt6lkIRAe9/25AXXkxSnJSmqJ+87QjCgFBlMaI39Khca03IIowHKe/yosdxKFtSzfPSqxeTRl+l8QxA75ed72gnwRhDky+E2pYAmnwhWt2ZIHA0ZntoWSFaA2Hsb25HayCMoWWFhk90JY4q126HFTWNPviCEQgigy8YQU2jT5PKdVTIqvMGuo3zUSGryuPMKyELoDlOS3RW3hNBynt66HEcyoZoftzuei+K7Bb09zhhMnHYUetFvTeIFn84rn1XL6YeSNvjdPnll+PKK6/Eqaeemov+5D/VJwO2QiDYkryNrVBqh8xjQvMhAY8gekPtmG1C22glITpVjOhJzZe8h3zBiB6SXKO3cShTkuXHWUw8ihxmhAURe4+0w+2In6P15sVMW3FqaWnB7NmzUV1djUWLFuHyyy9HVVVVLvqWn3gGSq/DXwNIdJPwQHE14BkYV9mmrNAGQQTagmFsPdCM+rYAZo4sT/jA0UREGAmqLEb0hN6Ua6MIWQBVb9MiRlTelUBv41AmJMuPs5h4WEwmmMzAEV8IvqCAAvtR9UNvXsy0Fae1a9eivr4ef/zjH/Hcc8/h7rvvxuzZs3HllVfivPPO09WaTqrQegAwWQGOB1gCxYnjAd4C1rofW2udaPGHUOy04Lv6djT6goiIIkwch/3NAVhNPOYdWxV3g9JERBAEEY/elGsjCFlUvU27GEl5VxK9jUPpkiw/zmUzodRlw4FmH0wcj7B4VPbVoxczI/WurKwMS5YswZdffomPPvoIw4YNw2WXXYbKykrceOON2Llzp9z9zB8CzUDzPkl5shRK//OWTu8tQMs+tDY14EBzO+wWHlsPeHGopR1Oi3TzuaxmBMMR/Ovbeuw83BY7dNeJyGUzw8Rz0kRU6kKLP4StB1opfpwgCELjRIWsCrcdxa7ua8DonXSqtxHKU15kx8xRZThnfCXOHleJc8ZXYuYoMrwSyUmWH8eBQ3WpA1aTCS2BMMIRUdd5Xln5xQ4dOoR169Zh3bp1MJlMOOuss7BlyxYcc8wxWLVqlVx9zC8avwPCPsDiAGxFgNkBmGzS/7YiwOIEQj6IDbsRiog43BKCLxRG30I7bBYTeI6DzWJCldsBbzCCLftbYooQTUQEQRCEHkileltIEHWT95CP5LvyTshLT8VtiuwWlBfZMaqiEBFR1HUxp7RD9cLhMF5//XU8++yzePfddzF+/HjccMMNuPTSS1FUVAQAePXVV3HFFVfgxhtvlL3D+ocDOBMQageEJsTlOQW9khJlMsNsNiHiZ6j1BlDssAJdBqyQyFDssKDBF4itp0BlRAmCIAg9QKXXCSK/6C0/rqrYgenD+8BqNuk6BDltxalfv34QRRGXXHIJPv74Y0ycOLFbm5kzZ8Lj8cjQvTyksFxSggR/gp2itN1chILSfujDbPik5gjKCuJjYhljaAmE0bfIARPPxRQhmogIgiAIPUDV25SDquwSSmGE/Li0FadVq1bhRz/6Eez25F/e4/Fgz549WXUsb+k3EQgnUpo6EfaD63csxtkEfLizHgdbAigrsMFq4hESRLQEwnBZzCgvsoHjEFOE8mEiogGeIHILPWOEFqDqbcpAVXYJpcn34jZpK04bNmzAvHnzuilOPp8P//M//4NnnnlGts7lJdvfBMRecozEMLD9TQwfdyGmDS/DR3sa0R4S4BXDMJt4VBTZMbDYiWZ/KE4R0ttE1FWAC0UEfH3QSwM8QeQIEqIILWEE67SaUJVdQi3yuYIgx9IssWYymXDo0CGUl5fHbW9oaEBFRQUikYisHZSb1tZWuN1utLS0xHKyFOWNm4D/Pt17u8lXAec8grrWADZsr0NtawAehwUFdgtMHFDfFoTbaU2YVKcH4ahrH4NhEfXeIArtZgwtK4hX+BxWGuAJIkuSCVH0jBFqQ15Q+WGMYcP2eikCpbR7BEpNow9Dywoxc1QZXWvC8KSjG6TscWptlcpYM8bg9XrjPE6CIOCtt97qpkwRCRCCabWTSoKWx5SMZn+oV4uc1t2kXQU4m4XHZ3ubse9IO/oXOxAWRLhsZlrPgyBkgtbMIbRMPlun1SKdKrt07QkidVJWnDweDziOA8dxGDFiRLf9HMdh+fLlsnYuL6maBHz+x9TadZCJIqTViSiRANcWjMAXimBwqRMtwQj2HmmH22GJ3W80wBM9Qdbq3iEhiiCMBVXZJYjckLLitGHDBjDGMGvWLLzyyisoKSmJ7bNaraiurkZlZWVOOplXlAwBwAHoKUKS62jXaYtGFaF0SSTAhQUREVGE1WKBm+NwxBeCLyigwC7dnjTAE8nQQ1iqFiAhiiCMBVXZJYjckLLiNH36dADAnj17MHDgQLLoZkokBJjtQKSHynoWh9QuD0kkwFlMPMw8j3BEEny9gTDC4lEBjgZ4IhGU+Jw6JEQRhLHIhyq7BKFFUlKcvvrqK4wdOxY8z6OlpQVbtmxJ2nb8+PGydS4v4TiA7+Wyc6ZuC97mC4kEOJfNhFKXDYda2uG2W2A28bDwkgCn1gBP4V/ahnJ20oOEKIIwFnqrsksQeiElxWnixImora1FeXk5Jk6cCI7jkKgYH8dxEARB9k7mFZ6Bva/jFPFL7fKQRAIcBw7VpQ60tIewp7EdQ8tcsFt4+IIRVQZ4Cv/SPpSzkx4kRBGE8eit3HtZoQ1NvhAZCAkiDVJSnPbs2YOysrLY30QW1H4FsF6US1GQ2pV1L8Khd5IJcGaeh8dlBc9z8DgtONDiT3s9Dzm8RBT+pQ8oZyd9aM0cgjAeyYpL1XuD2LC9ngyEBJEmKSlO1dXVCf8mMuDwNvRcGALS/sPbgHFKdEh5kglwE/p7MKayEFazKW3lRw4vEYV/6QfK2ckMrS9VQBCE/HQtLmV0AyGF4hPZkJLi9Prrr6d8wHPPPTfjzhgCe2HK7fL54ZZTgJNrEqDwL/1AOTvxpDNW5EuFToIg0sfoBkKlQ/HzWY4zKikpTvPmzUvpYJTjlAL9JqbU7EjRMfgiz93ocghwck4CFP6lHyhn5yiUk0dkAgl0xsTIBkKlPW00NucnKSlOokiComz0VIa8AwZgy95a7HZ7DelG74mukz1jTLZJgMK/9AXl7CgvCJCwnR+QQGdcjGogVNrTZvRwyHwm5XWcCJmo397j7mj2k/XItxg05AzDudF7ItFk77Sa0egLorww8QCUziRA4V/6w8g5O2oIAiRs6x8S6IyNUQ2ESnrajB4Ome+kpDg99thjuOaaa2C32/HYY4/12Pa6666TpWN5i7c+pWZ9uFb4DOZG74lkk/3eRh/2NrSjxGlDpcfR7XPpTAIU/qVPjJqzo6QgQMJ2fkACHWFUA6GSnjYjh0MagZQUp1WrVuHHP/4x7HY7Vq1albQdx3GkOPWGvajH3VGPE7MmbpevbvSe6GmyH9WvEPubA/j6YAsqimzgeT7uc+lOAhT+RegFpQQBErbzBxLo8oNsQmaNaiBU0tNm1HBIo5DyOk6J/iYyoM9wABySlSSX9nBociZeADdf3eg90dNkz3M8xlUV4rO9zdhW68WgUlfWk4CRw7+IzFAj90cpQYCE7fxBboFOLzlveulnKsgRMmtEA6GSnjajhkMahbRznFasWIGbb74ZTqczbrvf78dDDz2EpUuXyta5vKR0OGCyAUIgaRORt+J7vgpuxgzjRu+J3ib78kIHBvUJo7/HidZAWJZJwKjhX0T6qJX7o5QgQNZT/dCbgiCnQKeXnDe99DMV5AyZNZqBUElPm1HDIY1C2orT8uXL8dOf/rSb4tTe3o7ly5eT4tQbVid6WgCXA8BzgN1ZZCg3ek+kMtmXuKyYOaoMHMcZYhIgtIGauT9KCQJkPdUHqSgIcgl0esl500s/UyEXIbNqGAjV9P4p5WkzajikUUhbcWJdvCBRvvzyS5SUlMjSqbzm0JeAEO6xCS+EcUrBfnxWONIwbvSeSHWyL3ZZaSAiFEMLuT9KCAJkPdU+qSoIcgh0WrjvU0Ev/UyVfAiZ1YL3TylPWz6EQ+ZTiKucpKw4FRcXg+M4cByHESNGxF08QRDQ1taGn/70pznpZF7Rsg9AbyEtIjyhWswcVUY3Lch6Q2gTrQgyuRYE6PlLjhYEi3QVhGwFOq3c972hl36mit5DZrXk/VPK06bncEgtKLlaJWXFafXq1WCM4YorrsDy5cvhdrtj+6xWKwYNGoQpU6bkpJN5RWttyu0oz+Yo+WC9IfILLQkyuR4r6PnrjlYEi0wUhGwEOi3d9z2hl36mip5DZvPN+5cOepTjtKTkapGUFafLL78cADB48GCcfPLJsFgoLCMjzCnebKm2MxB6tt4Q+YeeBZlMoOfvKFoSLDJVEDIV6PRy3+uln6mi55DZqHJfVmiDLyQgLIiwmHi4bCZdev/yGSMruamSdo7T9OnTY38HAgGEQqG4/UVFPa9TZHhSvdEMekP2hh6tN0R+omdBJlPo+dOeYKG0gqCX+14v/UwVPYfMBiMijvhCONwSRJM/hIgowszzKHXZUF3qQIHNoivvXz6TbyGuuSDtkbS9vR2LFy9GeXk5XC4XiouL415EL5QMkrcdQRCqEBVk3A4rahp98AUjEEQGXzCCmkafpgUZInPSESyUIKog1HkDYCy+YmtUQajyOGVTEPRy3+uln+kQDZkdWlaI1kAY+5vb0RoIY2hZIWaM0G74VKs/jJoGH75v8sFpMaHUZYPTYsKhlnZs2d+KOq9fV96/fCYVD3ZIEA2t5KbtcfrFL36BDRs24He/+x0uu+wy/Pa3v8WBAwfw+9//Hg888EAu+phfFFRAuuyR5G04c0c7ZdBCgjNB6BHK/TEeWsudUcMToZf7Xi/9TAe9hcwyxvD9kXZYzTxExmA18+A4DjaLCX3NdtS2+rHlgIA5Y/rqxvuXz+RbiGsuSFtx+vvf/44//OEPmDFjBhYtWoRp06Zh2LBhqK6uxp/+9Cf8+Mc/zkU/8wdbAWCxAuEeFCezVWqnAFpJcCYIvaI3QYbIDi0KFmooCHq57/XSz3TQU8hsc3sYB1v8GFPpxnf1PtS1BeG2W2A18QgJIsIiwIsCBhQ7ZftNyBicOfkW4poL0lacjhw5giFDhgCQ8pmOHDkCADjllFPws5/9TN7e5SPWIsBkA8J+JF4Il5MKQ1hznyumpQRngtAzehJkiOzQqmChhoKgl/teL/3MR6Ie2v4eJ5xWE/YeaccRXwjeQBhmE48BHifMZqDIIc/zQsbg7NBzLp1SpK04DRkyBHv27MHAgQMxatQovPTSSzjhhBPw97//HR6PJwddzDPCbYDJLIXjMaH7fs4E8CapXQ7RWoIzQRCEHtCyYEEKAqE1OntoPU4r3A4LfEEBYVGEhecBMHiDEVk8tGQMlod8DHGVk7QVp0WLFuHLL7/E9OnTcdttt2Hu3Ll4/PHHEQ6HsXLlylz0Mb+wuCRHE2+S1sFlAqQN3FGlCZzULoeoWTmF3OgEQegZEiwIIjUSeWgL7JLoyRhDTaNPFg8tGYPlJR9DXOUibcXpxhtvjP09e/ZsbN++HZ9++imGDRuG8ePHy9q5vCTs6/iDARwAmHBUcerYzlindrkh0wTnbJUecqMTeoCUe6I3SLAgiN5RykNLZbTlhzzYiUlbcepKdXU1qqur5eiLMbB2eJJEEWBdytUyAJxFUqCsufU4ZZLgnK3SQ250Qg+Qcp89RlE8SbAgiN5RwkOrtWqXesYo43empKQ4PfbYYykf8Lrrrsu4M4Yg5AMiwe5KUxQWBsJBqV0OSTfBOVulh9zo2ocGS1Lu5YAUT4IgupJrD21XYzADk3KpBBEWk5RLZdQy2unM7TR+905KitOqVatSOhjHcaQ49YbZDoS8PbcJeaV2OSQd97kcSg+50bUNDZak3MsBKZ4EQSQjlx7azsbgYsGCfUcCaPQFERFFmDgOERGYMqTEcGW005nbafxOjZQUpz179uS6H8Zh72YkLkPeGSa1qzoup11J1X0uh9JDbnTtQoOlBCn32UGKJ0EQahE1Bu9paMOGHQ0w80CfAhsYeDT6QhAEEY1tIdR7g6rNZ0pHdaQzt9P4nTpZ5TgxJikARr+IaXHoS3nbZUkq7nM5lB4tLhpJ0GDZGVLus4MUT4Ig1KSs0IZipxUFNhNMPI+2YARmE4+BJU4MLHai2R9SbT5TOqoj3bmdxu/UyUhK/cMf/oBx48bB4XDA4XBg/Pjx+OMf/yh33/KTVB9WBR/qqPu8wm1Hscva7aHprPQkIhWlJ+pGr/MGYgp3lGhOVZXHaTg3utqkM1jmO3Lc50YmFcUzJIikeBIEkROa28PwhSKYMqQUJwwqweRBJTi+ugTjq9wodllVm8+inp/d9V4U2S3o73GiyG7B7novNu6oR11rQPZzpju30/idOmlLACtXrsTPfvYznHXWWXjppZfw0ksv4cwzz8RPf/rTlHOhDE2/CfK2UwA5lJ6oG93tsKKm0QdfMAJBZPAFI6hp9NFq1CpBg+VRSLnPDlI8CYJQk+h85rCaUWA3S94nuzkmV6gxn3X1/LhsZph4TvL8lLrQ0uEF6zrnZEu6czuN36mTdqjeb37zG/zud7/DggULYtvOPfdcjBkzBsuWLYtb54lIwMAT5W2nAHKtw6CXRSONVF2OQiiPotR6I/lKupU6CYIg5ESL85laIXDpXgsav1MnbcXp0KFDOPnkk7ttP/nkk3Ho0CFZOpXXBL2QFmrqybrAdbTTDnIpPVpfNNJo1eX0OljmSrnVi3KvRUjxJAhCTbQ4n6mVO5vutaDxO3XSVpyGDRuGl156CXfccUfc9hdffBHDhw+XrWN5y8GvkFJVvYNfAUNmKNCh1JFL6dHqopFGrC6nx8Ey18qt1pV7LUOKJ0EQaqHF+UwtL1gm14LG79RIW3Favnw5LrroIvzrX//C1KlTAQCbNm3C+vXr8dJLL8newbwj0CxvO4XRqtIDZOeFMHJ1OT0Nlkopt1q+z7UOKZ4EQaiF1uYzNb1gmVwLGr97J2XFaevWrRg7diwuuOACfPTRR1i1ahXWrl0LABg9ejQ+/vhjHHvssbnqZ/7gLJG3HQEgey+E0Utx6mGwNLJyqzdI8SQIQi20NJ+p7QXL5FrQ+N0zKStO48ePx/HHH4+rrroKF198MZ5//vlc9it/CfvlbUfI4oWgNXy0P1gaXbkltI+RCssQhJbR0nymthdMS9ciH0hZcXr//ffx7LPP4qabbsKNN96ICy+8EFdeeSWmTZuWy/7lH60pFtBItZ3BkcMLwRiDPxRBICyi0RdEWaENHOLbphqHTIJTcrK9NqTcElrGaIVlCIJInVx7wUj2UI6UFadp06Zh2rRp+M1vfoOXXnoJa9aswfTp0zFs2DBceeWVuPzyy1FRUZHLvuYHLEWhLtV2BidbL0RU2Nnf5MP3R3zYsj+M4eWFGNTHCbdDap9qHDIJTsmR49posdQsQQDGLCxDEER65MrzQ7KHsqQtYbhcLixatAjvv/8+vv32W/zoRz/Cb3/7WwwcOBDnnntuLvqYX7jK5W1ncLJZwLXzat5uhxXHDShBsdOKbw614r81TTjiC6a8QK8aK4PrBbmuDS1QS2gRtRa4JAiCINlDebIyzQ4bNgx33HEHfvnLX6KwsBBvvvlmRsf57W9/i0GDBsFut+PEE0/Exx9/nLTtU089hWnTpqG4uBjFxcWYPXt2j+01hxiUt53ByXS160TCTkmBFZOqi3FMvyIcaQ/hs33NaPWHMbSsEDNGJLcYk+CUHDmvTTTJ1u2woqbRB18wAkFkKSu3BJEL0vF6EwRByAXJHuqQseL0r3/9CwsXLkRFRQV+8Ytf4Ic//CE2bdqU9nFefPFFLFmyBHfffTc+++wzTJgwAXPmzEFdXV3C9hs3bsQll1yCDRs2YPPmzRgwYADOOOMMHDhwINOvoiymFN2mqbYzOJl6IZIJOx6nFeP7uzF9eBkGFDtwyvA+mDmq5zAbEpySI/e1iSbZDi0rRGsgjP3N7WgN9K7cEkSuyMbrTRCdYYyhyRdCbUsATb4QCbxEj5DsoQ5preN08OBBrFmzBmvWrMGuXbtw8skn47HHHsP8+fPhcrky6sDKlStx9dVXY9GiRQCAJ598Em+++SaeeeYZ3Hbbbd3a/+lPf4p7//TTT+OVV17B+vXrsWDBgoz6oChWh7ztDE6mpT57EnY4jkNpgQ3+iACH1dyrB4OKFiQnF9dGS6VmCYJy7wg5oDwVIl1I9lCHlBWnH/zgB3jvvffQp08fLFiwAFdccQVGjhyZ1clDoRA+/fRT3H777bFtPM9j9uzZ2Lx5c0rHaG9vRzgcRklJ4nWPgsEggsGjYW+tra1Z9Tlr+owEwAHoyZLEdbQjUiGTUp9yCjskOCUnV9eGyqsSWkHNBS6J/ICKixCZQLKHOqSsOFksFrz88ss455xzYDIl1m7TpaGhAYIgoG/fvnHb+/bti+3bt6d0jFtvvRWVlZWYPXt2wv33338/li9fnnVfZcNWAPBmQOzBdcqbpXZEyqTrhZBT2CHBKTn5fm20VgJWa/0xAmovcEnoG1rYm8iUfJ9ftUrKitPrr7+ey35kxAMPPIAXXngBGzduhN2e2Bpz++23Y8mSJbH3ra2tGDBggFJd7E7YD/CWnhUnk4UWwM2AdLwQcgo7JDglJ5+vjdZCa+L6ExERERn6FNgwrsqN4X0LdHmN9YLaC1wS+oUW9iYyJZ/nVy2TVo6T3PTp0wcmkwmHDx+O23748OFe14R6+OGH8cADD+C9997D+PHjk7az2Wyw2Wyy9FceegvTA8BYRzsil8gp7JDglJx8vDZaC63p3B+7hUeTL4xabwCf1BzBhzvrMW14GU4Z3keX11ovUO4dkQmUp0JkQz7Or1pHVcXJarVi0qRJWL9+PebNmwcAEEUR69evx+LFi5N+7sEHH8S9996Ld955B5MnT1aotzJhsXcsbhuNOe08GHZsY6LUTufoIWxITmGHBKfk5NO10VpoTef+FDst2HrAC18ojGKHFWUFVhxsCeCjPY0ICyJmjiqniTSHUO4dkS6Up3IUPcgMWiSf5lc9oKriBABLlizB5ZdfjsmTJ+OEE07A6tWr4fP5YlX2FixYgKqqKtx///0AgF//+tdYunQp/vznP2PQoEGora0FABQUFKCgQAd5QWE/wJkALix5ljiT5IDiIClMHCdt03montbCmHpCTmHHCIJTppNbvlwbrYXWRPtTVmjDd/Xt8IXC6Ftol8YSAGUFNrSHBNR2PJOUK0EQ2oHyVCT0JDNokXyZX/WA6orTRRddhPr6eixduhS1tbWYOHEi3n777VjBiH379oHnj1pafve73yEUCuHCCy+MO87dd9+NZcuWKdn1DGEAx0svJkivjs0Ad3Rfb+F8GkZrYUyEfNDkpr3Qmmh/BBFo9AXhcVhjShMAWE08vGIYHoeFciVAVm1CW1CeCskMhL5QXXECgMWLFycNzdu4cWPc+5qamtx3KJdYCyShRkyiGIkMMHNSOx2itTAmQj5ocpPQWmhNtD9twTAiogiLOd4yHRJEmE08CuwWNPtDhs6VIMVffxhB0TVyngrJDPJjhGdGTTShOBkKa2GHNVhIsJNJ2zleaqdDtBbGRMgDTW5H0VpoTbQ/Ww80w8RxCEdE2Dq8YYwxtATCqCiyw8TBMLkSiSDFX38YSdE1ap4KyQzyYqRnRi2MOYOqScgLiJGe24hhqZ0OSSWMKSSIhrZ665F0Jrd8Jxpa43ZYUdPogy8YgSAy+IIR1DT6FA+tifanr9uOiAjUeQMQBVEK9WkLwmUxY4DHgb1H2uG0mMEYA2P6DQXOhK6Kv8tmhonnJMW/1IUWfwhbD7Qa7rpomaiiu7veiyK7Bf09ThTZLdhd78XGHfWoaw2o3UXZieapVLjtKHZZ815pAkhmkBMjPjNqQIqT0gTbACGM5OXGOWl/sE3JXslG5zCmRBipQlA+QZNbPNHQmqFlhWgNhLG/uR2tgTCGlhVixgjlPRflRXbMHFmOKUNKwHMcvq1vQ0t7CH0L7CgrtOLTfU2oafBhf3M73txyCBu2G2sSJcVfX5CiaxxIZpAHemaUg0L1lMZX15HfFJ28O9/EnPRiTGqnQ7QWxkTIg9byerSA1kJryovsmHdsFcZUurFlfwsafAG0hyLYVdcGi9mE46o9KC905HV4WrLYfq0V9CB6hsK3jAPJDPJAz4xykOKkOBzAsY61nLrCcLQ2uT5d9OlWCKIkRm2R7PegyS0xWisBy3EcRlQUYnjfAjT5Qtiwox4mjseofoXgOUmpzde8tJ5i+0nx1xek6BoHvVcV1IoMQ8+McpDipDSuPuiuFHHo5nly9VGuTzKTaoUgSmLUFr39Hnqe3IwGx3HgOA7toQiqS10xpanz/nyyQPZW+GH6iD6GV/y1IuClAim6xkKvVQW1JMPQM6McpDgpjbUA4PkuRfW6xJzyvG7LkUfpLYzJ6BWulBRiUjlXqr+HHic3o2IUC2QqFR+/PujFmMpCwyr+WhLwUoE83MZDa6HPvaE1GYaeGeUgxUlpwj7AZAGECIBEAgsPmKxSO52TLIwp09LWerKY9oSSQkwq50rn99Db5GZklLZAqvV8phrbf+xAjyEVf60JeKmQi/CtfJk/8hmthT4nQ4vLc+g95FFPkOKkNJwJYDwSK02QtjNOapenZJLEqDeLaTKUFGJSPVe6v4deJjejo6QFUs3nMx3PWoXbWIq/FgW8VJHLw80Yw87DbbGCKSaeg81s0uX8QWgDrRZioKgQZSDFSWk8AwAhWgY40UTFpP2eAUr2SlHSDSHSo8U0EUoKMemcyyghXUZDCQtkVCh9/9t6KZ+qxAmH1azo85muZ81Iir9WBbxUydbDXdcawKZdDfjXt/XwBiModljQt8iB8iKT7uYPQll68lBqec6kqJDcQ4qT0tR+LZUbBwdwPND5ZmYd1fYYk9qVjVStm7kkHUFHzxbTrigpxKRzLkoqzV9yaYGsaw1gy4EWbNheh9rWAMoL7YiIDNUlTnicVsWeT4rtT46WBbxUyVTRrWsNYMOOOny6txkiYxhRVoCQyHC4LYC2YARjKovQ3LG2jR7mD0I5evOga33ONJJxSA1IcVIa7yGp+AMzASwCiJ0mLI4DeKtUrtx7SL0+5ph0BB29W0w7o6QQk865+hbZSPDMY3JhgYx6gWtb/AhERFSXOMFxHGpbA/D6IxhbVQSP06rI80mx/cnRuoCXK6IGt8MtAZh5wF1oB2/iYTdJ16SuLYh9Te0Y2seVs/uTcqq0Raq/RyoRLmWFNGcaGVKclKaoEuA7Lnu4S4EIZgJMJimCr6hSjd4pQjqCTj5YTKMoKcSkcy4SPPMfOS2Qnb3AFW47DrT4YbOYwHNcTCjde6QdbodFseczzrPW1I59R9rB8xwGFDtw4uASw4ZiGdUbFzW4uZ0WHGjxw9JpTOU4Dm67BUd8UhRDSBBlvz/zJSc3X0j190g5wmVUWd7PmaT4J4cUJ6UZdTbwj0LAdzjBTgGItOP/t/fmcXKVdb7/5+y1V/W+pJN0gEAgBJLIYkZRlCh4GUavG8OgcBmXlw5e15fb9arXl46I4ziKOODMRf35uqiA4sbIKCKgjCgQCAECSUjSWXvvrr3qrM/vj1PndFV3dXd1p+rU9n3z6leoOk9VPec5z/Ldnu+DYJ9droWpNISolSymXgoxK/0t2lRKVEqxF5gBEDgOqZwOUeAh8ByiioiZjIaMaoLj4Nn47I34sJkxpPMGknkdFrMQz2p4/mTK9k63YR9uV6OIY3CL+WWIPA/dsKAUGd9kgUcqryOd16veP1tlT26rsJLnsZIIl1ZeM0nxXxpSnLyG45fPmMcLdrkWp5IQolaymHopxKzmt5ppUylZw+pHsRc4ldeRyhs4Hs8hKAkQBA5BRYTIcdBME4mc7tn4nEjm8cj+KSRyGoY6AiSwFmhlAW8xHIObwANdQQWjiSz6RJ+7p1gzLQg8j3hOx5Y1sar1z1bak9sKrPR5rDTCpZnWzEohxX95SHHymqOPAbnppctkp+1yGy7xpk51ZLkQolazmPaEFWxdG8OzxxMYS+bc1Li1EGJWIzA1w6ZSsobVF0conUjlcHAiCwAIKyJ004LEcZhK5mEx4MBEGhv7wp6MTxJYl6YVBbylKDa4rev0IZnTMZ7K2x4ogcNkWoVP5NEf9VW1f7bSntxWYKXPYzURLs2wZlYKzaOVQYqT1xz9M2BqS5cxNbtcGyhOldAqFtMSgd+wAHDoCCjYsiaKjX2hmkxErSYwkTWs/sQCEgZjfvzm+XFYlon1nQFkdRMTKRXJnAa1YM33SzxevbHbk+dBAuvytJKAtxzFBrfZrIbTewMYT2gYS+URz2oIKyIu3tCFV1a5f7bSntxWYKXPo5UiXFaDM4/2hBVkNNM2hgk8gopA82gRpDh5jWkAYMsUYoVyhEOzKwCLCfwTqTx2H4sjFpBqJmC2isBE1rDGgOM4rO0IQDdMWADyhgWfKKA/okDgOfRFfDi9N4SgJEIWvTnImwRWYj7zDW4dQQlhv4juUO2MVa20J7cVWM0Zb60U4bJSVMPCTEbDeELFbE6DYVkQeR5dQQXru/wIKRLNoyDFyXv8seqWayOaVQEggb86kFehcYj4JazvDsAwgNmchlTeTg6xrjOA9Z0BhH0Sjsezni2wJLAS5fDa4NbuHotGYzXPo1UiXFZDMqdjZCoDizH0hn2QRAm6YWE0kUUyp+P03gDNoyDFyXv4Ci2wlZYjGh4S+KsDeRVWRi0TaCiibYUMKyKAEHTLgsTPhXRkVMPTBZYEVsKhXL/3Yl51frc3IuPINI/DU2n0Rfxt5bFoNFbrQWr2CJfVwBjDsZksZJGHxRjkwlEliiSgT/RhLJnDsydMXL65r+3nUVKcvEYOAYK89D4nQbbLES0BCfzVgbwKlVPrBBolikpXEBw39zzqoai0e4gNYVOvxDHzf1fVLaiGiRPxLBRJaBuPRSOyWg9Ss0a4rJZ4VsfJRA6bB6M4NJnBRFpF1CdBFnhopgXdAnjLxNqOQNvPo6Q4ec26iwE5DORmUH6vE2dfX3ex1zUjagQJ/NWBvAqV4UUCjUZUVNo5xIaoX+KYxX53PJWHxPO4cEMn1sT8Le+xaGTa0YO0UhwD71AsgIAs4MhMFjOZuTDstbEARNEO0253SHHymth6INBZUJy4wp9DQZEKdtnliJaABH6bUw0da0RhvdHwcj9dIyoqJCC1J/XaR7rU724o/O5EUsXmwfaelxqBdvMgrZRiA28sICPql5BRTTcMG2BIqQYZeEGKk/ckjgHgANFnh+uxIq8Tx9theqxQrnNDvWpJVBES+KsXQtOIwnoj4fV+ukZUVEhAaj/qtY+U9q8SrUI5A2/IZ6sIjDGMTGfawsBbCaQ4ec30QUDP2UpRPgnkE4BlALwI+GKALwzkU3a5BlacarnxvBVpZ4G/2iE0jSisNwr12E9HigpRb+q1j5T2rxKtAhl4K4cUJ8+Z52HieDuDHscDHGd7oLh55RqMem3AbXZqLfA3ojJbqxAaEtbLQ/vpiHakXv2exhtRD2q11rezgXclkOLkNV0bAckPzI4AzCoK1dOBjApkeSAyZJdrQOq1AbdVqJXA36jKLIWyeAvtpyPakXr1expvhNfUeq2niI7lIcXJa6JDgKgAhmorTuBge5cK/3I8IPnscg1Gqx7k2oiempXQyMoshbJ4SyuGWzT7+CRqT736fSuON6Jx8Wqtp4iOpSHFyWsSx+y9TWBFfyj9N5doyOQQreg9aFRPTaVUosw+eyKBbTwHzWSeC54UyuI9rRRu0ezjk/COevX7VhpvROPSqobrZoQUJ6+ZOgBkJkuz6RXDGJCdtMs1mOLUat6DRvbUVMpyyqxP4vHQixN4aSIFUeBrIngu5RGIBSQMRv147mQCA1EfZEFAUBHAcRyFstSQVgi3aIXxSXhLvfp9K4w3orFpRcN1s0KKk9ekxwAjh5LwPJfCaz1nl2swWsl7UA/rTS1CjpZSZhM5DQfGMxhL5rGxN4T+qL/qgudyHoHJlIpkXsfIlO356vBL6Iv40RtRoBomhbLUkGYOtyDrKrFa6tXvm3m8EY1PqxmumxlSnLwmO4OF4XmY95oVyjUWrbQR1mvrTa1CjhZTZhkYjkznXGt91C9D4LmqCp7LeQTOXRNxhd/t62MYT2gYS+Xx4ngSJ+IiLtnYg1du7CavAbEAsq4SBEHM0UqG62aHFCevkfxY6GmaD1co11i00kZYL603tQw5WkyZzagmptJ5gOPQFZIRVObusxqC53IegcNTafzm+TEEFREbCtf7o36coYagGSbGEnlEAxJ6wsqq7rsaUNKBxoWsqwRBEHO0kuG62SHFyWsC3QB4AOYShfhCucajVTbCemW9qXXI0WLKbCKnYSKlYjDqx/rOwILvPlXBczmPQEiRsOdEEn91epd7nQOHoCwADIj6Jbw0kcK2tTF0hrxXnijpQGND1lWiHGTsINqVVjJcNzukOHlN5+n2gbfWEooTL9jlGpRW2AjrlfXGi5CjcsqsYTL0R3w4ozeEWGDh956q4LmcR4DnOaiGCb7onuNZDUdmspjJaNB0C2lNR3fIh0s8DtejpAOND1lXifmQsYNod1rFcN3skOLkNVoaS4fpwb6upb2ozapp9o2wXllvvAo5mq/MygKHp4/GcWgqDcZY1QXP5TwClsWgiAKsQvbIeFbDcyeSyOgGoj4JPpEH44ATs1k8vG/SM2WFkg40B2RdJYohYwdB2LSC4brZoTgHr4mPFFKRL9b0vH09PuJdncrAGMNsRsNYIo/ZjAa2WPr0Jsax3pzeE0Yyr+N4PItkXsfpPWFcemZ1FuJiBaMc1Qw5cpTZ/qgPnSEFW4aiiPpljExnkFENmBZDRjUwMp05ZcHT8QhMpPIL+gZjDGlVx+k9QaRVA5Zl4chMFhndQG9IgU/kkczrGIz6sWkgjETOVqq86GMr8QAS9cWL8Uk0PvONHUFFnEt00xX0dP4giEageK3vCMqkNHkMeZy8xlABjgPAAYzH3CG4hfe4wp+h1q2K7RQSUWvrTT1Djmrp1l/OIxALKnjlRjur3gtjKYzFcwj7JWiGhXhOQ1CRsL7LD57jPc2QRkkHmguyrhKUYZEgiEaCFCev6d4IcDxgGSgN2SsoUIwDeNEuVwfaMSSilmGH9Q45qqXgWYli1h1S8Mf9U3hxNAnwgCwIGIgGsL7Lj6jfbnMvlRVKOtB8NHtYMHFqkLGDIIhGghQnr4kM2ckfzMXCCph9PTLkabUA2v9RK+q9obOWgudyillvxIfXbOrBVEaFT+IR9dup0TnM9R8vlRVKOkAQzQUZOwiCaCRIcfIaNQkY2tJlDM0u5zEUElE7WjnkaDnFrCMoY2NvGAcnUwjKpUqT18pKvT2ArQClhCa8hIwdBEE0EqQ4ec2RxwBmLF2GGXa5wa2eVMmBQiJqS7uGHDWaslJvD2Az0077H4nGoNHmD4Ig2htSnLxm6qXqlqsiFBJB1IpGU1Za2QNYK9px/yPRGDTa/EEQRPtCipPXmBVmy6u0XBWhkAiiljSastKuHsDVQPsfiXrTaPMHQRDtCSlOXtO5obrlqgiFRBC1hpSV5sLZzzSRzOPARBJ9tP+RqCM0fxDtBu0pbTxIcfIaf2d1y1UZCokgCAIo3c80ldawfzyJ07vDGO4OIBYoFV5p/yNBEI1IMysetKe0MSHFyWvURHXL1QAKiSCI9mb+fqaALOJEPIdj8SzSqoFz10RKlCfa/0gQRKPRzIoH7SltXEhx8hqpwo5eabkaQSERBNGelNvPxMAwGPXjZDyDjKbjyEwWUb9tTKH9jwTR3jSiV6eZFQ/aU9rYkOLkNYZe3XJtQiNOzET9oP5QO8qd58aBw/ouP5I5HbNZFWPxHIa7ghB5jvY/tjE0DolG9Oo0u+JBZ2o2NqQ4eU38WHXLtQGNODET9YP6Q21Z7Dy3qF/GlqEIDk9mcXAyhaMzGXSHFNr/2KbQOCQa1avTbIrHfANEXjfpTM0GhhQnr0meqG65FqdRJ2aiPlB/qD1LnecW9cs4o49D2C/i0jN70RtRyMvQhtA4JBrZq7OY8cehkRSPcgaIqF+Cqpt0pmaDQq3uNXz5gbzqci3M/Ik5qIgQeM6emLuCSOQ0PHciCcZYvatKeAD1B29wznObSOUXtCVjDJMpFRt7wzizP4SOoExKU5tB45AAVubV8Zpi4085GkXxcAwQBydTiPgkDMUCiPgkjCXzmExpODiZLjsHT6TyWBML0J7SOkGKk9eEB6pbroVp5ImZ8B7qD97gnOcW9csYmc4goxowLYaMamBkOkP7mdocGocEUJlXRzOtU/LqMMYwm9EwlshjNqNVrIwvZ/xpBMVjKQPEhq4gIn4JqbyBw1NpmoMbDArV85q+c6pbroVpJnc7UXuoP3gHnedGLAaNQwJYOqQXOHWvzqnsoXOMP1NpFSPTmZJw0kZJZrOcAeK07iBOxHPojwSQyGtVmYMpmUt1IMXJa4YvAaQQoKcXLyOH7HItyEoGbq0nZqK5oP7gLfU8z40W+Mal2cch9a3q4Hh1Dk6mMCwHS9rwVI8oqMYeukY3/lRigFAkHhdu6IBPEk65v1Iyl+pBipPXxNYBkUFgev/iZcKDdrkWo9zAHYz6sbYzgIhfWjAp1HJiJpoP6g/eU4/z3GiBb2yaeRxS36oetfLqVDPpRD2NP8tRqQHCJwmnPAdTMpfqQoqT1ySOA6YKgANQLl6Xs68njgOdw97WrYaUG7jjyTx+u3cMmmFhuDuIzqBcsohVa2ImC2Nr0AzhF8SpQQt849Os45D6VvWphVen2qnE62H8qQSvDBCNnP2wWSHFyWumDgCZKZRXnDj7Lzttl2sRxancwI1nNRyazMBiDBZj0A2GsE9csIid6sRMFsbWotHDL4jVQwt889Bs45D6Vu2otlenXfbQeWWAaLYzrZoBUpy8Jj0OGHkA5QY9s//0nF2uRZg/cBljODKTRUY30Bv2QTMszOY0ACEMdy1cxFY7MZOFsTVp5PALYvXQAt9cNNM4pL5VW6rp1Wn2PXQrwQsDRLsool5CipPXMAtg5c8WmCtj2uVahPkDN6OamMloiPrsRVYSeRiqDt20wHFi2UVspRMzWRhbm0YNvyBWDy3wzUezjEPqW81DM++hWw21NkC0kyLqFdRSXlPpoYAtdHjg/MPodMuCUQibAwDdsCDyPKTC62qc/0BnjRBEc9Esh1ZWg9WeT0OsjnbqW81OO54j5xgg+qO+qh8q3gxnWjUb5HHymtxMdcs1AfMtSBLPQxR42wLI8YjnNAxEAwgqtjWwGosYWRiJVqVVk520i6WZ9l16T7v0rVah2fbQNTLNmsylkSHFyWtMrbrlmoD5A7cnpKDDL+NYPAuJB0I+Geu7/ODAVW0RI/c00Yq0stDdDgs87busD+3Qt1qNZtpD1+iQIlpdSHHymlBvdcs1CfMHrijacaI8L+D0ngBCioSMalRtESMLI9FqtIPQ3coLPO27rC+t3LdalWbZQ9cMnIoi2qpRDquFFCevMdTqlmsi5g/cZE7HsdksTsZzOB7PVnURIwsj0Uq0k9DdqpZmyuxWf1q1bxFEJaxGEW3lKIfVQoqT15g6bF/LUntr+EK51qN44PZHfdjYF6rZIkYWxsaGrFiV025CdytammnfZWPQin2LIGpBO0Q5rAZSnLwmOgSIMmCZgGWg9BBcDuBFgBfscm3AahexSoVusjA2JmTFWhkkdDc/tO+SINqPZjUQtlOUw0ohxclrNl0JhAeA+HGAlwBLh608cfZrxoDIoF2OKMtKhW6yMDYWZMVaOSR0Nz+075Ig2otmNhC2W5TDSqBV1mtEGdjyNoBjgKXBVZpQeM0BOPetdjliAY7QfXAyhYhPwlAsgIhPwsHJFB7eN4mJZL7eVSSWYL4VK6iIEHjOtmJ1BZHIaXjuRJLOtZkHncXR/LTj+TQE0a40u6xSSZTDqZ632ayQ4uQ1lgWoKUCJAJwAV2kCZ79WwoCatssRJZDQ3fzQwcSrg4Tu1sDZd3l6TxjJvI7j8SySeR2n94Rx6ZnkaSWIVqAVZBU6NHpxKFTPa+JHgZFHATkASEH7oFtm2kqTv9P2RB35o12uc7jetW0oyHXc/NBendVDyU5aA9p3SRCtTSvIKhRavDikOHnN9AEgMwHoKmCqcJNDMBPITgGCApiGXY4UpxJI6G5+aK/OqUFCd2tA+y5PnWbddE/UD6/6TCvIKnSky+KQ4uQ1jAFqxj6nieMBnsPcHicLMDMAM+xyRAmtKnS3kwBAVqxTh4Ruot1p5k33RH3wss+0iqxCUQ7lqftT+/a3v43h4WH4fD5cfPHFePzxxxct+/zzz+Mtb3kLhoeHwXEcvvGNb3hX0Woh+exMesy0/zXygJGz/3XeN3W7XJPAGMNsRsNYIo/ZjFazuN1W3CA/kczjoRcncd+ek/iPZ0/ivj0n8dCLjb9xdLXQXh2CIE6FZt90T3iP132mlWSV3ogPr9nUg78+bxBXbhnEX583iNdsau/9mHVVnO666y589KMfxec//3k89dRTOP/883H55ZdjYmKibPlsNovTTjsNX/nKV9Df3+9xbauEnoftYbIwdwiuIyQ673GFco2Pl4J/qwnd7SoA0Ab51sArgwlBOLTCpnvCW+rRZ1pNVnGiHPqjPnQE5aapd62oa6je17/+dbznPe/BDTfcAAC4/fbb8R//8R/47ne/i0996lMLyl944YW48MILAaDs9aaAmQArKEduKnKUvmaWXa7Bqcd5PK3iOm73w+Vor05zQ6FShMNKQo1PNSy5FTbdE95Srz7TKrIKsZC6KU6apmHXrl349Kc/7b7H8zx27tyJxx57rGq/o6oqVFV1XyeTyap996rQcgCYnUWP40sVJE4oKFWsUK5xqafg3wpCNwkAtFenWaEDjAmHlSjQ1VC2W2HTPeEt9ewzrSCrEAupW6je1NQUTNNEX19fyft9fX0YGxur2u/cdNNNiEaj7t/atWur9t2rguMBQYJ9bhMPCLL9WpDt1+CK/r9xqfd5PM3uOqbD5YhmhEKlGhsvwydXEmq80rDkxe6DzpYhVkq9+0yzyyrEQlo+q96nP/1pfPSjH3VfJ5PJ+ipP4V7AFwPUpL2PyfEwOYqU5LMPxw331q+OFVBtK047ZZYDWifrDtFekKe0cfEyfHIlEQcAVhSdsNR99IQVyspJrAjK5EpUm7opTt3d3RAEAePj4yXvj4+PVzXxg6IoUBSlat93ygxdBESHgNFnCinHnT/Yr00diK21yzUw1RT823G/BE3mRDNCoVKNidfhkyuNOKi0rG5ay94HnS1DrAQ6j4ioNnUzZ8uyjJe97GV48MEH3fcsy8KDDz6IHTt21KtatYfjgUAXYBkATLhKE5j92jIAf2fDh+pVK91mu2aWa7WsOyuFMrI1J/UOeyEWUo/wyZWEGldaNq+bFd1HT1ihrJzEimjWTK7Nuk42a70rpa6heh/96Edx/fXX44ILLsBFF12Eb3zjG8hkMm6Wveuuuw5r1qzBTTfdBMBOKLF37173/0+cOIHdu3cjFArhjDPOqNt9rIj4UWBi7+IH3DJmX48fBTqHPa3aSqiGFYcyy7Vn1p129DC2CuQpbTzqET650oiDSsrmdbPi+6BN98RKabY+06zrZLPWeyXUVXG6+uqrMTk5ic997nMYGxvD1q1b8Z//+Z9uwoijR4+C5+cslydPnsS2bdvc11/72tfwta99Da9+9avx8MMPe1391TG5D0iNwfYw8Zg7ywmF18y+PrmvoRUn4NQFf9ov0XyT+alCGdmaGwp7aTzqET65UgW6krKO56nS+6CsnMRKaZY+06zrZLPWe6XUPTnEBz7wAXzgAx8oe22+MjQ8PNz8Lr+pfYCpoWRvk0thYTM1u9xZl3tcuZVzKoI/7ZewaYbJvBrJO9rdw9gqtKuntFGpR6KZlSrQlZSVhNZJmNNuyY6I6tGs62Sz1ns11F1xajsECQsVpvmwQrnmYLWCP2WWaw6q5XonD2Pr0G6e0kamXuGTK1GgKynLGGuJMNB2CFUiakezrpPNWu/VQIqT17AKBYtKyzUxtF+i8amm6508jK1FM3hK24F6hk+uRIFermwrhIG2S6gSUTuadZ1s1nqvBjLlew1fYZNXWq6JaffMco1OtbN1UUY2gqgN9cwatpIDPpcr26zZzwA6HJqoDs26TjZrvVcDeZy8RqzwTKlKyzU5tF+icam26508jARRO1olfLJZ76OdQpWI2tGs62Sz1ns1kOLkNWqquuVOgUbZwNqsC2WrU23XeyuE4hBEI9Mq4ZPNeB/tFKpE1I5mXSebtd6rgRQnr8lOVbfcKqnlBtbVKGTNuFC2OrVI3kEeRoIgWhFKdkRUi2ZdJ5u13iuFFCfPqVTbrp1WXssNrJRRqHWoleudPIylNIrnlyCI1TN/vgSAjGpCtyyIPIfJVB5n9EZaIlSJqD3Nuk42a71XAilOXrPmguqWWyG1zLVPGYVai1q63snDaEOGBoJoDYrny2dPJJDXTaTzJnK6gaxuYjDmxys3Nv8ZNoR3NOs62az1rhTyGXuNLwxw5WOgXTjBLlcDVrKBdSVQRqHWpJmzXDU6jqHh4GQKEZ+EoVgAEZ+Eg5MpPLxvEhPJfL2rSBBgjGE2o2EskcdsRqM5fAl6Iz6cuyaCVN7A0ZkscoYBnyxgfWcQEZ+E504kaVwTRJNDHiev0XJYNgyP4wrlqk+tNrBSRqHWpR1c717TTqesE80LeURXBmMMYwkVAzEfzhuKwrAYJIFHUBEABhrXBNECkOLkNdlJAMsoJcwqlKs+tdrA2owZhWhvSeW0uuvda8jQQDQ6FHq9cpxx3Rf2LVxfOdC4JogWgBQnr2EWsFyoA2N2uRpQqw3/zZZRiCypRD1pRkNDNVnKaEEGjfpDHtHV0e7jmiDaAVKc2oxabfhvpsPPyJJK1JtmMzRUk6WMFgDIoNEAkEd0dbTzuCaIdoEUJ8+pdMKs3cRai1z7zXL4GVlSiUagmQwN1WQpo8XhqbTtbAcjg0adaSTPSTN5INt1XBNEO0GKk9cEOqtbbpXUYsN/Mxx+RpZUohFoFkNDNVnKaLFeDuB3L0yCA8Nlm3rB87x7jQwa3tMonpNmC6lux3FNEO0GKU5eo6UALJfOlRXK1ZZabPhv9AxsjWRJJdqbZjA0VJOljBZZzYLFGDjGkNUshHxzAjkZNLynETwnzRpS3W7jmiDaDVKcvGZmpLrlGpBGzsDWKJZUggAa39BQTZYyWuimBY5jAOOgWwuNFmTQ8JZ6e06aPaS6ncY1QbQbpDh5DcfBPsdpKa8TVyhHVJtGsKQSRDGNbGioJksZLSSBB2McODBI/EKjBRk0vKeenpNWCKlul3FNEO0GKU5eM3QRKgrVG7rIi9q0HfW2pBJEu7KU0SIg8+A5Dhxn/38xrWzQaPTEB/XynFBINUEQjQopTl7DVWgxrbQcsWIoBp0gvGc5o8VZfSEwBhyZybaFQWO1iQ+8Vrbq4TmhkGqCIBoVUpy8ZvLFysud9qra1qWNoRh0wisa3avgJcsZLQC0hUFjtYkPmi3L3GqhkGqCIBoVUpy8JjVa+J/F9jkV3nfLEbWCYtCJWtMugu5KWM5o0eoGjdUmPmjWLHOrgUKqCYJoVEhx8prwAJZODsHs6+EB7+pEEETVaSdBd6UsZbRodYPGahIfNHuWudVAIdUEQTQipDh5Td85gCADprp4GUG2yxEE0ZS0o6BLVMZqEh+0Qpa51UAh1QRBNBqkOHnNmgsAXlxGcRLtcsSy0P4RohFpV0GXWJ7VJD5o5yxzre6BbARoHSWIyiHFyWtOPAlY+tJlTN0uN/xKb+rUpND+EaJRaWdBl1ia1SQ+oCxzRK2gdZQgVgbNsl4zthcwtaXLmJpdjlgUZ//IwckUIj4JQ7EAIj4JBydTeHjfJCaS+XpXkWhjigXdcpCg2744iQ+ifhkj0xlkVAOmxZBRDYxMZ8omPnCUrYlUHoyV7o91lK01sQBlmSNWBK2jBLFyaNX2muSJ6pZrQ+bvHwkqIgSes/ePdAWRyGl47kRygYBBEF5Bgi6xFE7ig9N7wkjmdRyPZ5HM6zi9J4xLz1yYNGQ1yhZBLAWtowSxOihUz2vMCi04lZZrQ2j/CNHoUDplYjlWmviAsswR1YTWUYJYHaQ4eQ2r0MlXabk2hPaPEM0ACbrEcqw08QFlmSOqhbOOKhKPtGpANy1IAo+gIoADR+toAUqcQcyHFCev6Tu7uuXaENooTTQLJOgS1YayzBHVQBF5qLqFp47EkdEMGJYFkefRFVSwvssPkefbfh2lxBlEOUhx8prODQAnAWyJzHqcZJcjyrKarFQEUS9I0CUIotHQDBOTKRVHZ7LY0BWALEnQDQujiSwSWQ2xoIzzh2Jtu47SAebEYrSvKaFe+GNApB/gyoeZgRPs6/5YxV/JGMNsRsNYIo/ZjNbymzlpozRBEARBrA7GGJ4/mULYJ2Kow4+EakAz7FC9qE/C8XgOyZyOzYPhtlxHa5k4o93ktVaEPE5eo0SAvnPt/89MAYYOwALAA6IEBLvt60qkoq9rVFdyreOCaf8IQRAEQawcJzHE6T0h6KaFIzNZzGQ0pPI6RIHH6T1BxAISZHERA2+LU6vEGY0qrxErgxQnr4muBYYuAAwViK4H4ocBQwNEGYhtsP9de6Fdbhka1ZXs1eRA+0cIgiAIYmUUJ1gKKiKifgkZ1YRuWZB4Hj6Jx4lErm0TQ9QiAVWjymvEyqFQPa/heeDsqwBfDMhOAuABQbT/zU7aIXqb/toutwSNegaD1wfqOftH+qM+dARlUpoIgiAIYgnmH9DNcRxCPhEdARkhnwjVsNo6MUS1DzBvVHmNWB3tOSoaAS0J5KaBfBzIJ+1/c9Ng+SQSOX3Z+NeVuJK9olEmB4ohJgiCIIjy0AHdS1Pt9mlEeY1YPRSq5zWWBTz5PWDqAODrAEI+gOMBZsHQctDG9uHEg7fhsTM+AlkUFw1xa8SzjBrhQD2KISYIgiCIxaEDupem2u3TiPIasXpIcfKa+FFg5FE7e16wFyiMO82wENdkyOYEBmefxBnSLOLK4KLxr414llG9J4fFYohfmkjiyHQGF27ocK1E7bogEARBEAQlWFqaarZPI8prxOohxclrpg8AuTgQ6nGVJgYgoxnQTAZejsKvTSOUOQw9sg7DchAj0xk8dyKJ14QVV+BvxLOM6jk5zA8TdNpDNy2k8ib2T8SxbzyFzQMRrOkgDxRBEATR3lCCpaWpVvs0orxGrB5SnDyHm/cvkNNMxLM6LMZgWgYE08LIVA6IaYj65bIhbo3oaq/n5FAuTDCetfdUZXQDfWEFusUgCBxlsSEIgiAI0AHdxSx2jMqptk8jymvE6iHFyWu6Tgf8HUB+FuD7oOeTyGWy4A0OnBhCmKWRFyPYp3dDO57ElqEIQopUNsSt0Vzt9Zwc5ocJMsZwZCaLjG6gN6SAgeFkPI+sZqI7pGAyrS7w4hEEQRAE0X7Uen90o8lrxOohxclrYuuB4b8Cnv0pWHIUvKkjxhiiAExDhC4GcbDjlZC7NmA2reHIdA6n9XCLhrg1mqu9XpPD/DDBjGpiJqMh6pOQ002cmM1hJqsBYAgqEoKyCMNMYtu6GFnbCIIgCKJN8eqMpUaT14jVQYqT1/A80LUR0DNgRh4c7FSXHACOWYDJYda3DuAFxPwyptJ5iDxw7prYoiFujeZqr8fkMD9MULcsGKYFQ+BwdDqLqbSGgagPg1E/dJNhOpPHyUQOJ+LZhmo7giAIgiC8YbH90UFFXHSP+anQaPIasXIohYfXmAaw527A1MGB2QqT+8fAWwY2Td4Py9BhMoaJlIqALDZd/KvXB9M6YYJRv4yR6Qx0wwLPzSlN3SEZgzE/eJ6HIgno8MvQTQuHJrJ0zhNBEE0JnVlHEKcGnbFErBTyOHnNsb8A488ClgG4/qY5BBjozb6E8OQuTAbOR3/Eh1edSUkMKqE4TPD4bAZ53cRoMo+1MT/WdATcTH+MMSRUA+s7A4jn1JqeK0UQhM1iG6+J1UFn1hHEqVPvY1SI5oMUJ68Z3wvoOaAoRG8+MsvjwsAotM4dOHcwio19IU+r2Mw4YYKzmSg6gwqmsypkkQfPAZbFoJkWEnkdQUnEGT1hpDSdJsQWox0E9Ga7RxLyq4tXezIIotWhM5aIlUKKk9ekTqJYaSoXWMGBgU+NYeA0P7YMRRtaIGpEJlNqQUjLQeA4xLMa0qqBiE9C2C+hP+LD+s4AJIGHatKE2Eq0g4DebPdIQn518XpPBtEcNJsxpVGgM5aIlUKKk9cEukpeLqY8+Tv6cSmF6K2YYiGtL6Jg80AMx2YyYBwHReRwZm8YgzG7TUemMzQhthDtIKA32z2SkF99VrIng0KQ24NmM6Y0EnTGErFSyNTuNbnZBW+VG46bohpNeCtkvpAWUiRs6AmgI6hAFgDNZJhMqcioBkamMzQhthDzn31QESHwnC2gdwWRyNmHIa9m83yjbMCv5T3WCtp4XX0q2ZOhmRaFILcJjjHl4GQKEZ+EoVgAEZ+Eg5MpPLxvEhPJfL2r2PA4+6NP7wkjmddxPJ5FMq/j9J4wGbCJBZDHyWtmj5R9e4HoPnu05lVpNcoJaVG/jC1DERyZzuFkIoeDUymE/QI29kbIGtdC1MoK30iW3Gb0NHi18bqdwpRoTwbhQB7d6kFnLBGVQoqT13DlBYhVlyNcFhPSbOVJwvquAI7OZHHpmb04sz9ME2KTUIlQXAsBvdHC4pox+5MXQn4jKbdeQHsyCIdmNKY0MnTGElEJpDh5zcbXAs/+uLJyxIpYSkjjwEHkOXSHZPRGFi4yRGNSqVBcbQG9ES25zehpqLWQ32jKrRfQngzCoRGNKe3k/SXak8ZZYduFc/47oESXLqNE7XLEinCEtIlUfsE+D0dIWxMLkCW2SVhJ7H61n30j7s1pxv49/2DqjGrAtFhV9hk2456vakF7Mgig1JhSDq+NKRPJPB56cRL37TmJ/3j2JO7bcxIPvbj6fVaNsr+UIIohj5PX8CLQfx5w5I+Ll+k/zy5HrAiyxLYOK/X4VPvZN6Ilt1n7d/HB1CfiWUxlVMgCj9N7wqcUTtfuYUq0J4NopLDNant/2y0El2geSDr3mvgRIH4U4HiAlRG6ON6+Hj8CdG7wvn5NTq2ENMJbViMUV/PZN2pYXLP271oI+Y2o3HoN7clobyoxpmweDNdcua52aHM7huASzQMpTl4ztc8+BLec0gTY76dG7XKkOK0KssQ2P6sViqv17BvJkjufZu3f1RbyG1W5JQgvWcqY0h9V8PzJVM29NtX0/jbi/lKCKIYUJ6+Z2AdYy+yLsDS73JlXeFOnFoQssc3NqQjF1Xj2jR4WR/27sZVbgvCScsYUzTDxyP4pT7w21fT+tnsILtH4kCnOa/RcdcsRRAvSCIkQaAN+Y1PLxBME0Ww4xpT+qA+xgITnT6Y8S5xSzSQVdMAz0eiQx8lrhAoFvUrLEUQL0igen2YNi2sXmnXPF0HUEq+9NtX0/lIILtHokOLkNZVaeCjtJtHmeCUUL3fuCIXFNTak3BJEKV4nTqmmoYtCcIlGhxQnr8lOVbccQbQwtRaKKeVta0DKLUHMUQ+vTbUMXY0SbUAQi0GKk+dUOthpUiAIoHZCMaW8JQiiFamX16Zahi4KwSUaGVKcvKZvc3XLEcQiLBeC1s60S8pb6gME0X7U02tTLUMXheASjQopTl6z7uUAL9spxxeDl+1yBLFKKARtadoh5S31gfKQMkm0A63gtaEQ3Dlo3mocSHHyGo4HRAXQllCcRMUuRxCrgELQlsfrzdNeQ32gPKRMLg0JZ60FeW1aA5q3GgtSnLxm+iDALNhHaJUTygrvTx8Euk7ztm5E09MuIWinSiunvKU+UB5SJpeGhLPmw7IsHJnOIqUaCCsi1ncFwPOlcxZ5bZobmrcaD1KcvCYzAVgGwIuAZaJUeeIBXgBM0y5HVJ1Wt6i2QwhaNWjllLfUBxZCyuTSkHDWfOw9mcBvnh/DwckMVMOEIgo4vSeIyzf345zBaL2rR1QBmrcaE1KcvCbQZf/LHKWp+Lwmy37JcXPliKrRDhbVVg9BqxatnPKW+sBCSJlcHBLOmo+9JxP43qOHMZPVsSbmQ0D2I6sZeO5EEidnc7jhlRtIeWoBaN5qTJovDqXZUUK2YsRMlCpNsF8z076uhOpRu5bFsagenEwh4pMwFAsg4pNwcDKFh/dNYiKZr3cVq0JxCFo5mjkErdo4m6dP7wkjmddxPJ5FMq/j9J4wLj2zeS3s1AcWUokyqZlWWymTDisRzoj6Y1kWfvP8GGayOjb1hRDxyxAFHhG/jE19Icxkdfzm+TFYVvv15VaD5q3GhDxOXiMFF+pLC+DsckRVaCeLaiuHoAHVD7Vsxc3Trd4HVkMr72k7VchD2Vwcmc7i4GQGa2I+cPP3M/E81sR8ODiZwZHpLDb0kAG2maF5qzEhxclrZkewrObELLvcmm0eVKj1aSd3dyuHoNUq1LLVNk+3ch9YLaRMLg4JZ81FSjWgGiYCsr/s9YAsYjSZR0o1PK4ZUW1o3mpMSHGqB2yh5c4CcEIUcEQSYXEi/MnDCE2/gKyRRUgKISAFAAA5I4egFMRAcAB8BSnLLWZhNDOKjJ6BX7Qn2qyeRVpPwy/6kdEzSGtpHEocwnRuGmE5jO2929Ef6odqqghKQfQF+jCeHUdGz5S8TmkpZPTMgvr5RT8sZuFw4jBGEiOQeRmMY+j0daI30Ist3VswlhnDrvFdGMuOQYQIgRPgl/3YGNuIrb1bwXM8RjOjSGtp93dm8jMAgA5fBwJiAHkzD8YYckYODAwcOKwNr0XezEMRFBxPHQfP8eDMMPJ6F7pDMmbUMeSMDFQrCwkyprUxWAzIqX6k1E5k2STSWhppPY2gFERYDqPH34M9k3uwf3Y/JrIT6PH3oNPfiXXhdcibeQSlIIIFD2Fx22b1LLJ6FtP5aQBAl78LG6IbMBAcwGhmFEeSRwAA68LrwHGc23bFz7kv0OeWtZiFgBhAWA4jJIfcPuA84+J6bxqSMTEbxGgij8l0Dnk2jWjARFcnh2k9jaNjGaS0FEaSI1AEBWE5DN3UkTftkMWoErWfiegHx3Hwi36EpBCyRrbkfsv1R8My8PTE0zgUPwRZkDEQHIBmaeA5HmvDa8EYw+7J3VANFafFTsO2XttA8MzkM5jKTcG0TASlIARewPrIegwEB/Dc2Ah+/cIeTOam0B/sQlgJIW/K2HPoKP5wQsIrNgzjjO4BnEifcNuUgeFY6hgAYH1kPdaE1ixor5SWQtbIggMHRVCQNbJIqAlE5AjyRh5xNQ7VVLEmtAb7Z/cjq2exJrwGb974ZvjEUmWt+L4VUcH23u0YCg+5v3kifcJ95mvDa8FzvNtfnL42EBwAgJLn6Rf9yBk5+AQfjqaOIpFPQBEVDAYHkTNzSKgJRJUoQlIIITlkf094AJee1YM9x+N4ceoI0noaFssiHGDoCwdxKH0Cj46dxGRuEt3+bqwNr7W/Y16/OpY6hqfGn8J4dhz9gX5s69uGgeAAnpl8Bvtn92MyO4kefw+iShSqqcJgBk6Pnl4yhmfzs9gzuQeTuUlE5SguGboEIi+WfTaLzWFHkkfwyLFHkNSS6PR1Yig0BIEX4BN9CEpBt32OpY6B53h0+btwfs/5EHnRfd6B0CzYTB6HJg0o/jQYl0dSTSGd5aAL04haIfxmRMb6yHpElEjJvFc8px1OHIYiKOjwdZSdA3JGDoqgYCIzgUPJQ5A4CZIguc9ye+92DIYGMZ4dR1JNYiQ5grgah0/wYSA4ANVU3bmuy9+FdeF1GM+OYyQxsmi/GkmMYCo3BcM0cCx1DGkjjbAUxtberTij44ySOce0TOSMHDiOQ7e/G+d2nQufP4nnJyfQGTKhWXlwnIBuZQCMMTw/dQj9ET/2J8ahzqrgOd4dl8Vzk1/wI2fm3OvFz3T+OuT0reLn7/T7+euM83ogOACLWSVjbGuP3c+Opo6CMQZZkKGaKgBA5EW8OPUiTmZPIigGsTa8Fr3BXmyIblj294rryBiDxEs4kT6BqdyUO17CchhJLYnjqeOYyk2hN9CLrb1bIXACjqaOLntvx1LH8NDRhzCaGUVfoA9burcgokTsNVlPI6Em0OHrwHBkuGR9SBtZaPxxHMnokCUdqpWCwkUgcCIy1jQyWg7g+uGXNpZd/+fP2YZlYPfEbrwUfwl5I48N0Q0Yjg7DtEw8cvwRpNQUuvxd2NKzBbqlu/NMORmkuD9O56cRU2IISkFE5AhCcsht44SawNHkUcyqswiIAWzt3Yo1oTUlz7vH34Nnp57FTH4Gnb5Odzw7c+0zk8+UvbaUzLPY2lX8fIrH+qH4IWimhr5gH7b3bXfnbQDQTA2/P/p7jGfH0ePvwTld50A11QW/U/zbftGPyewkpvPT7phJaAmE5TByRg4pLQW/6MeW7i2Yyc9gVp0Fr4QQknuxZ+wQQn4LESUEH9eFqbRWYgSbv8Y4a6AzZ/kEHzp8HRgIDmDP1B6MJEagmzqGQkPoCnShy9+FoBhEWk/jcOJwyX3PfzbzZY/5Y2i+DFWujReTH5oBjjG2bOBYrfn2t7+Nf/qnf8LY2BjOP/98fOtb38JFF120aPl77rkHn/3sZzEyMoKNGzfi5ptvxn/7b/+tot9KJpOIRqNIJBKIRCLVuoXKefanwL3vKexxsjkkibgnFMSTfh+mBAF5jgMTfRClAHyCD4qgQOAFyIKMLn8Xuny2AH7ZustwWmzxlOWH4ofw4NEHcThxGNP5aUznpqGZGkzLRN7KQ9VV5M08NEsDK/KC8eARkkI4LXYaYkoMqqlCERTIggzN1GwByTIwm59FzsxB4AQInF0/v+hHQk1gKjeFvJGHwQz3uwVOQEgKQeIk5Mwc8kYeJubagQOHgBjAUGgIZ3aeiZSWchU6zdRgMhOc8x/HuZMFYwzg7HqLvAiBF2BYBhhjEHkRATEIiXWix7cGBrKYVkeRNuLQTEfhEiByCmL+ELp8HcgZOeTMHPyCHz7Rh6ncFGbzsyXtxIGDzMsISSEE5SAEzg5zcdvWUKGZGgzLsOvN2YJ5h9KBkByCaqpQDRW6Ze8bCMthRJWoLdCAQ6e/EzIvYzY/i6SWREpLIW/mwYFDh68Dp0VPw3k95+HMjjOxf3Y/9kzuwfHUcbfeQ+EhnNd9HgYCp2H/7H7sjz+HsewJpLU08mYeeSMP3dLBCv/Nx2lnniu0KSdA5ET4RB8UUQHP8fAJPnT6O0v647HUMfz7nn/H4eRh+/la9vMVedFdkDRLg8UsW1kRFXT6OqHwCuJqHEktCd3SwXM8glIQMSUGmZcxlUkgpSdhQQcDwIMD4wAOAGN2X5B4HrIoQ+REGMy2toqcCImXEFWiuKDvArx88OVuex2KH0JcjcOwDFjMglkYkwwMJjPLtovTNhE5gms2XYMbt90IAHjk2CPufauGCo7jEJJC2DG4A5cPX44/n/wznhx/Egk14T5zRVQgQIAJ031mQ+EhgAHH08dxPHUcST0Jw7TrlzNy9ngqmrI5jgMPHhzHQeRFdPu7S/vGzH7sGt+Nw4nDSOpxWJYJgxn2+Ci6P5GzP3tW51nuZ38z8hv88cQfkdJSYIyB4zj4BB8kXkLOyC2YNwBA4iT4RB8GQ4M4M3YmDicP48DsAaiW6rYdDx4+0Qe/5IfEzT2bt531tgXz2aH4IfzLrn/B46OPI1cYr873SLwEiZcgciLAAaqpumPemb8uW3cZkloShxOHoZoqUmoeM9kMcpqGjJlAzkzCYHmwQqIep9+tCa1BSA5BERRolobR9Cimc9PIGTm3bzh1CMpBhKSQOyYAYCw7hqyehWVZMGC486rES/BLfvT5+yAJEo6ljiGjZ2AVGdM4cPb3c5w7rzjtz3N8ab8a/TP+68R/YTwzXtI+xd/VqXSi298NzdIQV+Pu74m8iKAYREAKICiGMZ6JI2skAI5B4CSAMZgM4DkAnAGTGYX51DbeOEpKWksjq2dhONelALp8Xbiw/0K87cy3AUDJOnQyfRJpLW1HpBee/8bYRkSVKBJaAqqpuuuMs+4oggIA2D+zH6PZUaiG6j4DWZAh8iJUQ3XnWtMyobOFe7IUXsFgaBDndp276O85zzulpWBYBvLG3Brp/KbACRB50Z3fnecr8qJbX4mXEFEiOLPjTETl0t8aSY7gZPokNEsreVYyL4PnePc7RV6EzMvo8HUgqkSRN/LIm3lMpNLIW2mAMwpP3HLrxhgPmVOwITaEMzvOBDhgOj+NmdwMGFiJDBGRI/jVwV+5ShMDg8AJtkLF7HnH6VM8eNeQOBQewnk955XIIIfih3DP/nvwXyf+C5O5Seimvb5IgoQupQt9wT6IvIiUlnL7vfN7ASmAvkAfBoIDkAV73RvLjEEzNfc71oXX4dqzrwUA3PnCnTiaOgrd1EuurQ2vXVTmMWGWyCpOO0SVKMCAhJbAdH4ao+lRTOWmkDWy7nMQICCshHHJmkvw7i3vxhNjT+D/e/7/s40VhbnUmXcUUXF/B4D725ZlIWfmoJs6DGtuDnbGuwULPHjb2At7PvdLfoi8CBEyAkI3BBYEBwk9ylq8cvA12HnGFvRGfG7bPzH2BJKqvYYazIBu6rYcUlgPF1vTnOfLgYOF0mcelIIYDA5iIDTg9u0N0Q2u7OHMrc4YMi0TM/mZElnEWdecNp7OTbtyTqXybK1ZiW5Qd8XprrvuwnXXXYfbb78dF198Mb7xjW/gnnvuwb59+9Db27ug/J/+9Ce86lWvwk033YS//uu/xg9/+EPcfPPNeOqpp3Duuecu+3t1V5z2/Rr40d/BCdc7JIn411gEz8sKDAAqz0HjOGiCBIvjoPAKWGFBjygRxJQYNsY2Imfm0KF04Nqzry3b2Q7FD+HOF+7ErDoLv+DHgfgBWzBVk66ikTfysMqeJWXjF/3okDtgMANRJYrToqe5iozJTITlMCRewmR2EgwMfskP1VAXKEwOHGw381KD11GKJF5CRLKtb6qpuvVcSph1Br3zWuIlyLxcsNapADiExAgYY0gbCVgwwUOAc3YWx9nCSYfSgU5fJ2byM5hRZ2BaiwvRAuxJuHBr7j2qpupOus5Cy1hBSeEAn+BDj78HSTWJnJlzBd+QFHKFwZyRQ1yN29e4gjWtkHmxy9+FmC+GlJZCRLbbybAMKIIC1VRdASalpRCWw8jqWeT0HBJaAmk9veQzKHufhUVAERT3GYWlsN0fO+z+mNNzOBA/gISasBde04DGtJLvcNpE4myBUzVU18ulCIqrCFvMcpUCZ9IXIIFxDAbT4YwfrpDfhsFyFxsRoi2QcEBQCqLX3wvNsid1iZfQ7e/GbH7W7ce6pS+pKM2HBw8LFiRewrvOfRfO7T4XX3n8K5jKTUHiJfc+HE+W4z1TBAUyL2M6P20vyqYJWZDRF+yzny2z7LZggE/0wbAMZPQMckbOVTyc/lRcV1fJ5XnIvIwef09J3yi+V83S3GdQjNNHe/296An2YCwz5iqVzmKuW/qS84XzPRIvwWSm207lfg+AvaiGhqBaKixmYXP3ZvzD+f9QIoh94U9fwJ6pPa7RZP7v8+7ztwUQkRNdQdoRRk6Pno4t3VuQN/PYPbEb07lp6JZhW+j1lNu/eI53xyk4ICAGEFNiMC0TU7kp9xnM7yciJ9r9jhchciIyRsadM+aXLa4vz/FgjIEHDxNm2WdafL8yZxumVEu1jUwFL39Wz5bMkUs9l+KxBdiKt3O/AkRwEGBaFkzoBWXSNlJwnN3nePCQBdlVTCReKlFaeI63FTHJNiatj6xHWAq7xoHnpp/DRHYCpmXCJ/rQ7etGWk8jqSURlIN4ef/LoQgKdk/udj2pW3u3YjI7ib+M/gWapbnjKGtkXcXDEfrAYdH+5uDMr2ElbP+eqGD3hP17ftEP0zIxq87CYAbMgqFhOeaPyaAYxGBo0L43NYmQHMLF/RdDERU8dPQhTOWnlvw+gRPs8VNQXGRBdueWjJ4pjGNmR68UR9wygONESLwIk+mQeRnndp+LtJZGxsjYdZOC2BjbiCOpI3hp9iVXKeRh98dyCmfxfXYoHejyd6E70I21obWuMnPb7tvw9OTTSOtpgAG6qbt9QuAF1yPkRIo4fRyA23f7/H3YENuA56aeQ97Iwy/6MRAcAAPDTH7GHjNgYMyOYPGJPuSNPGbyM5AFGcORYfgl/wKZhwOHqBJFUkuCgdlrly+G/kA/DsQPAADOiJ2Bo8mjOJ4+vkChBez5QRZkDAQGMJ4dh2EZkAXZVlIsw+0nnb5OWzkqMt75RT9m1VmY1tw8Vsl6ExACEHgBmqlBERW8rOdidCjdmFYn0BvsxDvOfofb9s9NPwee46EICsYz40jpqRJD00rX/GJ5jed49Pn78MqhV8In+PBS4iWMZ8bRF+zDGdEzkDfy2D25G9P5aRiWgbAURlgO2/NSYV2TeAkbYxsxlh1DRi/0RTHoyg9LybNesBLdoO6+sa9//et4z3vegxtuuAHnnHMObr/9dgQCAXz3u98tW/6b3/wmrrjiCnz84x/H2WefjS9+8YvYvn07br31Vo9rvkrSk3CEPgvA7wJ+vCTJEMHAc4DF2d2VLwgyjlAh8RI4xiFv5DGeHcdpkdMwq87iwaMPllgrAVsAe/Dog5hVZ3Fa5DSMZ8eRN/LgmC1YGJax7EIL2G7U6fw0BgODMEwDz08/D93UoQiKbWmzTFdIF3kReT2PnJ5bsNAUD8DlBi+DvbCrpmorLUXKx1JKkyMkFX+P45XSTA0cAIuZSOkJ5IwMAAYRMuxVp5AWntkZi3JGDj7eZwu31kKBphgTJvJmHpZl2dZl03AnC6f8/AXCYpZrlbFgISpHYVkW8rotNHf7ujGrzmJWnYXESXZ7WCr8oh9hKQyRF22vXnYKKS2FyewkDMtAp68TITmETl8nDMvAVHYKyXwS09lp1zLqhLGsFJOZEDkRqqlCN3WInAiO45A38xjLjmE4NIznpp7DTG7GVa5MmBAK/znfAcwpHoZpuFZJBuZ61GRBhk/w2UoNs4V157/5dh4GqyDgceBhexrzVt61+GmmhqyRRZfSBdVUMZufxURmAkktCYG3yxRbVSuBgUGECN3ScecLd+IHz/0As/lZ+AQ7bEwSJCiigpgSg27qmMnPIG/k0aV0IWtk3c+Ds/uPaqroUDqQ1JJQTdvwkFATrpLteO0WMzw4Qg8PHqZlIp6PYzo7jZSWWnCviylNHDiYzMR0fhrjqXHM5GagmzoE2Aqfo4hU0jaOIqoz3VV4JE5aMHbyZh5pLY0efw8kXsJLsy+585nFLPz28G+xd2av7R1B+d93BBBHceI4W3hmzPYaaoaGyewk/KIfR5JHXOOCyQxk9bT93Zxof5bNKROmZcI0TSTVJKZyU653tri9HAxmQDM1wAKyRnaBN29+fZ12WkpZnz+fAXZfMWEiJsegmRpm87NIa2nbI7nMXM7AoFm25dkn+lzl3rRMcIwrCH46IlIQksCDwQIPDgBzlTqFtz3NebPgrWb2s84ZOYDZhjZnzIHZCsoL0y/gwOwBbAhvwFhmDLP5WYi8iKgcBQNDWk+7SplmaCXhhEOhIZjMxJHEERyYPQDd1F0FyZnPHEXUQkGBqGAY65YO3dKh6irGMmM4kjgCk9m/l9SSmMpP2R4liBUrTfNx+ra9rDCoporR9CgOzx7GbH52+e9kc0qzxEvQTA15I+9a9G2PPQPHzUvowQEcLLCCgG5YBl6ceRE5I4cefw96/D1QDbsuU9kp24NqmW5EwXIwMKS0FDRDg2EamMnP4HdHfocHRh7AgfgBWx6A6K69PtHeV6xbOnJ6Dqpu158xBp/ggyzIrrGMA4fp/DT2TOyBbumIKTEAsJVqKYg1wTWYztmeszVB2yMs8iJCcghDoSHM5mexd3ovhkPDJTKPxEsQeAFJLel6BTmOcw19ImcbPF6Kv4SZ3Iw73wL2WuV44Biz++jh5GHkjJzbh525x+mbiXwCHLMNEpZle5ESasL93kqVJgC2h6rQFoZl4EDiBfSEIji7ayPiahwPHn3QbXuJl9Dt63aNzcW/sVKlaT4WszCrzuJI4ggCUgCGaSCtpWGaJgJiAEdTR+25lVfc+S8oBUvWNQECDsQPIG/k5/qipWIsO7akPNuI1FVx0jQNu3btws6dO933eJ7Hzp078dhjj5X9zGOPPVZSHgAuv/zyRcurqopkMlnyV1dycfd/R0URexUFFgAfY8hzPESLweA4CPO8FAIvIG/mXTd22kijP9CPw4nDGM2MlvzEaGYUhxOH0R/oR9pIYzY/C0VQkDfzJXHAlWBYBnJWDoqouJ4E1VThE33IGTlk9excqERhsC4W+rVSTGbOCdtLxL8uOikwOw7ZDnMphHfBhA4NHARwHA+es98TeFuYFzgBqqliWp12w0EqwRG+HcWvuG5OLHCx+9tiFvJGHiInlnjJckbOtViblgmetydssDnhQBZkmMxEXI3DL/qR1JK2slJkRZYFGUktCb9kx1A7MfKu12sVMMZcxUXgBOQNey9ZPB/HSGrEff4cZy/YYHAX0GI4jgMYXOWdL5qGHOGXcXMhDE7fMeEIMeX7l3NfTh1EXgRjzN5rZmbdj81qtuVP5EU3bG5F7VD4T+LsfSsvzL7ghn8U36tj2bdgC6hZM4u8YSt1JkxIvAQw22OQMezwKcuyXC9NVs/a37OMt9Up4+4xY4braU5oCfdei62o8++H4zhX0JpRZ9z+KvACwGFFyiUDc5VlwO7v5eYFBoaknoRmaQjLYVjMwvPTz2M0M4rRzCgeG33MVdIdYaPcPFL83J09G47BRBEVN1Qvno+XeGR1ptuKMyy3zwH2nCdyIlRLtQ0FBU+bAMG9j/l1YWBgHCvpT+U8SPPfByoXpBhj0E0dOrNDWS1YFXkBy7VXcYiQE0rIGIPGNBhML+ggRYKXEw5dmMssWO7+MYtZEATBDi3kBXffKcdxdkiypWI8N25HJjBmRwHwnOs1yupZd8/DaGYUk7lJhOQQeN4OSzyZOWl7G3jbc6Fbuu0lYaxkXXDqVWkbWLBwMmPv8wtJIVvRd+Zdjl/S81KuPYG5dc5iFpJa0t6XJPgBBoxmRzGSGikJT18ME+ackYibewbF+3k51+jnwBXNlbYyBM6eX3iOd+fikBzCaGbUbtPC3Luct664/zrGrISaQEgOYe/0Xjw1+ZSrMIuCbZwVeMENN3XWRB26+33F/d7xeBuWgYyRgSzItgddkN2w4KxpG50YY/Z8XoQzllVTxUhqpETmKZZPRMEOfcwbefCcrdD4RB98og+z+VnbUF20Hs83lhSPHZOZ9lxTuBcnxM6ECYubM/JZnB2e7obdVjiPOvOmY7x1tkGMZcbAcRz6A/14fvp5PDXxFCxm2fuUmW6HCFdB+Zjfrw3LwMnMSYxlxpBQE+j0dSKuxjGWHXPbWzVtA68T3qoz3a4LAwReQEJNuLKKE84ez8eXlGcbkboqTlNTUzBNE319fSXv9/X1YWxsrOxnxsbGVlT+pptuQjQadf/Wrl1bncqvFjkAcAIADhleQJbjgYLQYjkTJOa87wzMFfisQjiSE7vqF/1QTdV1ezo4Fge/6Hddxm7YB1eZ58eBwV6sOY5zLaQWbCuto9g4E8ZKLCmVciqRpMVCjvMOwMCBQeIFSAIHkecXCF4Ws6CZWtlFuNz9OcrS/N9bIFgV/Q5jrOR5ODihY/PLF//LczzAMBcOVRR64+BM7AJvexkcC/ypPB9H6ZqvoBjMKAn/K1bOygm6xR7C+QKoM+EvZYkvB+eKegu9gyYzoZtzC7azEK0mfKG4Hk7YiGZq7v6TYooXLwsWdFN3Qy2dz7v1Kwjc7ngvPN9KFd3idnT2azkeJudaJYspw1w/Kf7dWlkBHa+HY9DJ6llk9AwyesYNNXHauVKcso6nymIW0nrangcLiizHCs9+Xoit82ycckspjPP7dqXKZTkFciX3VmwRX8lc7n6myADifIczFoo97CWKE+Y+M/99YK4tisecO18UBH5HEXH6vTPXOt5swA7v0i3d7Q+OccPxXDrCZLn+uKJ2KIwxx/sk8qLrySnuP6eCe2/83L1p5sIQsErq6jxnd09vGYplBnc+YAv7SHGbOuXLlVvu3gxmQICArJFFWku7bTff4OX+xvzbKprbij/HMGd4cQwEpjU3hzOwBQYvJwSOgc2N9XkKjbOv1plPHAOVI8Q7fbZ82y40erjrKZsrUzwHu/dmsQXtsRKc8FrHUJEzcgDgJqBK62kAcPvwqa7zi9ajsNY5e219og8GM9zXTnuLvOg+s/lzlTOOHUReXFaebUTqHqpXaz796U8jkUi4f8eOHatvhXrPAaQAwPEIMiDgLkaFh+FseOfticOxBAFzFgiREyEJkpu9ycne4hCUglAEBTkjB0mw47kZ7HAeW1bgKh7EHDhIgh0bL3CCu3gZzHDDoZxJwo0zryKnkjJ5fpicY1XnwYNxRXH+RYu+xSw3lpkvMzwWUwScyXkxy3JJPcC5+3ec5+EgcIIdljmvfPG/ViGu3bGWO2EExTDYz8sJw3Asf6fyfJz2K64PY3Z/DEmhBe08vw2K61Yc2lBcxhGqFtaTm/dvmfrN69fO9wqcAEmQ3PcEXii7uK+E4oVYFmR3cSumWJHiwUMSJPuZc3Ofd+vHS+73goP7fIvbcrn6FCvWjtLkPPNiRW2573E+U/y7tcp45Ox/MCzb6+HsjwlKQYSlcEk7V4pTlud4GDDchAoiJ7p7ihyPptP13D7IzfXr4o3a5Zjft5cqW65+i71e7rMCL5S8Xmkfnu8FLh4LztiYXy9nzir3PrDQuFPcd52snBJn93Gn3ztzrcAJbkicJNgJP5z+YFiGHWrFCa6w68y35dqm8kaw/5wEI46HpPgZnmqfd+/Nmrs3WZg79qBi4Zabe86O52juUvn1yJ0PuIV9pLhN3e8oU265exM5ESbsUK2QHHLbrpxRqmw9i+a24s9x4FyvnMXsiASBn5vDOXDufOkg8IL7eXesF2QSVz7h5pRuZ/1xo3oc+WYReaOcIdBdT7m5MsVzsHtvPLegPVaCY5QzLHsuK85IF5ACCEn2WV1OHz7VdX7RehTWOr/oh8iJbsSM89ppb2dfrMALC+YqZxw7ON79peTZRqSuilN3dzcEQcD4+HjJ++Pj4+jv7y/7mf7+/hWVVxQFkUik5K+urL3YVp54CQMWcI5mgAeQ53j4LAaD4yFyPExgzhoC20ruE3zQTA0dvg6ExBDGsmNueutiBoID2BDdgLHsGEJiCB2+Dju8TvC5k3ili4LIi/DzdtKHqBKFxSzbBV7YuBmQAm72ODdxQJlBu5pJozgzzVLWv0UniUJYmxMa5tyPIiq2ddEqDTnhYWczUgQFXUoXFFFZ0UJSvLgV180REFzFp6DsOBab4g3jftGPoBh0Jx3Lstx9G46ipZm22z+mxJAzcojIETejGFAIuTE1ROQIcnohFpsxN7X4qpWFIoHLZPbmbtVUEfPFMBwedp+/k9kM3ELrtlM/cHYyCGe/k3sNdnnHIzC34NihcY5atZA5JcipgxOyFZACCAgB92MdcocrrM9fgCtqh8J/OrNT857dcba9n6YQFupQvPlf4AUEhAB8or13S4AdcgSuoCyIQfAcD57n3QXd2fxfEk6zCI6AANibkTuUDuRM+9k79yrz5c+qctqLwX5unUrnXNiJZQKscqXA+b7icCRH2C2nMESkCGReRkpLged4bO7ajIHgAAaCA9gxsAOSILljZDHho/i5O5ZZNzW1oSIiR7AhugEx31yGUMMyIHFzSSycPgfMWUEVXnGzozkJHLii/xYYRlipQDdfiS8nfAFFiQ2Wa1fONmI5+x6dLH3lDDxLfk9R/Tlw9n67wvfLnDynxBcL6IU51JnLXAGJs5VL0yx4tS3TVZQYY1AEBQqvoM/fh55Ajx1CaWlglr3nKiAGEJACrhV9IDiAHn+P7cGwbE/hYHAQnb5OWJZtxS5O+lO8Ljj1qrQNePAYDA7av6enIXHS3LzLLFfRq7Q9gdKogIgcsY8SMHMABwwEBjAcHi4JY10MAUVCvKPTF9q1uO8562O5z5vMHrsBKeB6qhhjSGtpDAQH7DYtDgNmi39fcf+152EeUSWKtJbGOV3nYHvPdjdJkmEarvfDiXRw1kQJcwas4n7veCOcTI+aqcGy7MgPv+iHzMsICAE4inhACJTUzxnLiqBgODxcIvMUyyeGaUCzNPhEHyxmzWUqNPLo8HXY+/iK1uPi+hUrdo5h0tn7WaygCRDAszkFl2d20p7i/dqV4MybjjEjZ+QQVaLoD/aDMYax7Bg2d23G9t7t4DkeKS0FiZMQkAJVMXTN79ciL2IwOIj+YD+iShQz+RnEFDvBhtPejsHeJ/og87LdVzjbWGhapntshdsX9TRivtiS8mwjUlfFSZZlvOxlL8ODDz7ovmdZFh588EHs2LGj7Gd27NhRUh4AHnjggUXLNxyCCFzyUSAyAF6QsVOzcIZhweAAqyB0M1523cjOhlzd0sE4Bp/oQ1+gD4eSh9ChdOCydZctGCQ8x+OydZehQ+nAoeQh9AX64BN9hYxk9qTmCK1L4Rf96PJ14WT2JERBxOauzZAEyd0jIHCCK4QYlgGfZKcYnr/JtFhgWG7ScBQPRVDQqXSWxAUvZfl1FsLi73EGpyzYMfWiIKLL14WgZB8kp1oqmMXcDEbgbMuVX/Qjb+UREAMlFtjie3EfZ2HzPM/bAoQoFNqWm5t8i8NcHCu2wAu2gAoeCS0Bnufhk3wAB0zlp9ChdKBD6XD3Myi8PSGldDtFblSJojvQbaeHDfRA5ETM5GeQ1tKYyc/YqakD3Yj6ougKdJU8r9XgWIUVXnGFWUcw6gv0YSQ9gnO7z0Wnv9Pd6+Sk2naEaFcJLuxrEgXb0uT0C5/ggxMOkDftvUDOxGsvUgIEni9sWp9rfwG2582EvfD6eJ8bRioLMgJiANPqtN2nfJ3oDfYiIkfcsIaVKAVO3zJgK13Xnn0trjv3OnT4OpA388joGeimDtVQEVfjkATJzf40rU4jIAbcz4PN9Z9ZdRYROQJFUOATfYgqUbtOhdjw4r5XTgFxkmcIvICYL4auQBfCcnjBvZYTjNzwGE5Al68LfeE+dPo7IQmSm7zCieWvpG2cviZxc54CnekLxo5P8CEoB+3UxZaOjR0b3fmM53i8fsPrcU7nOa7nqNzvO8KXI8w4+wFR8NgpooKeQA9yRg7rw+vdvUsSLyEkh9x+zcDcPU6O4i8IAiJKBN3+bntD+TwhysHJ5AfezsRXXLZcfZ12WsoyPH8+A+b6elyLQxbsFNUhOQRREJedyznYe4ocS7Fqqu48xDj7fiVeQs6yFRjnuXHgbCEenJuoyCf43A32Ei/ZFnAObqIBR4DWLR3ndJ2DjR0bcTh1GP1BW8AyLAMJLQHAjo5wEgMoooL+YD/WR9ZD4AUcTx+HADsz38aOjZAEyQ3vdfqYI/g7RqVKhrHjZfJJPvQF++zfg/17ETmCbl+3vX8FRsUJE+bjE3y2J6DgyVEEBf2hfmyIbUCHr2P57+SY+0x1S7cT5ohzR5M4fccJkXLq4USkCILgttOmzk3wiT5M5iYxmZuEIioYCA2gO9BtJ/QohHNXmgjDSUUvCiI6fZ3YuX4nXjf8OmyMbbTlgcLawBizU5wXzsHyS34okuLufcqbeWim5nrRGBi6fF3Y0rsFEi8hrsbBwBCWw8joGZzInECXvwud/k6cyNhHaxiWnaTgePo4Ov2dOKfrHIykR0pkHt2y965F5AgsWO5RJX7JPjfSYHZGvDNiZ6DT31niJXHkMCccXhZlbIhssPcbaYmSucfpm1Elanu0C54iC7aC5nzvSiJz/ILfbQuJl3BO1znI6lkcTBx05T+n7XVLx1R+CkEx6Boxi5/bqcBzPDqUDqyPrEdWz0IURITlMATBDtVcF15n7yOzVHf+y+iZknXNhIkzYmeU9EWZl5eVZxuRhkhHfv311+M73/kOLrroInzjG9/A3XffjRdffBF9fX247rrrsGbNGtx0000A7HTkr371q/GVr3wFV155JX784x/jy1/+cvOkI3fY95/An28HpvfjENNxT1DGk34fpkUFOW5uAvQJPvdcAEVQVpT33utznBRBgV/0I67Gy57jJHKinXVsmXOc1obXYmPHxhWd4+R4UpxznJx4dSfF90BoAGvDa5HSUjiePo7Z3CwyRqaknQNyADE5ZqfWNio/x8kJUwBsT0zeLD3HyZ10BdnOfCeF3DJOBpr55zh1+bvsCTMfR0JLuOc48eAR88XKn+OUPu7W2zlnY/45T873VOscpy5/Fzp9nZWf44TC/rGic5y6fF2QeXnRc5wUXkFKTyGhJdw9AsULQXF4nyIq7jlOblhr4RynC/svxMUDF3t6jtNfDf4VXj/8+tWd45Q+jqRW+TlOEi+hy99Vtm8U32utz3Hyi34MhgaxMbZxyXOcAlIAIie6z+atZ7615uc4zZ+/ZvOz7nktTrKB+ec46ZaOk+mTFZ/jxIHDaHZ00XOcAlIAff4+iIK46DlO7rN1DDDzznFy+5VzjlN23E0cUAwPW+Apd46TxEu2x6cw7yW0BOJq3PW2FId6OdncBF5AUAy6beNkj5t/jlO3rxsX9F+w5DlOzjELUSWKMzvORESOLHmOEwcO+2b2LTjHyVEmnDpWco7Tlu4ti/6e87xTWso9LHgl5zgpguJmoowqUWzs2LjgHKcjySM4kT6xIO21wivufhug9BwnJ8LAybzpzJXOflmnjwicfTD0YNAeg+CAmfwMpnP2QezFMsRKznESICAkh9AT6MFQaIXnOPm60BdY3TlOgJ1wotw5ToZplFxb7hwnkRPnDLOFdig+x2kmP4OT6ZOrPscpLIXdswSLZQKTre4cp4BkG28VXsFAcAAxX8w9R6lc2zvnODnzvGZqVTnHaU1oDfqD/ZWf46TOlMgii53jNF9+oHOcVsCtt97qHoC7detW3HLLLbj44osBAJdeeimGh4fx/e9/3y1/zz334H//7//tHoD71a9+tXkOwC3GNIDjjwOZKViBTpyIDeFI5rh9orToR0gKIWtkEZJCbtjOSk9aXuoUbb/ot08p19KughKWw9jeux39oX6oplr2BHfndUpLIaNnFtSv+OTtkcQIZF4G4+xzF3oDvdjSvQVjmTHsGt+FsewYRNiCuV+2LUBbe+3T4Eczo0hrafd3ZvIzAIAOXwcCYsA9D6I409Da8FrkTTvb2/HUcfAcjy5/F87vOb/kO9N6Gj7Bh2OpY+A4Dt3+bmzp3oLJ3OSCU697/D3YM7kH+2f3YyI7gR5/Dzr9nVgXXoe8mS97SrizcTOrZzGdtxesLn+X64p20u4C9gnfxSfDFz/nvkCfW9Zilnv4ZPHJ7c4zLndad/F1px0DYsDefK+lMJIcgSIodkYeU3fPVIoqUfuZFML7ivvjYqevu1ndLANPTzyNQ/FD9rkXwQFolm1ZXBteC8YYdk/uhmqoOC12Grb1bgMAPDP5DKZyUzAt0z37aH1kvdtexafRh6QQ/KLffX5dPvvk8xPpE26bMjAcS9l7GtdH1mNNaM2C9kppKfe8JUVQkDWySKgJROQI8kYecTUO1VSxJrQG+2f3I6tnsSa8Bm/e+Gb4RF/JWCu+b0VUsL13O4bCQ+5vFp/q7pxAX3yq/PwT1p3n6Rf9dviD4MPR1FEk8gkoooLB4CByZs4978ZR4ss9++J7BQCZl3EybWcU6/Z3Y214rf0d8/rVsdQxPDX+FMaz4+gP9GNb3zYMBAfwzOQz2D+7H5PZSfT4e9wQDIMZOD16eskYns3PYs/kHkzmJhGVo7hk6BKIvFj22Sw2hx1JHsEjxx5BUkui09eJodAQBN4WEINS0G2fY6ljJWPeCcMtd7q9Mx6czzlzyPrIekSUSMm8VzynHU4ctg+z9nWUnQOcWP2JzAQOJQ9B4iRIguQ+y+292zEYGsR4dhxJNYmR5Ajiahw+wYeB4IB9FENhruvyd2FdeB3Gs+MYSYws2q9GEiO2EGcaOJY6hrSRRlgKY2vvVpzRcUbJnOMoA+XmPScTnDNWAeBY6pjracqbdjay4nHpzE1+wQ5Lc64XP9P565DTt4qfv9Pv5z8n5/VAcAAWs0rG2NYeu58dTR2dC88sHLkg8iJenHoRJ7MnERSDWBtei95gLzZENyz7e8V1dDwmJ9InMJWbcsdLWA4jqSVxPHUcU7kp9AZ6sbV3KwROwNHU0WXv7VjqGB46+hBGM6PoC/TZypxin8mX1tNIqAl0+DowHBlesD4463ZWz2JWnUVUicIv+HEycxKaqbnzqjMGi9f/+XO2YRnYPbHbVZ42RDdgODoM0zLxyPFHkFJT6PJ3YUvPFuiW7s4z5WSQ4v7ozNVBKYiIHEFIDrltnFATOJo8ill1FgExgK29W7EmtKbkeff4e/Ds1LOYyc+g09fpjmdnrn1m8pmy15aSeRZbu4qfT/FYPxQ/BM3U0Bfsw/a+7e68Ddgh878/+nuMZ8fR4+/BOV3n2AdCz/ud4t/2i35MZicxnZ92x0xCSyAsh+2IEi0Fv+jHlu4tmMnPYFadRaev0x2jxWNhsbYvlisYmDtn+QQfOnwdGAgOYM/UHowkRqCbOoZCQ+gK2OtnUAwiradxOHG45L7nP5v568v8MVROFpnfxuX6Yj1pOsXJSxpKcSIIgiAIgiAIom401QG4BEEQBEEQBEEQjQ4pTgRBEARBEARBEMtAihNBEARBEARBEMQykOJEEARBEARBEASxDKQ4EQRBEARBEARBLAMpTgRBEARBEARBEMtAihNBEARBEARBEMQykOJEEARBEARBEASxDKQ4EQRBEARBEARBLAMpTgRBEARBEARBEMtAihNBEARBEARBEMQykOJEEARBEARBEASxDKQ4EQRBEARBEARBLINY7wp4DWMMAJBMJutcE4IgCIIgCIIg6omjEzg6wlK0neKUSqUAAGvXrq1zTQiCIAiCIAiCaARSqRSi0eiSZThWiXrVQliWhZMnTyIcDoPjuHpXB8lkEmvXrsWxY8cQiUTqXZ22gdq9PlC71wdq9/pA7V4fqN3rA7V7faB2P3UYY0ilUhgcHATPL72Lqe08TjzPY2hoqN7VWEAkEqEOXweo3esDtXt9oHavD9Tu9YHavT5Qu9cHavdTYzlPkwMlhyAIgiAIgiAIglgGUpwIgiAIgiAIgiCWgRSnOqMoCj7/+c9DUZR6V6WtoHavD9Tu9YHavT5Qu9cHavf6QO1eH6jdvaXtkkMQBEEQBEEQBEGsFPI4EQRBEARBEARBLAMpTgRBEARBEARBEMtAihNBEARBEARBEMQykOJEEARBEARBEASxDKQ41ZFvf/vbGB4ehs/nw8UXX4zHH3+83lVqKW666SZceOGFCIfD6O3txZve9Cbs27evpEw+n8eNN96Irq4uhEIhvOUtb8H4+HidatyafOUrXwHHcfjwhz/svkftXhtOnDiBd7zjHejq6oLf78eWLVvw5JNPutcZY/jc5z6HgYEB+P1+7Ny5EwcOHKhjjZsf0zTx2c9+Fhs2bIDf78fpp5+OL37xiyjOu0Ttfur84Q9/wFVXXYXBwUFwHIef//znJdcraeOZmRlce+21iEQiiMVieNe73oV0Ou3hXTQnS7W9ruv45Cc/iS1btiAYDGJwcBDXXXcdTp48WfId1PYrZ7k+X8z73vc+cByHb3zjGyXvU7tXH1Kc6sRdd92Fj370o/j85z+Pp556Cueffz4uv/xyTExM1LtqLcMjjzyCG2+8EX/+85/xwAMPQNd1vP71r0cmk3HLfOQjH8GvfvUr3HPPPXjkkUdw8uRJvPnNb65jrVuLJ554At/5zndw3nnnlbxP7V59Zmdn8YpXvAKSJOH+++/H3r178c///M/o6Ohwy3z1q1/FLbfcgttvvx1/+ctfEAwGcfnllyOfz9ex5s3NzTffjNtuuw233norXnjhBdx888346le/im9961tuGWr3UyeTyeD888/Ht7/97bLXK2nja6+9Fs8//zweeOAB3HffffjDH/6A9773vV7dQtOyVNtns1k89dRT+OxnP4unnnoK9957L/bt24e/+Zu/KSlHbb9yluvzDj/72c/w5z//GYODgwuuUbvXAEbUhYsuuojdeOON7mvTNNng4CC76aab6lir1mZiYoIBYI888ghjjLF4PM4kSWL33HOPW+aFF15gANhjjz1Wr2q2DKlUim3cuJE98MAD7NWvfjX70Ic+xBijdq8Vn/zkJ9krX/nKRa9blsX6+/vZP/3TP7nvxeNxpigK+9GPfuRFFVuSK6+8kv393/99yXtvfvOb2bXXXssYo3avBQDYz372M/d1JW28d+9eBoA98cQTbpn777+fcRzHTpw44Vndm535bV+Oxx9/nAFgR44cYYxR21eDxdr9+PHjbM2aNey5555j69evZ//yL//iXqN2rw3kcaoDmqZh165d2Llzp/sez/PYuXMnHnvssTrWrLVJJBIAgM7OTgDArl27oOt6yXPYtGkT1q1bR8+hCtx444248sorS9oXoHavFb/85S9xwQUX4G1vext6e3uxbds2/Pu//7t7/fDhwxgbGytp92g0iosvvpja/RT4q7/6Kzz44IPYv38/AOCZZ57Bo48+ije84Q0AqN29oJI2fuyxxxCLxXDBBRe4ZXbu3Ame5/GXv/zF8zq3MolEAhzHIRaLAaC2rxWWZeGd73wnPv7xj2Pz5s0LrlO71wax3hVoR6ampmCaJvr6+kre7+vrw4svvlinWrU2lmXhwx/+MF7xilfg3HPPBQCMjY1BlmV3cnfo6+vD2NhYHWrZOvz4xz/GU089hSeeeGLBNWr32nDo0CHcdttt+OhHP4r/9b/+F5544gl88IMfhCzLuP766922LTfvULuvnk996lNIJpPYtGkTBEGAaZr4x3/8R1x77bUAQO3uAZW08djYGHp7e0uui6KIzs5Oeg5VJJ/P45Of/CSuueYaRCIRANT2teLmm2+GKIr44Ac/WPY6tXttIMWJaAtuvPFGPPfcc3j00UfrXZWW59ixY/jQhz6EBx54AD6fr97VaRssy8IFF1yAL3/5ywCAbdu24bnnnsPtt9+O66+/vs61a13uvvtu3HnnnfjhD3+IzZs3Y/fu3fjwhz+MwcFBaneirdB1HW9/+9vBGMNtt91W7+q0NLt27cI3v/lNPPXUU+A4rt7VaSsoVK8OdHd3QxCEBVnExsfH0d/fX6datS4f+MAHcN999+Ghhx7C0NCQ+35/fz80TUM8Hi8pT8/h1GYm7P0AAA13SURBVNi1axcmJiawfft2iKIIURTxyCOP4JZbboEoiujr66N2rwEDAwM455xzSt47++yzcfToUQBw25bmnery8Y9/HJ/61Kfwt3/7t9iyZQve+c534iMf+QhuuukmANTuXlBJG/f39y9IvmQYBmZmZug5VAFHaTpy5AgeeOAB19sEUNvXgj/+8Y+YmJjAunXr3HX2yJEj+NjHPobh4WEA1O61ghSnOiDLMl72spfhwQcfdN+zLAsPPvggduzYUceatRaMMXzgAx/Az372M/z+97/Hhg0bSq6/7GUvgyRJJc9h3759OHr0KD2HU+Cyyy7Ds88+i927d7t/F1xwAa699lr3/6ndq88rXvGKBen29+/fj/Xr1wMANmzYgP7+/pJ2TyaT+Mtf/kLtfgpks1nwfOlSKggCLMsCQO3uBZW08Y4dOxCPx7Fr1y63zO9//3tYloWLL77Y8zq3Eo7SdODAAfzud79DV1dXyXVq++rzzne+E3v27ClZZwcHB/Hxj38cv/nNbwBQu9eMemenaFd+/OMfM0VR2Pe//322d+9e9t73vpfFYjE2NjZW76q1DO9///tZNBplDz/8MBsdHXX/stmsW+Z973sfW7duHfv973/PnnzySbZjxw62Y8eOOta6NSnOqscYtXstePzxx5koiuwf//Ef2YEDB9idd97JAoEA+3//7/+5Zb7yla+wWCzGfvGLX7A9e/awN77xjWzDhg0sl8vVsebNzfXXX8/WrFnD7rvvPnb48GF27733su7ubvaJT3zCLUPtfuqkUin29NNPs6effpoBYF//+tfZ008/7WZuq6SNr7jiCrZt2zb2l7/8hT366KNs48aN7JprrqnXLTUNS7W9pmnsb/7mb9jQ0BDbvXt3yVqrqqr7HdT2K2e5Pj+f+Vn1GKN2rwWkONWRb33rW2zdunVMlmV20UUXsT//+c/1rlJLAaDs3/e+9z23TC6XY//wD//AOjo6WCAQYP/9v/93Njo6Wr9KtyjzFSdq99rwq1/9ip177rlMURS2adMm9m//9m8l1y3LYp/97GdZX18fUxSFXXbZZWzfvn11qm1rkEwm2Yc+9CG2bt065vP52GmnncY+85nPlAiN1O6nzkMPPVR2Pr/++usZY5W18fT0NLvmmmtYKBRikUiE3XDDDSyVStXhbpqLpdr+8OHDi661Dz30kPsd1PYrZ7k+P59yihO1e/XhGCs63pwgCIIgCIIgCIJYAO1xIgiCIAiCIAiCWAZSnAiCIAiCIAiCIJaBFCeCIAiCIAiCIIhlIMWJIAiCIAiCIAhiGUhxIgiCIAiCIAiCWAZSnAiCIAiCIAiCIJaBFCeCIAiCIAiCIIhlIMWJIAiCIAiCIAhiGUhxIgiCIIgyXHrppfjwhz9c89955zvfiS9/+csVl5+amkJvby+OHz9ew1oRBEEQ8yHFiSAIgjglHnvsMQiCgCuvvNLT3/0//+f/YOvWrRWV4zgOHMdBFEUMDw/jIx/5CNLp9JKfu/fee/HFL36xSrUtzzPPPINf//rX+OAHP+i+d/jwYfzd3/0dBgcH4fP5MDQ0hDe+8Y148cUXAQDd3d247rrr8PnPf76mdSMIgiBKIcWJIAiCOCXuuOMO/M//+T/xhz/8ASdPnqx3dcqyefNmjI6OYmRkBDfffDP+7d/+DR/72MfKltU0DQDQ2dmJcDhc03p961vfwtve9jaEQiEAgK7reN3rXodEIoF7770X+/btw1133YUtW7YgHo+7n7vhhhtw5513YmZmpqb1IwiCIOYgxYkgCIJYNel0GnfddRfe//7348orr8T3v//9kuuzs7O49tpr0dPTA7/fj40bN+J73/seAFtB+cAHPoCBgQH4fD6sX78eN910k/vZeDyOd7/73ejp6UEkEsFrX/taPPPMMwCA73//+/jCF76AZ555xvUmzf/tYkRRRH9/P4aGhnD11Vfj2muvxS9/+UsAc56r//t//y82bNgAn88HYGGonqqq+OQnP4m1a9dCURScccYZuOOOO9zrzz33HN7whjcgFAqhr68P73znOzE1NbVonUzTxE9+8hNcddVV7nvPP/88Dh48iH/913/Fy1/+cqxfvx6veMUr8KUvfQkvf/nL3XKbN2/G4OAgfvazny36/QRBEER1IcWJIAiCWDV33303Nm3ahLPOOgvveMc78N3vfheMMff6Zz/7Wezduxf3338/XnjhBdx2223o7u4GANxyyy345S9/ibvvvhv79u3DnXfeieHhYfezb3vb2zAxMYH7778fu3btwvbt23HZZZdhZmYGV199NT72sY+5nqTR0VFcffXVFdfb7/e7niUAeOmll/DTn/4U9957L3bv3l32M9dddx1+9KMf4ZZbbsELL7yA73znO66nKB6P47WvfS22bduGJ598Ev/5n/+J8fFxvP3tb1+0Dnv27EEikcAFF1zgvtfT0wOe5/GTn/wEpmkueQ8XXXQR/vjHP1Z8zwRBEMSpIda7AgRBEETzcscdd+Ad73gHAOCKK65AIpHAI488gksvvRQAcPToUWzbts1VDooVo6NHj2Ljxo145StfCY7jsH79evfao48+iscffxwTExNQFAUA8LWvfQ0///nP8ZOf/ATvfe97EQqFXE/SSti1axd++MMf4rWvfa37nqZp+MEPfoCenp6yn9m/fz/uvvtuPPDAA9i5cycA4LTTTnOv33rrrdi2bVtJkofvfve7WLt2Lfbv348zzzxzwXceOXIEgiCgt7fXfW/NmjW45ZZb8IlPfAJf+MIXcMEFF+A1r3kNrr322pLfA4DBwUE8/fTTK7p3giAIYvWQx4kgCIJYFfv27cPjjz+Oa665BoAdDnf11VeXhK+9//3vx49//GNs3boVn/jEJ/CnP/3JvfY//sf/wO7du3HWWWfhgx/8IH7729+615555hmk02l0dXUhFAq5f4cPH8bBgwdXXNdnn30WoVAIfr8fF110EXbs2IFbb73Vvb5+/fpFlSYA2L17NwRBwKtf/eqy15955hk89NBDJXXdtGkTACxa31wuB0VRwHFcyfs33ngjxsbGcOedd2LHjh245557sHnzZjzwwAMl5fx+P7LZbEX3TxAEQZw65HEiCIIgVsUdd9wBwzAwODjovscYg6IouPXWWxGNRvGGN7wBR44cwa9//Ws88MADuOyyy3DjjTfia1/7GrZv347Dhw/j/vvvx+9+9zu8/e1vx86dO/GTn/wE6XQaAwMDePjhhxf8biwWW3FdzzrrLPzyl7+EKIoYHByELMsl14PB4JKf9/v9S15Pp9O46qqrcPPNNy+4NjAwUPYz3d3dyGaz0DRtQX3C4TCuuuoqXHXVVfjSl76Eyy+/HF/60pfwute9zi0zMzOzpLJHEARBVBdSnAiCIIgVYxgGfvCDH+Cf//mf8frXv77k2pve9Cb86Ec/wvve9z4A9r6d66+/Htdffz0uueQSfPzjH8fXvvY1AEAkEsHVV1+Nq6++Gm9961txxRVXYGZmBtu3b8fY2JibPrwcsiwvuw+ouOwZZ5yx6vvdsmULLMvCI4884obqFbN9+3b89Kc/xfDwMESxsqXVSaW+d+/eJdOqcxyHTZs2lXjrADsZhRMSSRAEQdQeCtUjCIIgVsx9992H2dlZvOtd78K5555b8veWt7zFDdf73Oc+h1/84hd46aWX8Pzzz+O+++7D2WefDQD4+te/jh/96Ed48cUXsX//ftxzzz3o7+9HLBbDzp07sWPHDrzpTW/Cb3/7W4yMjOBPf/oTPvOZz+DJJ58EYO+XOnz4MHbv3o2pqSmoqlqz+x0eHsb111+Pv//7v8fPf/5zHD58GA8//DDuvvtuAHZ43czMDK655ho88cQTOHjwIH7zm9/ghhtuWFS56+npwfbt2/Hoo4+67+3evRtvfOMb8ZOf/AR79+7FSy+9hDvuuAPf/e538cY3vtEtl81msWvXrgVKK0EQBFE7SHEiCIIgVswdd9yBnTt3IhqNLrj2lre8BU8++ST27NkDWZbx6U9/Gueddx5e9apXQRAE/PjHPwZgh6N99atfxQUXXIALL7wQIyMj+PWvfw2e58FxHH7961/jVa96FW644QaceeaZ+Nu//VscOXIEfX197u9cccUVeM1rXoOenh786Ec/quk933bbbXjrW9+Kf/iHf8CmTZvwnve8B5lMBoCdqOG//uu/YJomXv/612PLli348Ic/jFgsBp5ffKl997vfjTvvvNN9PTQ0hOHhYXzhC1/AxRdfjO3bt+Ob3/wmvvCFL+Azn/mMW+4Xv/gF1q1bh0suuaR2N0wQBEGUwLHivLEEQRAEQXhGLpfDWWedhbvuugs7duyo+HMvf/nL8cEPfhB/93d/V8PaEQRBEMWQx4kgCIIg6oTf78cPfvCDJQ/Knc/U1BTe/OY3u9kMCYIgCG8gjxNBEARBEARBEMQykMeJIAiCIAiCIAhiGUhxIgiCIAiCIAiCWAZSnAiCIAiCIAiCIJaBFCeCIAiCIAiCIIhlIMWJIAiCIAiCIAhiGUhxIgiCIAiCIAiCWAZSnAiCIAiCIAiCIJaBFCeCIAiCIAiCIIhlIMWJIAiCIAiCIAhiGf5/hFYkzpTajCYAAAAASUVORK5CYII=\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "def generate_points_per_condition(N=1000, S_min=0.0, S_max=150.0,\n",
        "                                sigma_min=0.0, sigma_max=0.5, t=1.0):\n",
        "    \"\"\"\n",
        "    Generates 1,000 random points for each:\n",
        "    - Interior domain\n",
        "    - S=0 boundary\n",
        "    - S=S_max boundary\n",
        "    - σ=0 boundary\n",
        "    - σ=σ_max boundary\n",
        "    - Initial condition (t=T)\n",
        "    \"\"\"\n",
        "    # --- Interior points (S, σ, t all random) ---\n",
        "    S_int = torch.rand(N, 1) * (S_max - S_min) + S_min\n",
        "    sigma_int = torch.rand(N, 1) * (sigma_max - sigma_min) + sigma_min\n",
        "    t_int = torch.rand(N, 1) * t\n",
        "    interior = torch.cat([S_int, sigma_int, t_int], dim=1)\n",
        "\n",
        "    # --- Boundary: S=0 (σ and t random) ---\n",
        "    S0 = torch.zeros(N, 1)\n",
        "    sigma_S0 = torch.rand(N, 1) * (sigma_max - sigma_min) + sigma_min\n",
        "    t_S0 = torch.rand(N, 1) * t\n",
        "    bd_S0 = torch.cat([S0, sigma_S0, t_S0], dim=1)\n",
        "\n",
        "    # --- Boundary: S=S_max (σ and t random) ---\n",
        "    Smax = torch.ones(N, 1) * S_max\n",
        "    sigma_Smax = torch.rand(N, 1) * (sigma_max - sigma_min) + sigma_min\n",
        "    t_Smax = torch.rand(N, 1) * t\n",
        "    bd_Smax = torch.cat([Smax, sigma_Smax, t_Smax], dim=1)\n",
        "\n",
        "    # --- Boundary: σ=0 (S and t random) ---\n",
        "    S_sigma0 = torch.rand(N, 1) * (S_max - S_min) + S_min\n",
        "    sigma0 = torch.zeros(N, 1)\n",
        "    t_sigma0 = torch.rand(N, 1) * t\n",
        "    bd_sigma0 = torch.cat([S_sigma0, sigma0, t_sigma0], dim=1)\n",
        "\n",
        "    # --- Boundary: σ=σ_max (S and t random) ---\n",
        "    S_sigmamax = torch.rand(N, 1) * (S_max - S_min) + S_min\n",
        "    sigmamax = torch.ones(N, 1) * sigma_max\n",
        "    t_sigmamax = torch.rand(N, 1) * t\n",
        "    bd_sigmamax = torch.cat([S_sigmamax, sigmamax, t_sigmamax], dim=1)\n",
        "\n",
        "    # --- Initial condition: t=T (S and σ random) ---\n",
        "    S_initial = torch.rand(N, 1) * (S_max - S_min) + S_min\n",
        "    sigma_initial = torch.rand(N, 1) * (sigma_max - sigma_min) + sigma_min\n",
        "    t_initial = torch.zeros(N, 1)\n",
        "    initial = torch.cat([S_initial, sigma_initial, t_initial], dim=1)\n",
        "\n",
        "    # Combine all (total points = 6*N)\n",
        "    all_points = torch.cat([\n",
        "        interior, bd_S0, bd_Smax, bd_sigma0, bd_sigmamax, initial\n",
        "    ], dim=0).requires_grad_(True)\n",
        "\n",
        "    return {\n",
        "        'interior': interior,\n",
        "        'bd_S0': bd_S0,\n",
        "        'bd_Smax': bd_Smax,\n",
        "        'bd_sigma0': bd_sigma0,\n",
        "        'bd_sigmamax': bd_sigmamax,\n",
        "        'initial': initial,\n",
        "        'all': all_points\n",
        "    }\n",
        "\n",
        "# Generate 1,000 points per condition\n",
        "data = generate_points_per_condition(N=365)\n",
        "\n",
        "# Verify\n",
        "print(f\"Total points: {len(data['all'])}\")\n",
        "print(f\"Interior: {len(data['interior'])} points (S∈[{data['interior'][:,0].min():.1f}, {data['interior'][:,0].max():.1f}])\")\n",
        "print(f\"S=0 boundary: {len(data['bd_S0'])} points (σ∈[{data['bd_S0'][:,1].min():.1f}, {data['bd_S0'][:,1].max():.1f}])\")\n",
        "print(f\"σ=0 boundary: {len(data['bd_sigma0'])} points (S∈[{data['bd_sigma0'][:,0].min():.1f}, {data['bd_sigma0'][:,0].max():.1f}])\")\n",
        "\n",
        "# Plot S-σ distribution\n",
        "plt.figure(figsize=(10, 6))\n",
        "plt.scatter(data['interior'][:,0], data['interior'][:,1], label='Interior', alpha=0.3)\n",
        "plt.scatter(data['bd_S0'][:,0], data['bd_S0'][:,1], label='S=0 boundary', alpha=0.5)\n",
        "plt.scatter(data['bd_sigma0'][:,0], data['bd_sigma0'][:,1], label='σ=0 boundary', alpha=0.5)\n",
        "plt.xlabel(\"Asset Price (S)\"), plt.ylabel(\"Volatility (σ)\")\n",
        "plt.title(\"Training Points Distribution (1,000 per condition)\")\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92rz4WVqPfxv"
      },
      "source": [
        "# ***PDE AND PINN CONDITIONS***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "M14zHua1Htd4"
      },
      "outputs": [],
      "source": [
        "# Define a function to compute the partial derivatives needed for the Heston PDE\n",
        "def compute_derivatives_heston(model, S, v, t):\n",
        "    inputs = torch.cat([S, v, t], dim=1)\n",
        "    # Compute C (option price)\n",
        "    C = model(inputs)\n",
        "\n",
        "    # Compute partial derivatives using autograd\n",
        "    C_S = torch.autograd.grad(C, S, grad_outputs=torch.ones_like(C), create_graph=True)[0]\n",
        "    C_v = torch.autograd.grad(C, v, grad_outputs=torch.ones_like(C), create_graph=True)[0]\n",
        "    C_t = torch.autograd.grad(C, t, grad_outputs=torch.ones_like(C), create_graph=True)[0]\n",
        "\n",
        "    C_SS = torch.autograd.grad(C_S, S, grad_outputs=torch.ones_like(C_S), create_graph=True)[0]\n",
        "    C_vv = torch.autograd.grad(C_v, v, grad_outputs=torch.ones_like(C_v), create_graph=True)[0]\n",
        "    C_Sv = torch.autograd.grad(C_S, v, grad_outputs=torch.ones_like(C_S), create_graph=True)[0]\n",
        "\n",
        "    return C, C_S, C_v, C_t, C_SS, C_Sv, C_vv\n",
        "\n",
        "    # Define the Heston PDE\n",
        "def heston_pde(model, S, v, t, kappa, theta, sigma, rho, r):\n",
        "    C, C_S, C_v, C_t, C_SS, C_Sv, C_vv = compute_derivatives_heston(model, S, v, t)\n",
        "    rho = torch.tensor(rho, dtype=torch.float32, device=S.device)\n",
        "    sigma = torch.tensor(sigma, dtype=torch.float32, device=S.device)\n",
        "    kappa = torch.tensor(kappa, dtype=torch.float32, device=S.device)\n",
        "    theta = torch.tensor(theta, dtype=torch.float32, device=S.device)\n",
        "    r = torch.tensor(r, dtype=torch.float32, device=S.device)\n",
        "    # Compute the terms of the Heston PDE\n",
        "    term1 = C_t\n",
        "    term2 = 0.5 * v * S**2 * C_SS\n",
        "    term3 = rho * sigma * v * S * C_Sv\n",
        "    term4 = 0.5 * sigma**2 * v * C_vv\n",
        "    term5 = r * S * C_S\n",
        "    term6 = kappa * (theta - v) * C_v\n",
        "    term7 = -r * C\n",
        "\n",
        "    # Heston PDE that equals zero\n",
        "    residual = term1 + term2 + term3 + term4 + term5 + term6 + term7\n",
        "    return residual\n",
        "\n",
        "# Define boundary conditions\n",
        "def Smin_conditions(model, inputs_S_min):\n",
        "    # Boundary condition for S = S_min\n",
        "    boundary_S_min = model(inputs_S_min)  # V(t, F_min, alpha) = 0\n",
        "    boundary_S_min = torch.mean(boundary_S_min**2)\n",
        "\n",
        "    return boundary_S_min\n",
        "\n",
        "# Define boundary conditions\n",
        "def Smax_conditions2(model,  inputs_S_max):\n",
        "    # Boundary condition for S = S_max\n",
        "    fSmax = inputs_S_max[:, 0].requires_grad_(True).reshape(-1, 1)\n",
        "    V_S_max = model(inputs_S_max)\n",
        "    V_S_max_dx = torch.autograd.grad(V_S_max, inputs_S_max, torch.ones_like(V_S_max), create_graph=True)[0]\n",
        "    dVdS = V_S_max_dx[:, 0].reshape(-1, 1)\n",
        "    boundary_S_max = dVdS - 1\n",
        "    boundary_S_max = torch.mean(boundary_S_max**2)\n",
        "    return boundary_S_max\n",
        "\n",
        "    # Define boundary conditions\n",
        "def Smax_conditions(model,  inputs_S_max):\n",
        "    # Boundary condition for S = S_max\n",
        "    fSmax = inputs_S_max[:, 0].requires_grad_(True).reshape(-1, 1)\n",
        "    V_S_max = model(inputs_S_max)\n",
        "    V_S_max_dx = torch.autograd.grad(V_S_max, inputs_S_max, torch.ones_like(V_S_max), create_graph=True)[0]\n",
        "    V_S_max_d2x = torch.autograd.grad(V_S_max_dx, inputs_S_max, torch.ones_like(V_S_max_dx), create_graph=True)[0]\n",
        "    dSmaxd2x = V_S_max_d2x[:, 0].reshape(-1, 1)\n",
        "    boundary_S_max = torch.mean(dSmaxd2x**2)\n",
        "    return boundary_S_max\n",
        "\n",
        "# Define boundary conditions\n",
        "def v0_conditions(model, inputs_v_min, K, r):\n",
        "    # Boundary condition for alpha = 0\n",
        "    Vmin_S = inputs_v_min[:, 0].reshape(-1, 1)\n",
        "    Vmin_t = inputs_v_min[:, 2].reshape(-1, 1)\n",
        "    V_v_min = model(inputs_v_min)\n",
        "    V_v_min_dt = torch.autograd.grad(V_v_min, inputs_v_min, torch.ones_like(V_v_min), create_graph=True)[0]\n",
        "    dVmindt = V_v_min_dt[:, 2].reshape(-1, 1)\n",
        "    #boundary_alpha_min = V_alpha_min_dt\n",
        "    boundary_v_min = V_v_min - torch.maximum(Vmin_S - K*torch.exp(-r*Vmin_t), torch.tensor(0.0))\n",
        "    boundary_v_min = torch.mean(boundary_v_min**2)\n",
        "\n",
        "    return boundary_v_min\n",
        "# Define boundary conditions\n",
        "def Vmax_conditions(model, inputs_v_max):\n",
        "    # Boundary condition for alpha = 0\n",
        "    Vmax_S = inputs_v_max[:, 0].reshape(-1, 1)\n",
        "    V_v_max = model(inputs_v_max)\n",
        "    boundary_v_max = V_v_max - Vmax_S\n",
        "    boundary_v_max = torch.mean(boundary_v_max**2)\n",
        "\n",
        "    return boundary_v_max\n",
        "\n",
        "\n",
        "def IC_european_call(S, K):\n",
        "    val = torch.maximum(S - K, torch.tensor(0.0))\n",
        "    return val.view(-1, 1).requires_grad_(True)\n",
        "\n",
        "def ame_condition(model, inputs_ame, K):\n",
        "    fS = inputs_ame[:, 0].requires_grad_(True).reshape(-1, 1)\n",
        "\n",
        "    C = model(inputs)\n",
        "    exercise_value = torch.maximum(fS - K, torch.tensor(0.0))\n",
        "    bnd_ame_early = torch.mean(torch.relu(exercise_value - C)**2)  # Penalty if C < intrinsic value\n",
        "\n",
        "    return bnd_ame_early"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# ***CALIBRATION***"
      ],
      "metadata": {
        "id": "b_3kdEALSX6H"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Heston model calibration function\n",
        "def heston_calibration_error(params, market_prices, strike_prices, maturities, spots, risk_free_rate=0.0007, dividend_rate=0.0):\n",
        "    \"\"\"\n",
        "    Calculate the squared errors between market and Heston model prices.\n",
        "\n",
        "    params: [v0, kappa, theta, sigma, rho]\n",
        "    \"\"\"\n",
        "    v0, kappa, theta, sigma, rho = params\n",
        "\n",
        "    # Set up QuantLib calendar and day counter\n",
        "    calendar = ql.NullCalendar()\n",
        "    day_count = ql.Actual365Fixed()\n",
        "\n",
        "    calculation_date = ql.Date().from_date(datetime.now().date())\n",
        "    ql.Settings.instance().evaluationDate = calculation_date\n",
        "\n",
        "    errors = []\n",
        "\n",
        "    for i, (K, T, market_price, spot) in enumerate(zip(strike_prices, maturities, market_prices, spots)):\n",
        "        # Skip if maturity is zero or negative\n",
        "        if T <= 0:\n",
        "            continue\n",
        "\n",
        "        # Create option payoff and exercise\n",
        "        payoff = ql.PlainVanillaPayoff(ql.Option.Call, float(K))\n",
        "        exercise = ql.EuropeanExercise(calculation_date + ql.Period(int(T*252), ql.Days))\n",
        "\n",
        "        # Create Heston process\n",
        "        spot_handle = ql.QuoteHandle(ql.SimpleQuote(spot))\n",
        "        flat_ts = ql.YieldTermStructureHandle(ql.FlatForward(calculation_date, risk_free_rate, day_count))\n",
        "        dividend_ts = ql.YieldTermStructureHandle(ql.FlatForward(calculation_date, dividend_rate, day_count))\n",
        "\n",
        "        heston_process = ql.HestonProcess(flat_ts, dividend_ts, spot_handle,\n",
        "                                         v0, kappa, theta, sigma, rho)\n",
        "\n",
        "        # Create Heston model and engine\n",
        "        heston_model = ql.HestonModel(heston_process)\n",
        "        engine = ql.AnalyticHestonEngine(heston_model)\n",
        "\n",
        "        # Price the option\n",
        "        option = ql.VanillaOption(payoff, exercise)\n",
        "        option.setPricingEngine(engine)\n",
        "\n",
        "        try:\n",
        "            heston_price = option.NPV()\n",
        "        except:\n",
        "            heston_price = 0  # Return 0 if pricing fails\n",
        "\n",
        "        # Calculate squared error\n",
        "        error = (heston_price - market_price)**2\n",
        "        errors.append(error)\n",
        "\n",
        "    # Return mean squared error\n",
        "    return np.mean(errors)"
      ],
      "metadata": {
        "id": "kK7WtgBI8dGJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0SKLF9CtmL1V"
      },
      "outputs": [],
      "source": [
        "def sabr_volatility(alpha, beta, rho, nu, F, K, T):\n",
        "    \"\"\" Computes the SABR model implied volatility using Hagan's formula \"\"\"\n",
        "    if F == K:  # ATM case\n",
        "        FK_beta = F**(1 - beta)\n",
        "        vol = alpha / FK_beta * (1 + (((1 - beta) ** 2) / 24 * (alpha**2 / FK_beta**2) +\n",
        "                                     (1 / 4) * (rho * beta * nu * alpha / FK_beta) +\n",
        "                                     ((2 - 3 * rho**2) / 24) * (nu**2)) * T)\n",
        "    else:\n",
        "        z = (nu / alpha) * (F * K) ** ((1 - beta) / 2) * np.log(F / K)\n",
        "        x_z = np.log((np.sqrt(1 - 2 * rho * z + z**2) + z - rho) / (1 - rho))\n",
        "        FK_beta = (F * K) ** ((1 - beta) / 2)\n",
        "        term1 = (1 + ((((1-beta)**2)/24)*((alpha**2)/FK_beta**2) +\n",
        "                     (1 / (4*FK_beta)) * (rho * beta * nu * alpha) +\n",
        "                     ((2 - 3 * rho**2) / 24) * (nu**2)) * T)\n",
        "        term2 = (1 + ((((1 - beta) ** 2) / 24) * ((np.log(F/K)) ** 2)) +\n",
        "                 ((((1 - beta) ** 4) / 1920) * ((np.log(F/K)) ** 4)))\n",
        "        vol = (alpha / FK_beta) * (z / x_z) * term1 / term2\n",
        "    return vol\n",
        "\n",
        "# Loss function to minimize\n",
        "def sabr_loss(params, F, strikes, T, market_vols):\n",
        "    alpha, beta, rho, nu = params\n",
        "    model_vols = np.array([sabr_volatility(alpha, beta, rho, nu, F, K, T) for K in strikes])\n",
        "    return np.sum((model_vols - market_vols) ** 2)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "_NAtl_ljPTfe"
      },
      "source": [
        "# ***ANALYTICAL BS - MONTE CARLO***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "RnZ_B5pDH4aB"
      },
      "outputs": [],
      "source": [
        "# ANALYTICAL BS OPTION PRICE\n",
        "\n",
        "def black_scholes_option_price(S, K, T, r, sigma, option_type='call'):\n",
        "\n",
        "    # Calculate d1 and d2\n",
        "    d1 = (np.log(S / K) + (r + 0.5 * sigma**2) * T) / (sigma * np.sqrt(T+0.00000001))\n",
        "    d2 = d1 - sigma * np.sqrt(T)\n",
        "\n",
        "    if option_type == 'call':\n",
        "        # Calculate the price of a European call option\n",
        "        option_price = S * norm.cdf(d1) - K * np.exp(-r * T) * norm.cdf(d2)\n",
        "    elif option_type == 'put':\n",
        "        # Calculate the price of a European put option\n",
        "        option_price = K * np.exp(-r * T) * norm.cdf(-d2) - S * norm.cdf(-d1)\n",
        "    else:\n",
        "        raise ValueError(\"option_type must be 'call' or 'put'\")\n",
        "\n",
        "    return option_price\n",
        "\n",
        "# MONTE CARLO OPTION PRICE\n",
        "\n",
        "def sabr_european_call_mc(S0_array, sigma0_array, T_array, K, r,\n",
        "                          beta, nu, rho, N, M, confidence=0.95):\n",
        "\n",
        "    S0_array = np.asarray(S0_array).flatten()\n",
        "    sigma0_array = np.asarray(sigma0_array).flatten()\n",
        "    T_array = np.asarray(T_array).flatten()\n",
        "\n",
        "    n_samples = len(S0_array)\n",
        "    prices = np.zeros(n_samples)\n",
        "    conf_intervals = []\n",
        "\n",
        "    z_score = norm.ppf(1 - (1 - confidence) / 2)\n",
        "\n",
        "    for i in range(n_samples):\n",
        "        S0 = S0_array[i]\n",
        "        alpha0 = sigma0_array[i]\n",
        "        T = T_array[i]\n",
        "        dt = T / N\n",
        "        sqrt_dt = np.sqrt(dt)\n",
        "\n",
        "        # Initialize arrays\n",
        "        S = np.zeros((M, N+1))\n",
        "        alpha = np.zeros((M, N+1))\n",
        "        S[:, 0] = S0\n",
        "        alpha[:, 0] = alpha0\n",
        "\n",
        "        for t in range(N):\n",
        "            z1 = np.random.randn(M)\n",
        "            z2 = np.random.randn(M)\n",
        "            dW1 = z1\n",
        "            dW2 = rho * z1 + np.sqrt(1 - rho**2) * z2\n",
        "\n",
        "            alpha[:, t+1] = alpha[:, t] + nu * alpha[:, t] * dW2 * sqrt_dt\n",
        "            S[:, t] = np.maximum(S[:, t], 1e-12)\n",
        "            sigma_S = alpha[:, t] * (S[:, t]**(beta))\n",
        "            mu_S = r * S[:, t]\n",
        "            S[:, t+1] = S[:, t] + mu_S * dt + sigma_S * dW1 * sqrt_dt\n",
        "            #S[:, t+1] = S[:, t]  + sigma_S * dW1 * sqrt_dt\n",
        "\n",
        "        # Call option payoff\n",
        "        payoffs = np.maximum(S[:, -1] - K, 0)\n",
        "        discounted = np.exp(-r * T) * payoffs\n",
        "\n",
        "        mean_price = np.mean(discounted)\n",
        "        prices[i] = mean_price\n",
        "\n",
        "    return prices\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "vwrnEcQstBPz"
      },
      "source": [
        "# ***CALLING REAL DATASET***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "pJhN2TeStAeF"
      },
      "outputs": [],
      "source": [
        "# Load all sheets in the Excel file\n",
        "excel_file = \"/content/drive/MyDrive/Bitirme_real_dataset/american_options.xlsx\"\n",
        "sheet_names = pd.ExcelFile(excel_file).sheet_names\n",
        "\n",
        "results_MC_df = pd.DataFrame(columns=[\"Sheet\", \"Heston Model MSE\", \"Heston Model MAPE\"])\n",
        "\n",
        "prediction_df = pd.DataFrame()\n",
        "\n",
        "output_dir = \"/content/drive/MyDrive/Bitirme_real_dataset/new/Heston/real/ame\"\n",
        "os.makedirs(output_dir, exist_ok=True)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P7ikHf_OPIKF"
      },
      "source": [
        "# ***TRAINING***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "g2_iXyZJmjwC",
        "outputId": "00714280-c902-4a19-c7f5-0005d01ac1dd"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Processing sheet: A\n",
            "F:  [41.879999 42.029999 42.86     42.550001 42.209999 43.349999 43.67\n",
            " 43.430001 43.539999 43.239999 43.05     43.869999 44.15     44.639999\n",
            " 44.3      44.66     45.290003 45.18     44.639999 44.4      44.780002\n",
            " 45.290003 44.26     45.000002 45.090001 45.010002 45.080002 44.599999\n",
            " 44.62     44.749999 44.580001 42.249999 43.01     42.24     41.630001\n",
            " 41.8      41.289999 40.970001 41.729999 41.479999 41.930001 42.029999\n",
            " 42.660001 43.239999 43.250001 43.030001 42.810001 42.619999 43.000001\n",
            " 43.320001 43.01     42.550001 42.000001 42.700001 41.65     41.249999\n",
            " 41.13     41.820001 42.09     41.970001 40.930001 40.66     40.519999\n",
            " 41.410001 41.54     41.659999 41.65     42.260001 43.86     44.749999\n",
            " 43.04     43.389999 42.190001 41.83     42.000001 41.850001 42.609999\n",
            " 42.850001 42.729999 41.300001 41.46     41.439999 41.31     41.479999\n",
            " 41.549999 42.000001 42.400001 42.94     43.16     43.63     43.04\n",
            " 43.97     45.680001 44.989998 45.559999]\n",
            "F no zero:  [41.879999 42.029999 42.86     42.550001 42.209999 43.349999 43.67\n",
            " 43.430001 43.539999 43.239999 43.05     43.869999 44.15     44.639999\n",
            " 44.3      44.66     45.290003 45.18     44.639999 44.4      44.780002\n",
            " 45.290003 44.26     45.000002 45.090001 45.010002 45.080002 44.599999\n",
            " 44.62     44.749999 44.580001 42.249999 43.01     42.24     41.630001\n",
            " 41.8      41.289999 40.970001 41.729999 41.479999 41.930001 42.029999\n",
            " 42.660001 43.239999 43.250001 43.030001 42.810001 42.619999 43.000001\n",
            " 43.320001 43.01     42.550001 42.000001 42.700001 41.65     41.249999\n",
            " 41.13     41.820001 42.09     41.970001 40.930001 40.66     40.519999\n",
            " 41.410001 41.54     41.659999 41.65     42.260001 43.86     44.749999\n",
            " 43.04     43.389999 42.190001 41.83     42.000001 41.850001 42.609999\n",
            " 42.850001 42.729999 41.300001 41.46     41.439999 41.31     41.479999\n",
            " 41.549999 42.000001 42.400001 42.94     43.16     43.63     43.04\n",
            " 43.97     45.680001 44.989998 45.559999]\n",
            "spot price no zero:  41.879999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.16360435160627904\n",
            "kappa: 2.000000277555758\n",
            "theta: 0.03999582070420238\n",
            "sigma_heston: 0.09999470701172732\n",
            "rho_heston: -0.6999993664789897\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.39532095046376325\n",
            "Beta: 0.976724798751423\n",
            "Rho: 0.018544715903049656\n",
            "Nu: 0.2932543331343732\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.12/dist-packages/torch/optim/lr_scheduler.py:1340: UserWarning: Converting a tensor with requires_grad=True to a scalar may lead to unexpected behavior.\n",
            "Consider using tensor.detach() first. (Triggered internally at /pytorch/torch/csrc/autograd/generated/python_variable_methods.cpp:835.)\n",
            "  current = float(metrics)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Iteration 0, Loss: 300117664.0\n",
            "Loss-1 (IC): 0.0004136861825827509, Loss-2 (pde): 8.281475061266974e-09 , Loss-5 (bd): 300117664.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 1175208.875\n",
            "Loss-1 (IC): 0.00046318292152136564, Loss-2 (pde): 0.15663237869739532 , Loss-5 (bd): 1175208.75\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 234627.5\n",
            "Loss-1 (IC): 0.00044706015614792705, Loss-2 (pde): 0.1441294252872467 , Loss-5 (bd): 234627.359375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 99829.9765625\n",
            "Loss-1 (IC): 0.0004593922640196979, Loss-2 (pde): 0.4998153746128082 , Loss-5 (bd): 99829.4765625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 71140.34375\n",
            "Loss-1 (IC): 0.00043194476165808737, Loss-2 (pde): 1.0024592876434326 , Loss-5 (bd): 71139.34375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 55938.93359375\n",
            "Loss-1 (IC): 0.0004582187393680215, Loss-2 (pde): 0.78183513879776 , Loss-5 (bd): 55938.15234375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 47543.28515625\n",
            "Loss-1 (IC): 0.00045104132732376456, Loss-2 (pde): 0.41489145159721375 , Loss-5 (bd): 47542.87109375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 44656.328125\n",
            "Loss-1 (IC): 0.0004219606053084135, Loss-2 (pde): 0.23745465278625488 , Loss-5 (bd): 44656.08984375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 33297.31640625\n",
            "Loss-1 (IC): 0.0004405591753311455, Loss-2 (pde): 0.1556013822555542 , Loss-5 (bd): 33297.16015625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 44339.79296875\n",
            "Loss-1 (IC): 0.00043767725583165884, Loss-2 (pde): 0.1851356029510498 , Loss-5 (bd): 44339.60546875\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  28336.568359375\n",
            "Model 992 iterasyondan yüklendi, Loss: 28336.568359\n",
            "MSE between MC-book and PINN: 0.26666052163828263\n",
            "MAPE between MC-book and PINN:: 0.019570214173032688\n",
            "Processing sheet: AAPL\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:210: FutureWarning: The behavior of DataFrame concatenation with empty or all-NA entries is deprecated. In a future version, this will no longer exclude empty or all-NA columns when determining the result dtypes. To retain the old behavior, exclude the relevant entries before the concat operation.\n",
            "  results_MC_df = pd.concat([results_MC_df, new_row], ignore_index=True)\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "F:  [549.029976 542.099991 526.999992 523.900002 525.31002  517.100006\n",
            " 523.509979 520.300026 501.750015 485.920013 506.089981 502.680023\n",
            " 500.000015 504.770004 514.010002 450.499977 439.880001 449.830002\n",
            " 458.269981 456.830002 455.489998 453.619995 442.320004 457.840012\n",
            " 457.350014 468.220009 474.980003 479.930023 467.900002 467.009995\n",
            " 466.590012 460.160011 459.990021 448.850006 446.060009 450.809998\n",
            " 442.799988 448.970009 444.569988 441.400009 430.470013 420.049988\n",
            " 431.139988 425.659996 430.580002 431.720001 437.869995 428.429993\n",
            " 428.349991 432.499992 443.660007 455.720016 454.489975 452.079987\n",
            " 452.729988 461.910011 463.580009 461.140007 452.079987 442.660011\n",
            " 428.910004 429.789997 431.989994 427.71999  423.199993 426.209995\n",
            " 426.98     435.689999 434.329994 429.800011 419.85001  426.240009\n",
            " 402.800007 392.049988 390.530006]\n",
            "F no zero:  [549.029976 542.099991 526.999992 523.900002 525.31002  517.100006\n",
            " 523.509979 520.300026 501.750015 485.920013 506.089981 502.680023\n",
            " 500.000015 504.770004 514.010002 450.499977 439.880001 449.830002\n",
            " 458.269981 456.830002 455.489998 453.619995 442.320004 457.840012\n",
            " 457.350014 468.220009 474.980003 479.930023 467.900002 467.009995\n",
            " 466.590012 460.160011 459.990021 448.850006 446.060009 450.809998\n",
            " 442.799988 448.970009 444.569988 441.400009 430.470013 420.049988\n",
            " 431.139988 425.659996 430.580002 431.720001 437.869995 428.429993\n",
            " 428.349991 432.499992 443.660007 455.720016 454.489975 452.079987\n",
            " 452.729988 461.910011 463.580009 461.140007 452.079987 442.660011\n",
            " 428.910004 429.789997 431.989994 427.71999  423.199993 426.209995\n",
            " 426.98     435.689999 434.329994 429.800011 419.85001  426.240009\n",
            " 402.800007 392.049988 390.530006]\n",
            "spot price no zero:  549.029976\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.5\n",
            "kappa: 10.0\n",
            "theta: 0.01\n",
            "sigma_heston: 0.5761802045485922\n",
            "rho_heston: -0.99\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.4217032239383481\n",
            "Beta: 0.9683485937138233\n",
            "Rho: 0.031230566746666445\n",
            "Nu: 0.2909128438363357\n",
            "Iteration 0, Loss: 30641616896.0\n",
            "Loss-1 (IC): 0.04592599347233772, Loss-2 (pde): 0.025565151125192642 , Loss-5 (bd): 30641616896.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 3768338432.0\n",
            "Loss-1 (IC): 0.039231106638908386, Loss-2 (pde): 117.86911010742188 , Loss-5 (bd): 3768338432.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 3107800832.0\n",
            "Loss-1 (IC): 0.0389573834836483, Loss-2 (pde): 2520.611328125 , Loss-5 (bd): 3107798272.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 408998464.0\n",
            "Loss-1 (IC): 0.04661428928375244, Loss-2 (pde): 69108.875 , Loss-5 (bd): 408929344.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 2939801088.0\n",
            "Loss-1 (IC): 0.04054240509867668, Loss-2 (pde): 5943.916015625 , Loss-5 (bd): 2939795200.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 856680896.0\n",
            "Loss-1 (IC): 0.04612758383154869, Loss-2 (pde): 159637.984375 , Loss-5 (bd): 856521280.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 94712464.0\n",
            "Loss-1 (IC): 0.054263561964035034, Loss-2 (pde): 67585.3828125 , Loss-5 (bd): 94644880.0\n",
            "CURRENT LR: [0.0001]\n",
            "Iteration 700, Loss: 26463620.0\n",
            "Loss-1 (IC): 0.052118897438049316, Loss-2 (pde): 59144.6484375 , Loss-5 (bd): 26404476.0\n",
            "CURRENT LR: [0.0001]\n",
            "Iteration 800, Loss: 23620726.0\n",
            "Loss-1 (IC): 0.05310939997434616, Loss-2 (pde): 22600.880859375 , Loss-5 (bd): 23598126.0\n",
            "CURRENT LR: [0.0001]\n",
            "Iteration 900, Loss: 12577441.0\n",
            "Loss-1 (IC): 0.054383546113967896, Loss-2 (pde): 26326.3671875 , Loss-5 (bd): 12551115.0\n",
            "CURRENT LR: [0.0001]\n",
            "best loss:  7324759.5\n",
            "Model 999 iterasyondan yüklendi, Loss: 7324759.500000\n",
            "MSE between MC-book and PINN: 76.26498027959805\n",
            "MAPE between MC-book and PINN:: 0.04592853116659419\n",
            "Processing sheet: GOOG\n",
            "F:  [723.250034 723.670024 737.96998  734.749998 733.300033 738.120037\n",
            " 741.480016 739.989992 723.250034 724.929993 715.189987 711.320021\n",
            " 704.510004 702.869983 741.500016 754.210011 753.670024 750.730035\n",
            " 753.680024 753.83002  755.690035 775.600037 759.020015 765.740034\n",
            " 770.169987 773.950017 785.369982 782.419993 780.700035 782.859982\n",
            " 787.819983 792.889981 806.850007 792.459992 795.530039 799.709998\n",
            " 790.770033 790.129988 799.779996 801.200022 806.190023 821.500015\n",
            " 838.600024 831.380018 832.599988 831.520014 834.819995 827.609988\n",
            " 825.309983 821.540014 814.300008]\n",
            "F no zero:  [723.250034 723.670024 737.96998  734.749998 733.300033 738.120037\n",
            " 741.480016 739.989992 723.250034 724.929993 715.189987 711.320021\n",
            " 704.510004 702.869983 741.500016 754.210011 753.670024 750.730035\n",
            " 753.680024 753.83002  755.690035 775.600037 759.020015 765.740034\n",
            " 770.169987 773.950017 785.369982 782.419993 780.700035 782.859982\n",
            " 787.819983 792.889981 806.850007 792.459992 795.530039 799.709998\n",
            " 790.770033 790.129988 799.779996 801.200022 806.190023 821.500015\n",
            " 838.600024 831.380018 832.599988 831.520014 834.819995 827.609988\n",
            " 825.309983 821.540014 814.300008]\n",
            "spot price no zero:  723.250034\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.06599761000000001\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.2559198670890043\n",
            "Beta: 0.9965087085050515\n",
            "Rho: 0.00023012659784105396\n",
            "Nu: 0.29953536404470277\n",
            "Iteration 0, Loss: 114030362624.0\n",
            "Loss-1 (IC): 0.16588194668293, Loss-2 (pde): 0.6047740578651428 , Loss-5 (bd): 114030362624.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 8497156096.0\n",
            "Loss-1 (IC): 0.12190805375576019, Loss-2 (pde): 1017.6044921875 , Loss-5 (bd): 8497155072.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 6496185856.0\n",
            "Loss-1 (IC): 0.12314710766077042, Loss-2 (pde): 54900.7421875 , Loss-5 (bd): 6496131072.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 6102917120.0\n",
            "Loss-1 (IC): 0.14475828409194946, Loss-2 (pde): 41958.78125 , Loss-5 (bd): 6102875136.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 7530925568.0\n",
            "Loss-1 (IC): 0.1217990443110466, Loss-2 (pde): 16450.4140625 , Loss-5 (bd): 7530909184.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 4437300224.0\n",
            "Loss-1 (IC): 0.14762039482593536, Loss-2 (pde): 237193.734375 , Loss-5 (bd): 4437063168.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 3238800128.0\n",
            "Loss-1 (IC): 0.1466718167066574, Loss-2 (pde): 161947.234375 , Loss-5 (bd): 3238638080.0\n",
            "CURRENT LR: [0.0001]\n",
            "Iteration 700, Loss: 1728588544.0\n",
            "Loss-1 (IC): 0.1388111263513565, Loss-2 (pde): 157015.125 , Loss-5 (bd): 1728431488.0\n",
            "CURRENT LR: [0.0001]\n",
            "Iteration 800, Loss: 1159419520.0\n",
            "Loss-1 (IC): 0.1559005230665207, Loss-2 (pde): 87579.484375 , Loss-5 (bd): 1159331968.0\n",
            "CURRENT LR: [0.0001]\n",
            "Iteration 900, Loss: 152229152.0\n",
            "Loss-1 (IC): 0.15825501084327698, Loss-2 (pde): 178935.28125 , Loss-5 (bd): 152050224.0\n",
            "CURRENT LR: [0.0001]\n",
            "best loss:  61914268.0\n",
            "Model 970 iterasyondan yüklendi, Loss: 61914268.000000\n",
            "MSE between MC-book and PINN: 494.54302902497074\n",
            "MAPE between MC-book and PINN:: 0.04830485182248298\n",
            "Processing sheet: FB\n",
            "F:  [28.       27.77     28.76     29.42     29.059999 30.59     31.299999\n",
            " 31.719999 30.950001 30.1      29.85     30.139999 29.66     30.73\n",
            " 30.82     31.08     31.540001 32.470001 30.790001 31.24     30.98\n",
            " 29.73     28.110001 28.639999 29.049999 28.65     28.549999 28.26\n",
            " 27.370001 27.91     28.5      28.32     28.93     28.459999 27.280001\n",
            " 27.129999 27.27     27.389999 26.870001 27.25     27.780001 27.719999\n",
            " 27.52     27.450001 28.58     27.959999 28.139999 27.83     27.08\n",
            " 27.040001 26.65    ]\n",
            "F no zero:  [28.       27.77     28.76     29.42     29.059999 30.59     31.299999\n",
            " 31.719999 30.950001 30.1      29.85     30.139999 29.66     30.73\n",
            " 30.82     31.08     31.540001 32.470001 30.790001 31.24     30.98\n",
            " 29.73     28.110001 28.639999 29.049999 28.65     28.549999 28.26\n",
            " 27.370001 27.91     28.5      28.32     28.93     28.459999 27.280001\n",
            " 27.129999 27.27     27.389999 26.870001 27.25     27.780001 27.719999\n",
            " 27.52     27.450001 28.58     27.959999 28.139999 27.83     27.08\n",
            " 27.040001 26.65    ]\n",
            "spot price no zero:  28.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.21141604\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.4572532137072797\n",
            "Beta: 0.9943379138417455\n",
            "Rho: 0.000757355951041313\n",
            "Nu: 0.2987809630741417\n",
            "Iteration 0, Loss: 231117456.0\n",
            "Loss-1 (IC): 0.0003708464209921658, Loss-2 (pde): 1.5025968025383918e-08 , Loss-5 (bd): 231117456.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 964376.9375\n",
            "Loss-1 (IC): 0.00026311445981264114, Loss-2 (pde): 0.02697516232728958 , Loss-5 (bd): 964376.9375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 137589.1875\n",
            "Loss-1 (IC): 0.00029264192562550306, Loss-2 (pde): 0.25580736994743347 , Loss-5 (bd): 137588.9375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 90271.3203125\n",
            "Loss-1 (IC): 0.00028982263756915927, Loss-2 (pde): 0.3319534957408905 , Loss-5 (bd): 90270.984375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 56679.8828125\n",
            "Loss-1 (IC): 0.0002976930409204215, Loss-2 (pde): 0.33671364188194275 , Loss-5 (bd): 56679.546875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 27734.62109375\n",
            "Loss-1 (IC): 0.0002827874559443444, Loss-2 (pde): 0.25760069489479065 , Loss-5 (bd): 27734.36328125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 19064.560546875\n",
            "Loss-1 (IC): 0.00027676677564159036, Loss-2 (pde): 0.09982733428478241 , Loss-5 (bd): 19064.4609375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 12732.4248046875\n",
            "Loss-1 (IC): 0.00030000967672094703, Loss-2 (pde): 0.11816325783729553 , Loss-5 (bd): 12732.306640625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 10053.083984375\n",
            "Loss-1 (IC): 0.00029562792042270303, Loss-2 (pde): 0.07943032681941986 , Loss-5 (bd): 10053.00390625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 7679.236328125\n",
            "Loss-1 (IC): 0.00028910685796290636, Loss-2 (pde): 0.05072259157896042 , Loss-5 (bd): 7679.185546875\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  5085.2744140625\n",
            "Model 994 iterasyondan yüklendi, Loss: 5085.274414\n",
            "MSE between MC-book and PINN: 0.04257106573063998\n",
            "MAPE between MC-book and PINN:: 0.009954226219255917\n",
            "Processing sheet: XOM\n",
            "F:  [88.709999 88.550003 88.959999 87.93     88.480003 88.139999 89.099998\n",
            " 89.610001 89.580002 89.529999 89.470001 90.199997 90.800003 90.919998\n",
            " 90.699997 91.349998 91.730003 91.110001 91.760002 90.669998 89.970001\n",
            " 90.040001 89.150002 89.739998 89.790001 88.25     88.610001 88.279999\n",
            " 88.459999 88.669998 88.519997 88.360001 89.32     88.970001 88.589996\n",
            " 89.199997 87.699997 88.510002 89.529999 89.550003 89.43     88.949997\n",
            " 89.610001 89.559998 88.709999 88.970001 89.160004 89.160004 89.260002\n",
            " 89.830002 89.370003 88.769997 88.580002 88.629997 88.169998 89.290001\n",
            " 89.019997 90.129997 90.580002 90.110001 90.769997 90.580002 89.93\n",
            " 89.769997 89.010002 88.599998 88.769997 88.68     89.220001 88.989998\n",
            " 86.489998 86.610001 86.080002 86.620003 87.449997]\n",
            "F no zero:  [88.709999 88.550003 88.959999 87.93     88.480003 88.139999 89.099998\n",
            " 89.610001 89.580002 89.529999 89.470001 90.199997 90.800003 90.919998\n",
            " 90.699997 91.349998 91.730003 91.110001 91.760002 90.669998 89.970001\n",
            " 90.040001 89.150002 89.739998 89.790001 88.25     88.610001 88.279999\n",
            " 88.459999 88.669998 88.519997 88.360001 89.32     88.970001 88.589996\n",
            " 89.199997 87.699997 88.510002 89.529999 89.550003 89.43     88.949997\n",
            " 89.610001 89.559998 88.709999 88.970001 89.160004 89.160004 89.260002\n",
            " 89.830002 89.370003 88.769997 88.580002 88.629997 88.169998 89.290001\n",
            " 89.019997 90.129997 90.580002 90.110001 90.769997 90.580002 89.93\n",
            " 89.769997 89.010002 88.599998 88.769997 88.68     89.220001 88.989998\n",
            " 86.489998 86.610001 86.080002 86.620003 87.449997]\n",
            "spot price no zero:  88.709999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.05793649\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.2650423833536799\n",
            "Beta: 0.9999999184428523\n",
            "Rho: -0.010103722098842765\n",
            "Nu: 0.3182044562526008\n",
            "Iteration 0, Loss: 800256000.0\n",
            "Loss-1 (IC): 0.0013073714217171073, Loss-2 (pde): 5.235889693722129e-05 , Loss-5 (bd): 800256000.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 16548189.0\n",
            "Loss-1 (IC): 0.0013675063382834196, Loss-2 (pde): 4.407342433929443 , Loss-5 (bd): 16548185.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 482430.375\n",
            "Loss-1 (IC): 0.0013454653089866042, Loss-2 (pde): 4.9114251136779785 , Loss-5 (bd): 482425.46875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 161109.125\n",
            "Loss-1 (IC): 0.0012835306115448475, Loss-2 (pde): 8.099528312683105 , Loss-5 (bd): 161101.03125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 158258.796875\n",
            "Loss-1 (IC): 0.001399379805661738, Loss-2 (pde): 30.770551681518555 , Loss-5 (bd): 158228.03125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 457806.5625\n",
            "Loss-1 (IC): 0.0014813574962317944, Loss-2 (pde): 38.90938949584961 , Loss-5 (bd): 457767.65625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 174716.84375\n",
            "Loss-1 (IC): 0.001444549416191876, Loss-2 (pde): 39.976890563964844 , Loss-5 (bd): 174676.859375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 99098.3828125\n",
            "Loss-1 (IC): 0.001372281345538795, Loss-2 (pde): 49.311309814453125 , Loss-5 (bd): 99049.0703125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 697680.125\n",
            "Loss-1 (IC): 0.0012954105623066425, Loss-2 (pde): 60.24769973754883 , Loss-5 (bd): 697619.875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 170796.515625\n",
            "Loss-1 (IC): 0.0013739961432293057, Loss-2 (pde): 62.367610931396484 , Loss-5 (bd): 170734.140625\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  51205.015625\n",
            "Model 849 iterasyondan yüklendi, Loss: 51205.015625\n",
            "MSE between MC-book and PINN: 0.5938034567869213\n",
            "MAPE between MC-book and PINN:: 0.013747217806523332\n",
            "Processing sheet: WMT\n",
            "F:  [69.239998 68.800003 69.059998 68.400002 68.589996 68.57     68.360001\n",
            " 68.629997 68.300003 68.980003 69.209999 68.849998 69.199997 69.580002\n",
            " 69.489998 69.790001 69.       69.349998 69.889999 69.75     69.949997\n",
            " 70.489998 69.629997 70.769997 71.309998 71.230003 71.480003 71.400002\n",
            " 71.400002 71.389999 70.82     69.300003 68.760002 69.209999 70.260002\n",
            " 70.400002 70.440002 71.110001 71.660004 70.779999 71.739998 73.260002\n",
            " 73.720001 73.379997 73.32     73.029999 72.980003 73.599998 73.650002\n",
            " 73.220001 72.5     ]\n",
            "F no zero:  [69.239998 68.800003 69.059998 68.400002 68.589996 68.57     68.360001\n",
            " 68.629997 68.300003 68.980003 69.209999 68.849998 69.199997 69.580002\n",
            " 69.489998 69.790001 69.       69.349998 69.889999 69.75     69.949997\n",
            " 70.489998 69.629997 70.769997 71.309998 71.230003 71.480003 71.400002\n",
            " 71.400002 71.389999 70.82     69.300003 68.760002 69.209999 70.260002\n",
            " 70.400002 70.440002 71.110001 71.660004 70.779999 71.739998 73.260002\n",
            " 73.720001 73.379997 73.32     73.029999 72.980003 73.599998 73.650002\n",
            " 73.220001 72.5     ]\n",
            "spot price no zero:  69.239998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.038769609999999996\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.3122491394703859\n",
            "Beta: 0.9999846854074492\n",
            "Rho: -0.1432537072230218\n",
            "Nu: 0.6492500528920278\n",
            "Iteration 0, Loss: 454323840.0\n",
            "Loss-1 (IC): 0.0007003931095823646, Loss-2 (pde): 5.9263849834678695e-05 , Loss-5 (bd): 454323840.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 8556647.0\n",
            "Loss-1 (IC): 0.0008485243888571858, Loss-2 (pde): 20.71780014038086 , Loss-5 (bd): 8556626.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 285168.8125\n",
            "Loss-1 (IC): 0.0008934293873608112, Loss-2 (pde): 25.28308868408203 , Loss-5 (bd): 285143.53125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 137082.640625\n",
            "Loss-1 (IC): 0.0008536080713383853, Loss-2 (pde): 30.245420455932617 , Loss-5 (bd): 137052.390625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 109743.0859375\n",
            "Loss-1 (IC): 0.0008694232674315572, Loss-2 (pde): 35.22802734375 , Loss-5 (bd): 109707.859375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 103195.9375\n",
            "Loss-1 (IC): 0.0008144910680130124, Loss-2 (pde): 32.8951416015625 , Loss-5 (bd): 103163.0390625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 219192.796875\n",
            "Loss-1 (IC): 0.000827292853500694, Loss-2 (pde): 37.690650939941406 , Loss-5 (bd): 219155.109375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 119885.828125\n",
            "Loss-1 (IC): 0.0008185832994058728, Loss-2 (pde): 35.35429382324219 , Loss-5 (bd): 119850.4765625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 63012.66796875\n",
            "Loss-1 (IC): 0.0008507254533469677, Loss-2 (pde): 37.52734375 , Loss-5 (bd): 62975.140625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 256075.03125\n",
            "Loss-1 (IC): 0.000799428962636739, Loss-2 (pde): 36.94114303588867 , Loss-5 (bd): 256038.09375\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  28279.126953125\n",
            "Model 931 iterasyondan yüklendi, Loss: 28279.126953\n",
            "MSE between MC-book and PINN: 0.8927806049888906\n",
            "MAPE between MC-book and PINN:: 0.011229342049291621\n",
            "Processing sheet: MSFT\n",
            "F:  [27.620001 27.25     26.74     26.690001 26.549999 26.700001 26.459999\n",
            " 26.83     26.889999 27.209999 27.040001 27.25     27.25     27.15\n",
            " 27.610001 27.629999 27.879999 27.91     28.01     27.85     27.450001\n",
            " 27.93     27.440001 27.5      27.34     27.280001 27.549999 27.860001\n",
            " 27.879999 28.030001 28.040001 28.01     28.049999 27.870001 27.49\n",
            " 27.76     27.370001 27.370001 27.809999 27.799999 27.950001 28.15\n",
            " 28.35     28.09     28.139999 28.       27.870001 27.91     27.92\n",
            " 28.139999 28.040001 28.1      28.18     28.32     28.110001 28.25\n",
            " 28.16     28.16     28.370001 28.610001 28.610001 28.799999 28.559999\n",
            " 28.6      28.700001 28.59     29.610001 30.280001 28.940001 28.790001\n",
            " 28.690001 28.969999 28.83     28.790001 29.77    ]\n",
            "F no zero:  [27.620001 27.25     26.74     26.690001 26.549999 26.700001 26.459999\n",
            " 26.83     26.889999 27.209999 27.040001 27.25     27.25     27.15\n",
            " 27.610001 27.629999 27.879999 27.91     28.01     27.85     27.450001\n",
            " 27.93     27.440001 27.5      27.34     27.280001 27.549999 27.860001\n",
            " 27.879999 28.030001 28.040001 28.01     28.049999 27.870001 27.49\n",
            " 27.76     27.370001 27.370001 27.809999 27.799999 27.950001 28.15\n",
            " 28.35     28.09     28.139999 28.       27.870001 27.91     27.92\n",
            " 28.139999 28.040001 28.1      28.18     28.32     28.110001 28.25\n",
            " 28.16     28.16     28.370001 28.610001 28.610001 28.799999 28.559999\n",
            " 28.6      28.700001 28.59     29.610001 30.280001 28.940001 28.790001\n",
            " 28.690001 28.969999 28.83     28.790001 29.77    ]\n",
            "spot price no zero:  27.620001\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.061404839999999995\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.3161462654563922\n",
            "Beta: 0.9999871313846183\n",
            "Rho: -0.0908259803559365\n",
            "Nu: 0.45643364747103166\n",
            "Iteration 0, Loss: 97010632.0\n",
            "Loss-1 (IC): 0.000143377561471425, Loss-2 (pde): 1.5496176274609752e-05 , Loss-5 (bd): 97010632.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 991420.8125\n",
            "Loss-1 (IC): 0.00014792298316024244, Loss-2 (pde): 0.11521277576684952 , Loss-5 (bd): 991420.6875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 182831.828125\n",
            "Loss-1 (IC): 0.00015507593343500048, Loss-2 (pde): 0.15539497137069702 , Loss-5 (bd): 182831.671875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 75028.1640625\n",
            "Loss-1 (IC): 0.00015023630112409592, Loss-2 (pde): 0.46861425042152405 , Loss-5 (bd): 75027.6953125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 38097.65234375\n",
            "Loss-1 (IC): 0.0001459482591599226, Loss-2 (pde): 0.8103513121604919 , Loss-5 (bd): 38096.84375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 36948.21875\n",
            "Loss-1 (IC): 0.000149519692058675, Loss-2 (pde): 0.8771176934242249 , Loss-5 (bd): 36947.33984375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 27746.173828125\n",
            "Loss-1 (IC): 0.0001428518444299698, Loss-2 (pde): 0.9936301708221436 , Loss-5 (bd): 27745.1796875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 25609.28515625\n",
            "Loss-1 (IC): 0.00014626668416894972, Loss-2 (pde): 0.9352279305458069 , Loss-5 (bd): 25608.349609375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 17751.94921875\n",
            "Loss-1 (IC): 0.00014264590572565794, Loss-2 (pde): 0.7279182076454163 , Loss-5 (bd): 17751.220703125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 18027.68359375\n",
            "Loss-1 (IC): 0.00015082380559761077, Loss-2 (pde): 0.6695753931999207 , Loss-5 (bd): 18027.013671875\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  8503.904296875\n",
            "Model 996 iterasyondan yüklendi, Loss: 8503.904297\n",
            "MSE between MC-book and PINN: 0.09557705434531004\n",
            "MAPE between MC-book and PINN:: 0.0202512356864218\n",
            "Processing sheet: BRKB\n",
            "F:  [ 93.199997  93.620003  93.849998  93.449997  93.809998  93.32\n",
            "  94.650002  94.389999  95.360001  95.360001  95.029999  95.300003\n",
            "  95.160004  95.910004  96.480003  97.309998  97.389999  97.120003\n",
            "  97.239998  96.879997  96.93      98.        96.510002  97.910004\n",
            "  97.830002  97.110001  97.25      97.129997  97.699997  97.970001\n",
            "  99.209999  99.769997 101.019997 100.220001 100.169998 101.209999\n",
            "  98.580002  98.720001 101.209999 102.160004 102.050003 101.949997\n",
            " 102.660004 103.239998 103.410004 103.629997 104.07     103.010002\n",
            " 103.650002 103.989998 102.790001]\n",
            "F no zero:  [ 93.199997  93.620003  93.849998  93.449997  93.809998  93.32\n",
            "  94.650002  94.389999  95.360001  95.360001  95.029999  95.300003\n",
            "  95.160004  95.910004  96.480003  97.309998  97.389999  97.120003\n",
            "  97.239998  96.879997  96.93      98.        96.510002  97.910004\n",
            "  97.830002  97.110001  97.25      97.129997  97.699997  97.970001\n",
            "  99.209999  99.769997 101.019997 100.220001 100.169998 101.209999\n",
            "  98.580002  98.720001 101.209999 102.160004 102.050003 101.949997\n",
            " 102.660004 103.239998 103.410004 103.629997 104.07     103.010002\n",
            " 103.650002 103.989998 102.790001]\n",
            "spot price no zero:  93.199997\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.03437316000000001\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.24454514042587946\n",
            "Beta: 0.9999964148561682\n",
            "Rho: -0.04222786803734035\n",
            "Nu: 0.3973061629948772\n",
            "Iteration 0, Loss: 1296311680.0\n",
            "Loss-1 (IC): 0.002093588700518012, Loss-2 (pde): 0.0019911625422537327 , Loss-5 (bd): 1296311680.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 30625426.0\n",
            "Loss-1 (IC): 0.0021889416966587305, Loss-2 (pde): 42.854068756103516 , Loss-5 (bd): 30625384.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 298813.3125\n",
            "Loss-1 (IC): 0.0020575460512191057, Loss-2 (pde): 38.70063018798828 , Loss-5 (bd): 298774.625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 338187.6875\n",
            "Loss-1 (IC): 0.0021567444782704115, Loss-2 (pde): 73.40025329589844 , Loss-5 (bd): 338114.28125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 139141.84375\n",
            "Loss-1 (IC): 0.0020294159185141325, Loss-2 (pde): 104.09184265136719 , Loss-5 (bd): 139037.75\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 124998.421875\n",
            "Loss-1 (IC): 0.002021189546212554, Loss-2 (pde): 108.93431854248047 , Loss-5 (bd): 124889.484375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 568342.5625\n",
            "Loss-1 (IC): 0.0019506316166371107, Loss-2 (pde): 112.77465057373047 , Loss-5 (bd): 568229.8125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 139087.921875\n",
            "Loss-1 (IC): 0.0020840968936681747, Loss-2 (pde): 100.07098388671875 , Loss-5 (bd): 138987.84375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 85578.28125\n",
            "Loss-1 (IC): 0.0019947506953030825, Loss-2 (pde): 89.53262329101562 , Loss-5 (bd): 85488.75\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 467579.25\n",
            "Loss-1 (IC): 0.0020262938924133778, Loss-2 (pde): 133.54891967773438 , Loss-5 (bd): 467445.6875\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  68470.15625\n",
            "Model 985 iterasyondan yüklendi, Loss: 68470.156250\n",
            "MSE between MC-book and PINN: 1.809251844205421\n",
            "MAPE between MC-book and PINN:: 0.0063688112342346025\n",
            "Processing sheet: CVX\n",
            "F:  [110.389999 109.919998 110.5      109.75     109.260002 109.540001\n",
            " 110.470001 111.730003 112.849998 113.440002 113.970001 114.739998\n",
            " 115.239998 115.910004 115.010002 115.5      116.199997 116.040001\n",
            " 117.209999 116.449997 115.150002 116.5      115.199997 115.809998\n",
            " 115.910004 115.019997 115.639999 115.639999 116.5      115.529999\n",
            " 115.709999 114.959999 115.919998 114.989998 114.989998 115.959999\n",
            " 113.540001 114.959999 116.650002 117.150002 116.900002 117.489998\n",
            " 117.93     118.470001 118.559998 118.57     118.730003 118.25\n",
            " 118.360001 120.       119.68    ]\n",
            "F no zero:  [110.389999 109.919998 110.5      109.75     109.260002 109.540001\n",
            " 110.470001 111.730003 112.849998 113.440002 113.970001 114.739998\n",
            " 115.239998 115.910004 115.010002 115.5      116.199997 116.040001\n",
            " 117.209999 116.449997 115.150002 116.5      115.199997 115.809998\n",
            " 115.910004 115.019997 115.639999 115.639999 116.5      115.529999\n",
            " 115.709999 114.959999 115.919998 114.989998 114.989998 115.959999\n",
            " 113.540001 114.959999 116.650002 117.150002 116.900002 117.489998\n",
            " 117.93     118.470001 118.559998 118.57     118.730003 118.25\n",
            " 118.360001 120.       119.68    ]\n",
            "spot price no zero:  110.389999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.038025\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.25923496031436066\n",
            "Beta: 0.9999952855504395\n",
            "Rho: -0.050280912412456615\n",
            "Nu: 0.4077337847442367\n",
            "Iteration 0, Loss: 1543291520.0\n",
            "Loss-1 (IC): 0.002496897941455245, Loss-2 (pde): 0.00035428424598649144 , Loss-5 (bd): 1543291520.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 64444072.0\n",
            "Loss-1 (IC): 0.002200628397986293, Loss-2 (pde): 6.646195411682129 , Loss-5 (bd): 64444064.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 436774.9375\n",
            "Loss-1 (IC): 0.002619554055854678, Loss-2 (pde): 54.85893630981445 , Loss-5 (bd): 436720.0625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 307856.0\n",
            "Loss-1 (IC): 0.0025237579829990864, Loss-2 (pde): 61.3728141784668 , Loss-5 (bd): 307794.625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 1218120.875\n",
            "Loss-1 (IC): 0.0026423439849168062, Loss-2 (pde): 64.58964538574219 , Loss-5 (bd): 1218056.25\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 257090.109375\n",
            "Loss-1 (IC): 0.0026662922464311123, Loss-2 (pde): 70.93284606933594 , Loss-5 (bd): 257019.171875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 152679.421875\n",
            "Loss-1 (IC): 0.0026586188469082117, Loss-2 (pde): 86.32868957519531 , Loss-5 (bd): 152593.09375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 3804062.25\n",
            "Loss-1 (IC): 0.0026104305870831013, Loss-2 (pde): 106.15531158447266 , Loss-5 (bd): 3803956.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 108037.9609375\n",
            "Loss-1 (IC): 0.0024755760096013546, Loss-2 (pde): 149.94418334960938 , Loss-5 (bd): 107888.015625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 425347.46875\n",
            "Loss-1 (IC): 0.002492853906005621, Loss-2 (pde): 132.85281372070312 , Loss-5 (bd): 425214.625\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  86110.1640625\n",
            "Model 955 iterasyondan yüklendi, Loss: 86110.164062\n",
            "MSE between MC-book and PINN: 0.09657168915384937\n",
            "MAPE between MC-book and PINN:: 0.0035191286980875204\n",
            "Processing sheet: IBM\n",
            "F:  [196.350006 195.270004 193.990005 193.139999 192.869995 192.320007\n",
            " 192.880005 194.449997 192.619995 192.5      192.589996 193.649994\n",
            " 194.470001 196.080002 204.720001 204.419998 204.970001 204.929993\n",
            " 203.899994 203.520004 203.070007 205.179993 203.789993 202.789993\n",
            " 201.020004 199.740005 201.679993 200.160004 200.039993 200.089996\n",
            " 199.649994 200.979996 200.320007 199.309998 198.330002 201.089996\n",
            " 197.509995 199.139999 202.330002 200.830002 202.910004 205.190002\n",
            " 206.529999 208.380005 209.419998 210.380005 210.080002 210.550003\n",
            " 212.059998 215.800003 214.919998 213.210007 213.440002 215.059998\n",
            " 212.259995 212.080002 210.740005 212.360001 210.889999 213.300003\n",
            " 212.380005 214.360001 212.660004 211.309998 209.410004 209.320007\n",
            " 209.220001 212.       212.919998 211.380005 209.259995 212.\n",
            " 209.669998 207.149994 190.      ]\n",
            "F no zero:  [196.350006 195.270004 193.990005 193.139999 192.869995 192.320007\n",
            " 192.880005 194.449997 192.619995 192.5      192.589996 193.649994\n",
            " 194.470001 196.080002 204.720001 204.419998 204.970001 204.929993\n",
            " 203.899994 203.520004 203.070007 205.179993 203.789993 202.789993\n",
            " 201.020004 199.740005 201.679993 200.160004 200.039993 200.089996\n",
            " 199.649994 200.979996 200.320007 199.309998 198.330002 201.089996\n",
            " 197.509995 199.139999 202.330002 200.830002 202.910004 205.190002\n",
            " 206.529999 208.380005 209.419998 210.380005 210.080002 210.550003\n",
            " 212.059998 215.800003 214.919998 213.210007 213.440002 215.059998\n",
            " 212.259995 212.080002 210.740005 212.360001 210.889999 213.300003\n",
            " 212.380005 214.360001 212.660004 211.309998 209.410004 209.320007\n",
            " 209.220001 212.       212.919998 211.380005 209.259995 212.\n",
            " 209.669998 207.149994 190.      ]\n",
            "spot price no zero:  196.350006\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.066564\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.26093073739791905\n",
            "Beta: 1.0\n",
            "Rho: -0.000256158630742672\n",
            "Nu: 0.3004349009684718\n",
            "Iteration 0, Loss: 5267293184.0\n",
            "Loss-1 (IC): 0.00698075583204627, Loss-2 (pde): 0.0014843499520793557 , Loss-5 (bd): 5267293184.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 348503840.0\n",
            "Loss-1 (IC): 0.0070731486193835735, Loss-2 (pde): 39.85143280029297 , Loss-5 (bd): 348503808.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 4344775.0\n",
            "Loss-1 (IC): 0.008303350768983364, Loss-2 (pde): 2469.3173828125 , Loss-5 (bd): 4342305.5\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 832878.8125\n",
            "Loss-1 (IC): 0.008635751903057098, Loss-2 (pde): 1167.769287109375 , Loss-5 (bd): 831711.0625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 625750.375\n",
            "Loss-1 (IC): 0.008678215555846691, Loss-2 (pde): 1091.574951171875 , Loss-5 (bd): 624658.8125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 542522.6875\n",
            "Loss-1 (IC): 0.00848945789039135, Loss-2 (pde): 961.356201171875 , Loss-5 (bd): 541561.3125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 668001.875\n",
            "Loss-1 (IC): 0.008340596221387386, Loss-2 (pde): 1289.6324462890625 , Loss-5 (bd): 666712.25\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 534725.375\n",
            "Loss-1 (IC): 0.008553657680749893, Loss-2 (pde): 717.0341186523438 , Loss-5 (bd): 534008.3125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 6156636.5\n",
            "Loss-1 (IC): 0.008365754038095474, Loss-2 (pde): 671.8326416015625 , Loss-5 (bd): 6155964.5\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 13939760.0\n",
            "Loss-1 (IC): 0.007617664057761431, Loss-2 (pde): 900.1640625 , Loss-5 (bd): 13938860.0\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  234096.421875\n",
            "Model 875 iterasyondan yüklendi, Loss: 234096.421875\n",
            "MSE between MC-book and PINN: 0.09635265689472576\n",
            "MAPE between MC-book and PINN:: 0.0024238789516839933\n",
            "Processing sheet: JNJ\n",
            "F:  [70.839996 70.739998 71.550003 71.400002 71.410004 71.730003 72.190002\n",
            " 72.349998 72.559998 72.370003 72.580002 72.900002 73.230003 72.690002\n",
            " 72.849998 73.099998 73.919998 73.620003 74.410004 74.089996 73.919998\n",
            " 74.18     74.110001 74.660004 75.389999 75.059998 75.480003 75.410004\n",
            " 75.800003 75.660004 75.809998 76.160004 76.959999 76.650002 76.870003\n",
            " 76.25     75.57     75.75     76.32     76.110001 76.699997 77.199997\n",
            " 77.660004 77.389999 77.75     78.190002 78.440002 78.559998 78.550003\n",
            " 79.099998 79.190002 78.809998 78.860001 79.449997 79.010002 79.739998\n",
            " 79.68     80.849998 81.269997 81.529999 81.93     82.690002 82.07\n",
            " 82.410004 82.040001 81.110001 81.519997 82.019997 82.32     82.739998\n",
            " 81.709999 83.440002 83.900002 83.18     84.489998]\n",
            "F no zero:  [70.839996 70.739998 71.550003 71.400002 71.410004 71.730003 72.190002\n",
            " 72.349998 72.559998 72.370003 72.580002 72.900002 73.230003 72.690002\n",
            " 72.849998 73.099998 73.919998 73.620003 74.410004 74.089996 73.919998\n",
            " 74.18     74.110001 74.660004 75.389999 75.059998 75.480003 75.410004\n",
            " 75.800003 75.660004 75.809998 76.160004 76.959999 76.650002 76.870003\n",
            " 76.25     75.57     75.75     76.32     76.110001 76.699997 77.199997\n",
            " 77.660004 77.389999 77.75     78.190002 78.440002 78.559998 78.550003\n",
            " 79.099998 79.190002 78.809998 78.860001 79.449997 79.010002 79.739998\n",
            " 79.68     80.849998 81.269997 81.529999 81.93     82.690002 82.07\n",
            " 82.410004 82.040001 81.110001 81.519997 82.019997 82.32     82.739998\n",
            " 81.709999 83.440002 83.900002 83.18     84.489998]\n",
            "spot price no zero:  70.839996\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.034151039999999994\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.2802635802845355\n",
            "Beta: 0.999982758731577\n",
            "Rho: -0.11681102648830906\n",
            "Nu: 0.5445565756918634\n",
            "Iteration 0, Loss: 701379904.0\n",
            "Loss-1 (IC): 0.0010135292541235685, Loss-2 (pde): 0.0003022690361831337 , Loss-5 (bd): 701379904.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 24909078.0\n",
            "Loss-1 (IC): 0.0009998230962082744, Loss-2 (pde): 18.140718460083008 , Loss-5 (bd): 24909060.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 610321.1875\n",
            "Loss-1 (IC): 0.0010742887388914824, Loss-2 (pde): 12.195502281188965 , Loss-5 (bd): 610309.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 344203.21875\n",
            "Loss-1 (IC): 0.0011313674040138721, Loss-2 (pde): 9.019447326660156 , Loss-5 (bd): 344194.1875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 201543.421875\n",
            "Loss-1 (IC): 0.0010771079687401652, Loss-2 (pde): 16.719982147216797 , Loss-5 (bd): 201526.703125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 87576.3125\n",
            "Loss-1 (IC): 0.001020439201965928, Loss-2 (pde): 31.9765567779541 , Loss-5 (bd): 87544.3359375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 88941.8125\n",
            "Loss-1 (IC): 0.0010511447908356786, Loss-2 (pde): 33.739192962646484 , Loss-5 (bd): 88908.0703125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 80322.7734375\n",
            "Loss-1 (IC): 0.0011132934596389532, Loss-2 (pde): 38.48146438598633 , Loss-5 (bd): 80284.2890625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 112685.3125\n",
            "Loss-1 (IC): 0.0010705082677304745, Loss-2 (pde): 51.18184280395508 , Loss-5 (bd): 112634.1328125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 55048.5859375\n",
            "Loss-1 (IC): 0.001120407017879188, Loss-2 (pde): 50.09959411621094 , Loss-5 (bd): 54998.484375\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  49587.2734375\n",
            "Model 973 iterasyondan yüklendi, Loss: 49587.273438\n",
            "MSE between MC-book and PINN: 2.4378984874587384\n",
            "MAPE between MC-book and PINN:: 0.028757044954098678\n",
            "Processing sheet: PG\n",
            "F:  [69.389999 68.949997 69.089996 68.620003 68.510002 68.879997 69.269997\n",
            " 69.220001 69.629997 69.879997 69.339996 69.669998 69.940002 69.949997\n",
            " 70.690002 70.419998 73.25     73.769997 75.       75.080002 75.160004\n",
            " 75.919998 75.25     75.699997 76.150002 76.150002 75.75     75.809998\n",
            " 75.980003 76.559998 76.779999 76.540001 77.379997 77.080002 77.040001\n",
            " 76.989998 75.919998 76.080002 76.75     76.18     76.489998 76.68\n",
            " 77.050003 77.199997 76.900002 77.18     77.349998 77.169998 76.800003\n",
            " 77.389999 76.339996 76.160004 77.110001 77.580002 77.209999 77.269997\n",
            " 76.68     77.400002 77.059998 77.059998 77.699997 78.959999 78.120003\n",
            " 78.540001 78.230003 78.790001 78.260002 79.239998 79.669998 80.080002\n",
            " 79.650002 80.099998 79.059998 79.870003 81.43    ]\n",
            "F no zero:  [69.389999 68.949997 69.089996 68.620003 68.510002 68.879997 69.269997\n",
            " 69.220001 69.629997 69.879997 69.339996 69.669998 69.940002 69.949997\n",
            " 70.690002 70.419998 73.25     73.769997 75.       75.080002 75.160004\n",
            " 75.919998 75.25     75.699997 76.150002 76.150002 75.75     75.809998\n",
            " 75.980003 76.559998 76.779999 76.540001 77.379997 77.080002 77.040001\n",
            " 76.989998 75.919998 76.080002 76.75     76.18     76.489998 76.68\n",
            " 77.050003 77.199997 76.900002 77.18     77.349998 77.169998 76.800003\n",
            " 77.389999 76.339996 76.160004 77.110001 77.580002 77.209999 77.269997\n",
            " 76.68     77.400002 77.059998 77.059998 77.699997 78.959999 78.120003\n",
            " 78.540001 78.230003 78.790001 78.260002 79.239998 79.669998 80.080002\n",
            " 79.650002 80.099998 79.059998 79.870003 81.43    ]\n",
            "spot price no zero:  69.389999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.011620840000000002\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.1942046591461558\n",
            "Beta: 0.9999944631049601\n",
            "Rho: -0.09638379876732651\n",
            "Nu: 0.7526668841101247\n",
            "Iteration 0, Loss: 852558208.0\n",
            "Loss-1 (IC): 0.0013566705165430903, Loss-2 (pde): 1.8527889551478438e-05 , Loss-5 (bd): 852558208.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 38638180.0\n",
            "Loss-1 (IC): 0.0010770222870633006, Loss-2 (pde): 10.461464881896973 , Loss-5 (bd): 38638168.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 300482.40625\n",
            "Loss-1 (IC): 0.0012847607722505927, Loss-2 (pde): 5.283923625946045 , Loss-5 (bd): 300477.125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 245543.0625\n",
            "Loss-1 (IC): 0.0012248484417796135, Loss-2 (pde): 7.167771339416504 , Loss-5 (bd): 245535.890625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 161297.953125\n",
            "Loss-1 (IC): 0.0012044465402141213, Loss-2 (pde): 11.57266616821289 , Loss-5 (bd): 161286.375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 106331.234375\n",
            "Loss-1 (IC): 0.0012761479010805488, Loss-2 (pde): 17.037900924682617 , Loss-5 (bd): 106314.1953125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 94380.15625\n",
            "Loss-1 (IC): 0.0012521562166512012, Loss-2 (pde): 30.490026473999023 , Loss-5 (bd): 94349.6640625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 262686.5625\n",
            "Loss-1 (IC): 0.0012613291619345546, Loss-2 (pde): 38.359004974365234 , Loss-5 (bd): 262648.1875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 94288.953125\n",
            "Loss-1 (IC): 0.0012777645606547594, Loss-2 (pde): 44.84499740600586 , Loss-5 (bd): 94244.109375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 56909.09765625\n",
            "Loss-1 (IC): 0.0012577848974615335, Loss-2 (pde): 47.19498825073242 , Loss-5 (bd): 56861.90234375\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  35822.734375\n",
            "Model 991 iterasyondan yüklendi, Loss: 35822.734375\n",
            "MSE between MC-book and PINN: 0.8027548265147676\n",
            "MAPE between MC-book and PINN:: 0.014440474465172342\n",
            "Processing sheet: WFC\n",
            "F:  [35.049999 34.759998 34.939999 34.77     34.709999 34.709999 35.400002\n",
            " 35.099998 34.77     35.110001 35.09     35.029999 34.93     35.040001\n",
            " 34.950001 35.16     35.139999 35.110001 35.27     34.970001 34.830002\n",
            " 35.130001 34.759998 34.849998 34.970001 34.66     34.880001 35.259998\n",
            " 35.509998 35.130001 35.209999 35.16     35.139999 35.099998 35.459999\n",
            " 35.82     34.790001 34.75     35.130001 35.080002 35.389999 35.849998\n",
            " 35.880001 36.049999 36.419998 36.5      37.130001 36.66     36.77\n",
            " 36.970001 38.200001 37.759998 37.490002 37.439999 37.139999 37.200001\n",
            " 37.209999 37.299999 36.98     36.990002 36.93     36.880001 36.669998\n",
            " 37.419998 37.150002 37.02     37.450001 37.57     37.509998 37.209999\n",
            " 36.57     37.060001 36.560001 36.27     36.689999]\n",
            "F no zero:  [35.049999 34.759998 34.939999 34.77     34.709999 34.709999 35.400002\n",
            " 35.099998 34.77     35.110001 35.09     35.029999 34.93     35.040001\n",
            " 34.950001 35.16     35.139999 35.110001 35.27     34.970001 34.830002\n",
            " 35.130001 34.759998 34.849998 34.970001 34.66     34.880001 35.259998\n",
            " 35.509998 35.130001 35.209999 35.16     35.139999 35.099998 35.459999\n",
            " 35.82     34.790001 34.75     35.130001 35.080002 35.389999 35.849998\n",
            " 35.880001 36.049999 36.419998 36.5      37.130001 36.66     36.77\n",
            " 36.970001 38.200001 37.759998 37.490002 37.439999 37.139999 37.200001\n",
            " 37.209999 37.299999 36.98     36.990002 36.93     36.880001 36.669998\n",
            " 37.419998 37.150002 37.02     37.450001 37.57     37.509998 37.209999\n",
            " 36.57     37.060001 36.560001 36.27     36.689999]\n",
            "spot price no zero:  35.049999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.17796671825509938\n",
            "kappa: 2.00000044686477\n",
            "theta: 0.03999357458424606\n",
            "sigma_heston: 0.09999021824125852\n",
            "rho_heston: -0.6999988252452679\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.38121901812519027\n",
            "Beta: 0.8946703025209252\n",
            "Rho: 0.09944714626081709\n",
            "Nu: 0.2732813944502615\n",
            "Iteration 0, Loss: 197571136.0\n",
            "Loss-1 (IC): 0.00028979594935663044, Loss-2 (pde): 2.1727746570832096e-06 , Loss-5 (bd): 197571136.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 1742080.5\n",
            "Loss-1 (IC): 0.00028146622935310006, Loss-2 (pde): 0.1888674944639206 , Loss-5 (bd): 1742080.25\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 207758.078125\n",
            "Loss-1 (IC): 0.000281198212178424, Loss-2 (pde): 0.23519033193588257 , Loss-5 (bd): 207757.84375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 84025.3671875\n",
            "Loss-1 (IC): 0.00029496426577679813, Loss-2 (pde): 0.8971015810966492 , Loss-5 (bd): 84024.46875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 47412.390625\n",
            "Loss-1 (IC): 0.0002941999409813434, Loss-2 (pde): 0.9151721596717834 , Loss-5 (bd): 47411.4765625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 41108.95703125\n",
            "Loss-1 (IC): 0.00029877660563215613, Loss-2 (pde): 0.6993513703346252 , Loss-5 (bd): 41108.2578125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 35958.65234375\n",
            "Loss-1 (IC): 0.00028909777756780386, Loss-2 (pde): 0.4475375711917877 , Loss-5 (bd): 35958.203125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 25399.869140625\n",
            "Loss-1 (IC): 0.0002911066694650799, Loss-2 (pde): 0.24682550132274628 , Loss-5 (bd): 25399.62109375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 22390.81640625\n",
            "Loss-1 (IC): 0.00027855433290824294, Loss-2 (pde): 0.11022578924894333 , Loss-5 (bd): 22390.705078125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 26955.62890625\n",
            "Loss-1 (IC): 0.000290635391138494, Loss-2 (pde): 0.07783528417348862 , Loss-5 (bd): 26955.55078125\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  7799.837890625\n",
            "Model 991 iterasyondan yüklendi, Loss: 7799.837891\n",
            "MSE between MC-book and PINN: 0.10320053640560546\n",
            "MAPE between MC-book and PINN:: 0.014216481322674595\n",
            "Processing sheet: PFE\n",
            "F:  [25.91     25.85     25.959999 25.98     26.02     26.469999 26.76\n",
            " 26.52     26.74     26.620001 26.610001 26.83     26.540001 26.68\n",
            " 26.65     26.85     27.       26.84     27.700001 27.51     27.280001\n",
            " 27.629999 27.17     27.51     27.32     26.959999 26.879999 27.139999\n",
            " 26.99     27.       27.059999 27.290001 27.709999 27.57     27.41\n",
            " 27.379999 26.84     27.030001 27.41     27.370001 27.389999 27.690001\n",
            " 28.07     28.120001 28.27     28.190001 28.25     27.940001 28.02\n",
            " 28.110001 28.02     28.040001 27.99     28.290001 28.110001 28.379999\n",
            " 28.16     28.6      28.639999 28.860001 28.84     29.23     29.030001\n",
            " 29.16     29.1      29.16     29.110001 29.92     30.639999 30.67\n",
            " 30.450001 30.940001 30.870001 30.59     31.059999]\n",
            "F no zero:  [25.91     25.85     25.959999 25.98     26.02     26.469999 26.76\n",
            " 26.52     26.74     26.620001 26.610001 26.83     26.540001 26.68\n",
            " 26.65     26.85     27.       26.84     27.700001 27.51     27.280001\n",
            " 27.629999 27.17     27.51     27.32     26.959999 26.879999 27.139999\n",
            " 26.99     27.       27.059999 27.290001 27.709999 27.57     27.41\n",
            " 27.379999 26.84     27.030001 27.41     27.370001 27.389999 27.690001\n",
            " 28.07     28.120001 28.27     28.190001 28.25     27.940001 28.02\n",
            " 28.110001 28.02     28.040001 27.99     28.290001 28.110001 28.379999\n",
            " 28.16     28.6      28.639999 28.860001 28.84     29.23     29.030001\n",
            " 29.16     29.1      29.16     29.110001 29.92     30.639999 30.67\n",
            " 30.450001 30.940001 30.870001 30.59     31.059999]\n",
            "spot price no zero:  25.91\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.018090250000000002\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.19571528779099773\n",
            "Beta: 0.999996504788061\n",
            "Rho: -0.0378384783200911\n",
            "Nu: 0.38174311057566485\n",
            "Iteration 0, Loss: 86894288.0\n",
            "Loss-1 (IC): 0.00011875625932589173, Loss-2 (pde): 2.6654421725336164e-11 , Loss-5 (bd): 86894288.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 1198135.875\n",
            "Loss-1 (IC): 0.00014352098514791578, Loss-2 (pde): 0.1018424853682518 , Loss-5 (bd): 1198135.75\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 144662.15625\n",
            "Loss-1 (IC): 0.00014615255349781364, Loss-2 (pde): 0.09801442921161652 , Loss-5 (bd): 144662.0625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 62868.53515625\n",
            "Loss-1 (IC): 0.00014024130359757692, Loss-2 (pde): 0.24635958671569824 , Loss-5 (bd): 62868.2890625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 36341.9453125\n",
            "Loss-1 (IC): 0.00014147166803013533, Loss-2 (pde): 0.28046584129333496 , Loss-5 (bd): 36341.6640625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 30322.705078125\n",
            "Loss-1 (IC): 0.00014434430340770632, Loss-2 (pde): 0.3972201943397522 , Loss-5 (bd): 30322.30859375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 24277.708984375\n",
            "Loss-1 (IC): 0.00014542040298692882, Loss-2 (pde): 0.6122965812683105 , Loss-5 (bd): 24277.095703125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 20473.43359375\n",
            "Loss-1 (IC): 0.00014079535321798176, Loss-2 (pde): 0.532680094242096 , Loss-5 (bd): 20472.900390625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 15186.8017578125\n",
            "Loss-1 (IC): 0.00013773806858807802, Loss-2 (pde): 0.44086042046546936 , Loss-5 (bd): 15186.3603515625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 22682.53515625\n",
            "Loss-1 (IC): 0.0001419567852281034, Loss-2 (pde): 0.40845420956611633 , Loss-5 (bd): 22682.126953125\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  7807.21337890625\n",
            "Model 971 iterasyondan yüklendi, Loss: 7807.213379\n",
            "MSE between MC-book and PINN: 0.08065248590026708\n",
            "MAPE between MC-book and PINN:: 0.01797241153869703\n",
            "Processing sheet: GE\n",
            "F:  [21.34     21.1      21.200001 21.129999 20.9      20.950001 21.17\n",
            " 21.129999 21.120001 21.200001 21.120001 21.299999 22.040001 22.01\n",
            " 21.940001 22.049999 22.290001 22.5      22.5      22.23     22.280001\n",
            " 22.620001 22.309999 22.540001 22.440001 22.48     22.5      22.450001\n",
            " 22.58     23.389999 23.41     23.290001 23.75     23.41     23.26\n",
            " 23.389999 22.809999 23.049999 23.370001 23.219999 23.190001 23.27\n",
            " 23.59     23.67     23.68     23.77     23.620001 23.41     23.49\n",
            " 23.690001 23.440001]\n",
            "F no zero:  [21.34     21.1      21.200001 21.129999 20.9      20.950001 21.17\n",
            " 21.129999 21.120001 21.200001 21.120001 21.299999 22.040001 22.01\n",
            " 21.940001 22.049999 22.290001 22.5      22.5      22.23     22.280001\n",
            " 22.620001 22.309999 22.540001 22.440001 22.48     22.5      22.450001\n",
            " 22.58     23.389999 23.41     23.290001 23.75     23.41     23.26\n",
            " 23.389999 22.809999 23.049999 23.370001 23.219999 23.190001 23.27\n",
            " 23.59     23.67     23.68     23.77     23.620001 23.41     23.49\n",
            " 23.690001 23.440001]\n",
            "spot price no zero:  21.34\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.29964676\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.5042151557333191\n",
            "Beta: 0.9151181749460191\n",
            "Rho: 0.07966238123740094\n",
            "Nu: 0.28042923319562363\n",
            "Iteration 0, Loss: 137392432.0\n",
            "Loss-1 (IC): 0.00020475563360378146, Loss-2 (pde): 3.6230296700523468e-06 , Loss-5 (bd): 137392432.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 883613.5\n",
            "Loss-1 (IC): 0.00016275593952741474, Loss-2 (pde): 0.08516834676265717 , Loss-5 (bd): 883613.4375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 74610.9921875\n",
            "Loss-1 (IC): 0.00017507541633676738, Loss-2 (pde): 0.6720754504203796 , Loss-5 (bd): 74610.3203125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 71585.7265625\n",
            "Loss-1 (IC): 0.00017496423970442265, Loss-2 (pde): 0.6993994116783142 , Loss-5 (bd): 71585.0234375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 48420.4375\n",
            "Loss-1 (IC): 0.00017253194528166205, Loss-2 (pde): 0.5685304999351501 , Loss-5 (bd): 48419.8671875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 42976.80078125\n",
            "Loss-1 (IC): 0.00017821697110775858, Loss-2 (pde): 0.42464980483055115 , Loss-5 (bd): 42976.375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 26230.443359375\n",
            "Loss-1 (IC): 0.00017364365339744836, Loss-2 (pde): 0.18701381981372833 , Loss-5 (bd): 26230.255859375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 17359.23828125\n",
            "Loss-1 (IC): 0.0001691907091299072, Loss-2 (pde): 0.07915402948856354 , Loss-5 (bd): 17359.158203125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 9640.6552734375\n",
            "Loss-1 (IC): 0.00017672391550149769, Loss-2 (pde): 0.028113314881920815 , Loss-5 (bd): 9640.626953125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 5908.9091796875\n",
            "Loss-1 (IC): 0.00017286118236370385, Loss-2 (pde): 0.017050445079803467 , Loss-5 (bd): 5908.89208984375\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  4753.51953125\n",
            "Model 989 iterasyondan yüklendi, Loss: 4753.519531\n",
            "MSE between MC-book and PINN: 0.025060962208128024\n",
            "MAPE between MC-book and PINN:: 0.007105314518860204\n",
            "Processing sheet: JPM\n",
            "F:  [44.66     44.57     45.360001 45.41     45.5      45.470001 46.150002\n",
            " 46.139999 45.880001 46.349998 46.82     46.439999 46.459999 46.540001\n",
            " 46.23     46.369999 47.16     46.639999 47.119999 47.130001 47.049999\n",
            " 47.849998 47.68     48.790001 48.610001 48.23     48.630001 48.66\n",
            " 49.139999 48.68     49.220001 48.880001 49.450001 48.610001 48.25\n",
            " 48.91     47.700001 47.599998 49.279999 48.919998 48.91     49.099998\n",
            " 49.490002 50.029999 50.630001 50.200001 50.48     50.279999 50.16\n",
            " 51.       50.02     49.509998 49.200001 49.119999 48.349998 48.779999\n",
            " 48.52     48.639999 47.77     47.459999 47.830002 48.279999 46.849998\n",
            " 47.490002 47.91     48.580002 48.68     49.25     49.310001 49.009998\n",
            " 47.93     48.490002 46.790001 46.639999 47.23    ]\n",
            "F no zero:  [44.66     44.57     45.360001 45.41     45.5      45.470001 46.150002\n",
            " 46.139999 45.880001 46.349998 46.82     46.439999 46.459999 46.540001\n",
            " 46.23     46.369999 47.16     46.639999 47.119999 47.130001 47.049999\n",
            " 47.849998 47.68     48.790001 48.610001 48.23     48.630001 48.66\n",
            " 49.139999 48.68     49.220001 48.880001 49.450001 48.610001 48.25\n",
            " 48.91     47.700001 47.599998 49.279999 48.919998 48.91     49.099998\n",
            " 49.490002 50.029999 50.630001 50.200001 50.48     50.279999 50.16\n",
            " 51.       50.02     49.509998 49.200001 49.119999 48.349998 48.779999\n",
            " 48.52     48.639999 47.77     47.459999 47.830002 48.279999 46.849998\n",
            " 47.490002 47.91     48.580002 48.68     49.25     49.310001 49.009998\n",
            " 47.93     48.490002 46.790001 46.639999 47.23    ]\n",
            "spot price no zero:  44.66\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.11628100000000002\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.3306174481256663\n",
            "Beta: 0.9685925648183247\n",
            "Rho: 0.019073781032785148\n",
            "Nu: 0.2909100897081254\n",
            "Iteration 0, Loss: 333358496.0\n",
            "Loss-1 (IC): 0.0004710259672719985, Loss-2 (pde): 3.5608769621831016e-07 , Loss-5 (bd): 333358496.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 3849842.75\n",
            "Loss-1 (IC): 0.00045398209476843476, Loss-2 (pde): 1.1911183595657349 , Loss-5 (bd): 3849841.5\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 172448.40625\n",
            "Loss-1 (IC): 0.0004992252797819674, Loss-2 (pde): 0.6612333655357361 , Loss-5 (bd): 172447.75\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 99133.2421875\n",
            "Loss-1 (IC): 0.0005241367034614086, Loss-2 (pde): 1.3734467029571533 , Loss-5 (bd): 99131.8671875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 63317.37890625\n",
            "Loss-1 (IC): 0.0004914437304250896, Loss-2 (pde): 2.0567917823791504 , Loss-5 (bd): 63315.3203125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 69468.8125\n",
            "Loss-1 (IC): 0.0005063808057457209, Loss-2 (pde): 1.7335963249206543 , Loss-5 (bd): 69467.078125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 46200.22265625\n",
            "Loss-1 (IC): 0.0004900735220871866, Loss-2 (pde): 1.8026914596557617 , Loss-5 (bd): 46198.41796875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 65110.11328125\n",
            "Loss-1 (IC): 0.0005078114336356521, Loss-2 (pde): 1.7713234424591064 , Loss-5 (bd): 65108.33984375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 76000.203125\n",
            "Loss-1 (IC): 0.000493386120069772, Loss-2 (pde): 1.390649676322937 , Loss-5 (bd): 75998.8125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 20919.8828125\n",
            "Loss-1 (IC): 0.00047782380715943873, Loss-2 (pde): 1.869040608406067 , Loss-5 (bd): 20918.013671875\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  13714.5166015625\n",
            "Model 989 iterasyondan yüklendi, Loss: 13714.516602\n",
            "MSE between MC-book and PINN: 0.18826946238524245\n",
            "MAPE between MC-book and PINN:: 0.014452791094571253\n",
            "Processing sheet: ORCL\n",
            "F:  [34.689999 34.310001 34.610001 34.43     34.439999 34.459999 34.91\n",
            " 34.860001 34.959999 34.700001 34.639999 34.619999 35.110001 34.93\n",
            " 34.689999 34.939999 35.380001 35.540001 35.779999 35.380001 35.509998\n",
            " 36.209999 35.130001 35.48     35.099998 34.560001 34.900002 34.959999\n",
            " 35.110001 34.990002 34.900002 34.810001 35.400002 35.009998 34.279999\n",
            " 34.75     34.279999 34.32     34.68     34.240002 34.630001 35.049999\n",
            " 35.459999 35.860001 35.939999 35.709999 35.880001 35.43     35.580002\n",
            " 36.299999 36.34    ]\n",
            "F no zero:  [34.689999 34.310001 34.610001 34.43     34.439999 34.459999 34.91\n",
            " 34.860001 34.959999 34.700001 34.639999 34.619999 35.110001 34.93\n",
            " 34.689999 34.939999 35.380001 35.540001 35.779999 35.380001 35.509998\n",
            " 36.209999 35.130001 35.48     35.099998 34.560001 34.900002 34.959999\n",
            " 35.110001 34.990002 34.900002 34.810001 35.400002 35.009998 34.279999\n",
            " 34.75     34.279999 34.32     34.68     34.240002 34.630001 35.049999\n",
            " 35.459999 35.860001 35.939999 35.709999 35.880001 35.43     35.580002\n",
            " 36.299999 36.34    ]\n",
            "spot price no zero:  34.689999\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.094249\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.2980571362894511\n",
            "Beta: 0.9698606772737499\n",
            "Rho: 0.011028082832469368\n",
            "Nu: 0.29127663046781394\n",
            "Iteration 0, Loss: 180839024.0\n",
            "Loss-1 (IC): 0.0002558929845690727, Loss-2 (pde): 1.1036378282369697e-06 , Loss-5 (bd): 180839024.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 1109063.0\n",
            "Loss-1 (IC): 0.000268817413598299, Loss-2 (pde): 0.1534780114889145 , Loss-5 (bd): 1109062.875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 195938.59375\n",
            "Loss-1 (IC): 0.0002699964097701013, Loss-2 (pde): 0.16530506312847137 , Loss-5 (bd): 195938.421875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 89589.046875\n",
            "Loss-1 (IC): 0.0002719653712119907, Loss-2 (pde): 0.856460690498352 , Loss-5 (bd): 89588.1875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 48482.55859375\n",
            "Loss-1 (IC): 0.000274637364782393, Loss-2 (pde): 1.9083247184753418 , Loss-5 (bd): 48480.6484375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 37460.8828125\n",
            "Loss-1 (IC): 0.00026753812562674284, Loss-2 (pde): 1.5679022073745728 , Loss-5 (bd): 37459.31640625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 31477.197265625\n",
            "Loss-1 (IC): 0.00026191744836978614, Loss-2 (pde): 1.0999659299850464 , Loss-5 (bd): 31476.09765625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 31279.166015625\n",
            "Loss-1 (IC): 0.000262692803516984, Loss-2 (pde): 0.8102145195007324 , Loss-5 (bd): 31278.35546875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 24192.625\n",
            "Loss-1 (IC): 0.00027751020388677716, Loss-2 (pde): 0.4165525734424591 , Loss-5 (bd): 24192.208984375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 21625.03125\n",
            "Loss-1 (IC): 0.000269043433945626, Loss-2 (pde): 0.37951862812042236 , Loss-5 (bd): 21624.65234375\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  14136.669921875\n",
            "Model 999 iterasyondan yüklendi, Loss: 14136.669922\n",
            "MSE between MC-book and PINN: 0.10524068343145569\n",
            "MAPE between MC-book and PINN:: 0.013693188094781985\n",
            "Processing sheet: T\n",
            "F:  [35.       35.02     35.23     35.389999 34.349998 34.240002 34.369999\n",
            " 34.27     34.02     33.759998 33.259998 33.200001 33.439999 33.610001\n",
            " 33.779999 33.75     34.02     34.130001 34.68     34.48     34.790001\n",
            " 35.509998 35.23     35.349998 35.43     35.27     35.27     35.23\n",
            " 35.599998 35.419998 35.290001 35.360001 35.669998 35.470001 35.43\n",
            " 35.68     35.189999 35.490002 35.849998 35.91     36.009998 36.23\n",
            " 36.599998 36.290001 36.389999 36.68     36.599998 36.720001 36.599998\n",
            " 36.860001 36.43     36.150002 36.139999 36.189999 36.150002 36.43\n",
            " 36.389999 36.740002 36.619999 36.689999 37.25     37.57     37.279999\n",
            " 37.91     38.02     37.619999 37.759998 38.18     38.540001 38.59\n",
            " 37.950001 37.939999 37.779999 37.740002 38.279999]\n",
            "F no zero:  [35.       35.02     35.23     35.389999 34.349998 34.240002 34.369999\n",
            " 34.27     34.02     33.759998 33.259998 33.200001 33.439999 33.610001\n",
            " 33.779999 33.75     34.02     34.130001 34.68     34.48     34.790001\n",
            " 35.509998 35.23     35.349998 35.43     35.27     35.27     35.23\n",
            " 35.599998 35.419998 35.290001 35.360001 35.669998 35.470001 35.43\n",
            " 35.68     35.189999 35.490002 35.849998 35.91     36.009998 36.23\n",
            " 36.599998 36.290001 36.389999 36.68     36.599998 36.720001 36.599998\n",
            " 36.860001 36.43     36.150002 36.139999 36.189999 36.150002 36.43\n",
            " 36.389999 36.740002 36.619999 36.689999 37.25     37.57     37.279999\n",
            " 37.91     38.02     37.619999 37.759998 38.18     38.540001 38.59\n",
            " 37.950001 37.939999 37.779999 37.740002 38.279999]\n",
            "spot price no zero:  35.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.0576\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.282021033968996\n",
            "Beta: 0.9999975860277672\n",
            "Rho: -0.03762428324550569\n",
            "Nu: 0.3714000430010855\n",
            "Iteration 0, Loss: 192128912.0\n",
            "Loss-1 (IC): 0.00028381485026329756, Loss-2 (pde): 4.0051682503872144e-07 , Loss-5 (bd): 192128912.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 1295991.875\n",
            "Loss-1 (IC): 0.0002786501427181065, Loss-2 (pde): 0.7567092180252075 , Loss-5 (bd): 1295991.125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 148281.15625\n",
            "Loss-1 (IC): 0.00027612262056209147, Loss-2 (pde): 1.7265163660049438 , Loss-5 (bd): 148279.421875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 65632.6953125\n",
            "Loss-1 (IC): 0.0002938958059530705, Loss-2 (pde): 3.6454849243164062 , Loss-5 (bd): 65629.046875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 46267.5703125\n",
            "Loss-1 (IC): 0.00026745549985207617, Loss-2 (pde): 3.5650405883789062 , Loss-5 (bd): 46264.00390625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 39393.15234375\n",
            "Loss-1 (IC): 0.00028562205261550844, Loss-2 (pde): 3.1260647773742676 , Loss-5 (bd): 39390.02734375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 36272.1328125\n",
            "Loss-1 (IC): 0.0002629550581332296, Loss-2 (pde): 1.948728322982788 , Loss-5 (bd): 36270.18359375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 26735.8046875\n",
            "Loss-1 (IC): 0.00028254775679670274, Loss-2 (pde): 1.792272686958313 , Loss-5 (bd): 26734.01171875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 25791.908203125\n",
            "Loss-1 (IC): 0.00025953832664527, Loss-2 (pde): 1.2507132291793823 , Loss-5 (bd): 25790.658203125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 17340.72265625\n",
            "Loss-1 (IC): 0.0002782410301733762, Loss-2 (pde): 1.097267508506775 , Loss-5 (bd): 17339.625\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  10742.265625\n",
            "Model 994 iterasyondan yüklendi, Loss: 10742.265625\n",
            "MSE between MC-book and PINN: 0.22094114782609164\n",
            "MAPE between MC-book and PINN:: 0.013228981516490901\n",
            "Processing sheet: PM\n",
            "F:  [86.739998 85.860001 86.519997 86.25     86.089996 85.830002 87.290001\n",
            " 89.230003 89.07     88.919998 88.339996 89.139999 89.980003 90.029999\n",
            " 88.839996 89.760002 89.419998 89.       88.910004 87.650002 88.160004\n",
            " 88.129997 87.330002 87.959999 87.690002 89.82     90.449997 90.349998\n",
            " 90.139999 90.989998 90.010002 89.989998 91.309998 92.089996 93.129997\n",
            " 93.419998 91.559998 91.599998 91.43     91.75     91.440002 92.360001\n",
            " 92.279999 91.599998 91.809998 91.110001 91.209999 90.889999 90.550003\n",
            " 91.309998 91.370003]\n",
            "F no zero:  [86.739998 85.860001 86.519997 86.25     86.089996 85.830002 87.290001\n",
            " 89.230003 89.07     88.919998 88.339996 89.139999 89.980003 90.029999\n",
            " 88.839996 89.760002 89.419998 89.       88.910004 87.650002 88.160004\n",
            " 88.129997 87.330002 87.959999 87.690002 89.82     90.449997 90.349998\n",
            " 90.139999 90.989998 90.010002 89.989998 91.309998 92.089996 93.129997\n",
            " 93.419998 91.559998 91.599998 91.43     91.75     91.440002 92.360001\n",
            " 92.279999 91.599998 91.809998 91.110001 91.209999 90.889999 90.550003\n",
            " 91.309998 91.370003]\n",
            "spot price no zero:  86.739998\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.04322241\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.22227943873918005\n",
            "Beta: 0.9999999848725699\n",
            "Rho: -0.0019387843837688145\n",
            "Nu: 0.30376730628781495\n",
            "Iteration 0, Loss: 884230144.0\n",
            "Loss-1 (IC): 0.0013370949309319258, Loss-2 (pde): 4.352029918663902e-06 , Loss-5 (bd): 884230144.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 25387322.0\n",
            "Loss-1 (IC): 0.0013201807159930468, Loss-2 (pde): 0.7046617865562439 , Loss-5 (bd): 25387322.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 257876.0\n",
            "Loss-1 (IC): 0.0014498181408271194, Loss-2 (pde): 4.343789100646973 , Loss-5 (bd): 257871.65625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 303606.03125\n",
            "Loss-1 (IC): 0.001540357363410294, Loss-2 (pde): 4.581973552703857 , Loss-5 (bd): 303601.4375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 1053582.875\n",
            "Loss-1 (IC): 0.0014929523458704352, Loss-2 (pde): 6.368492603302002 , Loss-5 (bd): 1053576.5\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 179804.953125\n",
            "Loss-1 (IC): 0.001531500369310379, Loss-2 (pde): 9.911482810974121 , Loss-5 (bd): 179795.046875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 92980.6875\n",
            "Loss-1 (IC): 0.0013802866451442242, Loss-2 (pde): 14.637868881225586 , Loss-5 (bd): 92966.046875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 96761.0\n",
            "Loss-1 (IC): 0.0014722149353474379, Loss-2 (pde): 15.154293060302734 , Loss-5 (bd): 96745.84375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 129704.6640625\n",
            "Loss-1 (IC): 0.0015011134091764688, Loss-2 (pde): 17.4240665435791 , Loss-5 (bd): 129687.2421875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 236269.953125\n",
            "Loss-1 (IC): 0.0015768298180773854, Loss-2 (pde): 20.2243595123291 , Loss-5 (bd): 236249.734375\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  68675.3984375\n",
            "Model 990 iterasyondan yüklendi, Loss: 68675.398438\n",
            "MSE between MC-book and PINN: 0.30982480033985144\n",
            "MAPE between MC-book and PINN:: 0.011639224136841497\n",
            "Processing sheet: BAC\n",
            "F:  [12.03 11.96 12.11 12.09 11.98 11.43 11.78 11.63 11.47 11.55 11.78 11.28\n",
            " 11.14 11.35 11.42 11.53 11.62 11.48 11.49 11.38 11.32 11.71 11.48 11.88\n",
            " 11.93 11.84 11.76 11.86 12.25 12.17 12.13 12.03 12.19 11.8  11.42 11.44\n",
            " 11.03 11.13 11.3  11.23 11.34 11.41 11.55 11.92 12.26 12.07 12.15 12.01\n",
            " 12.06 12.11 12.57 12.56 12.71 12.78 12.57 12.56 12.4  12.28 12.23 12.18\n",
            " 12.15 12.15 11.81 11.94 11.97 12.21 12.25 12.32 12.27 12.17 11.98 12.28\n",
            " 11.7  11.44 11.66]\n",
            "F no zero:  [12.03 11.96 12.11 12.09 11.98 11.43 11.78 11.63 11.47 11.55 11.78 11.28\n",
            " 11.14 11.35 11.42 11.53 11.62 11.48 11.49 11.38 11.32 11.71 11.48 11.88\n",
            " 11.93 11.84 11.76 11.86 12.25 12.17 12.13 12.03 12.19 11.8  11.42 11.44\n",
            " 11.03 11.13 11.3  11.23 11.34 11.41 11.55 11.92 12.26 12.07 12.15 12.01\n",
            " 12.06 12.11 12.57 12.56 12.71 12.78 12.57 12.56 12.4  12.28 12.23 12.18\n",
            " 12.15 12.15 11.81 11.94 11.97 12.21 12.25 12.32 12.27 12.17 11.98 12.28\n",
            " 11.7  11.44 11.66]\n",
            "spot price no zero:  12.03\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.16048036000000002\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.39735129568374344\n",
            "Beta: 0.9932197227417094\n",
            "Rho: 0.0015674316750641352\n",
            "Nu: 0.2975880092459862\n",
            "Iteration 0, Loss: 36122092.0\n",
            "Loss-1 (IC): 5.4026226280257106e-05, Loss-2 (pde): 1.6800746379885823e-05 , Loss-5 (bd): 36122092.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 163126.703125\n",
            "Loss-1 (IC): 4.768585495185107e-05, Loss-2 (pde): 0.0011139406124129891 , Loss-5 (bd): 163126.703125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 30549.267578125\n",
            "Loss-1 (IC): 4.748449646285735e-05, Loss-2 (pde): 0.06699716299772263 , Loss-5 (bd): 30549.201171875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 25623.5703125\n",
            "Loss-1 (IC): 4.797071233042516e-05, Loss-2 (pde): 0.08182568848133087 , Loss-5 (bd): 25623.48828125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 19223.91796875\n",
            "Loss-1 (IC): 4.881566928816028e-05, Loss-2 (pde): 0.09603282809257507 , Loss-5 (bd): 19223.822265625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 15057.45703125\n",
            "Loss-1 (IC): 4.821230686502531e-05, Loss-2 (pde): 0.09022416174411774 , Loss-5 (bd): 15057.3671875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 12731.4228515625\n",
            "Loss-1 (IC): 4.893056029686704e-05, Loss-2 (pde): 0.05989731848239899 , Loss-5 (bd): 12731.36328125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 10030.8505859375\n",
            "Loss-1 (IC): 4.933208765578456e-05, Loss-2 (pde): 0.025664733722805977 , Loss-5 (bd): 10030.8251953125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 6215.4404296875\n",
            "Loss-1 (IC): 4.5891069021308795e-05, Loss-2 (pde): 0.00851984042674303 , Loss-5 (bd): 6215.431640625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 4326.11669921875\n",
            "Loss-1 (IC): 4.7180696128634736e-05, Loss-2 (pde): 0.0035422469954937696 , Loss-5 (bd): 4326.11328125\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  3122.61181640625\n",
            "Model 985 iterasyondan yüklendi, Loss: 3122.611816\n",
            "MSE between MC-book and PINN: 0.03865698371080102\n",
            "MAPE between MC-book and PINN:: 0.02102117218035172\n",
            "Processing sheet: VZ\n",
            "F:  [44.27     44.060001 44.299999 44.689999 43.099998 43.       43.59\n",
            " 43.299999 42.59     41.970001 41.509998 42.130001 42.540001 42.939999\n",
            " 42.790001 42.59     42.669998 42.77     43.5      43.610001 43.610001\n",
            " 44.560001 44.52     44.560001 44.75     44.459999 44.349998 44.32\n",
            " 44.439999 44.52     44.330002 44.400002 44.5      44.919998 45.119999\n",
            " 45.400002 45.720001 46.119999 46.349998 46.529999 46.720001 47.110001\n",
            " 47.689999 47.279999 47.48     47.959999 47.810001 48.360001 47.939999\n",
            " 48.48     48.02     48.75     48.950001 48.599998 48.799999 49.02\n",
            " 49.16     49.48     48.939999 49.150002 49.220001 49.5      48.990002\n",
            " 49.299999 49.560001 49.43     49.360001 49.860001 50.509998 50.860001\n",
            " 50.639999 50.459999 49.540001 50.91     52.25    ]\n",
            "F no zero:  [44.27     44.060001 44.299999 44.689999 43.099998 43.       43.59\n",
            " 43.299999 42.59     41.970001 41.509998 42.130001 42.540001 42.939999\n",
            " 42.790001 42.59     42.669998 42.77     43.5      43.610001 43.610001\n",
            " 44.560001 44.52     44.560001 44.75     44.459999 44.349998 44.32\n",
            " 44.439999 44.52     44.330002 44.400002 44.5      44.919998 45.119999\n",
            " 45.400002 45.720001 46.119999 46.349998 46.529999 46.720001 47.110001\n",
            " 47.689999 47.279999 47.48     47.959999 47.810001 48.360001 47.939999\n",
            " 48.48     48.02     48.75     48.950001 48.599998 48.799999 49.02\n",
            " 49.16     49.48     48.939999 49.150002 49.220001 49.5      48.990002\n",
            " 49.299999 49.560001 49.43     49.360001 49.860001 50.509998 50.860001\n",
            " 50.639999 50.459999 49.540001 50.91     52.25    ]\n",
            "spot price no zero:  44.27\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/tmp/ipython-input-2940639486.py:35: DeprecationWarning: scipy.optimize: The `disp` and `iprint` options of the L-BFGS-B solver are deprecated and will be removed in SciPy 1.18.0.\n",
            "  result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Optimized Heston parameters:\n",
            "v0: 0.03006756\n",
            "kappa: 2.0\n",
            "theta: 0.04\n",
            "sigma_heston: 0.1\n",
            "rho_heston: -0.7\n",
            "Optimized SABR parameters:\n",
            "Alpha: 0.23610427668431044\n",
            "Beta: 0.9999903182365623\n",
            "Rho: -0.0758874702053863\n",
            "Nu: 0.5335626520991193\n",
            "Iteration 0, Loss: 392202528.0\n",
            "Loss-1 (IC): 0.0006475457921624184, Loss-2 (pde): 8.777198672760278e-05 , Loss-5 (bd): 392202528.0\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 100, Loss: 5687350.5\n",
            "Loss-1 (IC): 0.0005283034988678992, Loss-2 (pde): 1.0548624992370605 , Loss-5 (bd): 5687349.5\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 200, Loss: 263643.1875\n",
            "Loss-1 (IC): 0.0006167766987346113, Loss-2 (pde): 1.6262776851654053 , Loss-5 (bd): 263641.5625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 300, Loss: 99686.15625\n",
            "Loss-1 (IC): 0.0006190154817886651, Loss-2 (pde): 2.7271339893341064 , Loss-5 (bd): 99683.4296875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 400, Loss: 75616.28125\n",
            "Loss-1 (IC): 0.0005771387368440628, Loss-2 (pde): 1.986043095588684 , Loss-5 (bd): 75614.296875\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 500, Loss: 67912.546875\n",
            "Loss-1 (IC): 0.0005911182379350066, Loss-2 (pde): 1.438616156578064 , Loss-5 (bd): 67911.109375\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 600, Loss: 62267.390625\n",
            "Loss-1 (IC): 0.0005779963103123009, Loss-2 (pde): 0.9792784452438354 , Loss-5 (bd): 62266.41015625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 700, Loss: 70657.4921875\n",
            "Loss-1 (IC): 0.0005493268836289644, Loss-2 (pde): 0.9169387817382812 , Loss-5 (bd): 70656.578125\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 800, Loss: 44669.51171875\n",
            "Loss-1 (IC): 0.0005838556680828333, Loss-2 (pde): 0.8857097029685974 , Loss-5 (bd): 44668.625\n",
            "CURRENT LR: [0.0002]\n",
            "Iteration 900, Loss: 41098.53125\n",
            "Loss-1 (IC): 0.0005831278976984322, Loss-2 (pde): 0.6483012437820435 , Loss-5 (bd): 41097.8828125\n",
            "CURRENT LR: [0.0002]\n",
            "best loss:  27907.37109375\n",
            "Model 989 iterasyondan yüklendi, Loss: 27907.371094\n",
            "MSE between MC-book and PINN: 0.11466633418708973\n",
            "MAPE between MC-book and PINN:: 0.00887250765321329\n"
          ]
        }
      ],
      "source": [
        "for sheet_name in sheet_names:\n",
        "    print(f\"Processing sheet: {sheet_name}\")\n",
        "    # Load data for the current sheet\n",
        "    df = pd.read_excel(excel_file, sheet_name=sheet_name)\n",
        "\n",
        "    F = df['close'].values  # SPOT PRICE\n",
        "    spot_price = df['close'].iloc[0]\n",
        "    sigma = df['implied_volatility'].values\n",
        "    K = df['strike'].values\n",
        "    market_prices = df['Option_mid'].values\n",
        "    time = df['Remaining_day'].values / 252\n",
        "\n",
        "    df_no_zeros = df[df[\"Option_mid\"] != 0]\n",
        "\n",
        "    F_nozero = df['close'].values  # SPOT PRICE\n",
        "    spot_price_nozero = df['close'].iloc[0]\n",
        "    sigma_nozero = df['implied_volatility'].values\n",
        "    K_nozero = df['strike'].values\n",
        "    market_prices_nozero = df['Option_mid'].values\n",
        "    time_nozero = df['Remaining_day'].values / 252\n",
        "\n",
        "    print( \"F: \", F)\n",
        "    print( \"F no zero: \", F_nozero)\n",
        "    print( \"spot price no zero: \", spot_price_nozero)\n",
        "\n",
        "    # Initial parameter guesses for heston\n",
        "    initial_params_heston = [sigma_nozero[0]**2, 2.0, 0.04, 0.1, -0.7] # v0 - initial variance, kappa - mean reversion speed, theta - long-term variance, sigma - vol of vol, rho - correlation\n",
        "\n",
        "     # Bounds for heston parameters (v0 > 0, kappa > 0, theta > 0, sigma > 0, -1 <= rho <= 1)\n",
        "    bounds_heston = [(0.01, 0.5), (0.1, 10.0), (0.01, 0.5), (0.01, 1.0), (-0.99, 0.99)]\n",
        "\n",
        "    # Run calibration for heston parameters\n",
        "    result_parameters_heston = minimize(heston_calibration_error, initial_params_heston, args=(market_prices_nozero, K_nozero, time_nozero, F_nozero),\n",
        "                                        bounds=bounds_heston, method='L-BFGS-B', options={'maxiter': 100, 'disp': True})\n",
        "\n",
        "    # Extract calibrated heston parameters\n",
        "    v0_heston, kappa, theta, sigma_heston, rho_heston = result_parameters_heston.x\n",
        "\n",
        "    print(\"Optimized Heston parameters:\")\n",
        "    print(\"v0:\", v0_heston)\n",
        "    print(\"kappa:\", kappa)\n",
        "    print(\"theta:\", theta)\n",
        "    print(\"sigma_heston:\", sigma_heston)\n",
        "    print(\"rho_heston:\", rho_heston)\n",
        "\n",
        "    # Initial guess for SABR parameters\n",
        "    initial_guess = [sigma[0], 1, 0.0, 0.3]\n",
        "\n",
        "        # Optimize SABR parameters\n",
        "    result_parameters = minimize(sabr_loss, initial_guess, args=(F[0], K, time[0], sigma),\n",
        "                              bounds=[(0.01, 1), (0, 1), (-0.99, 0.99), (0.01, None)])\n",
        "\n",
        "    alfa, beta, rho, nu = result_parameters.x\n",
        "\n",
        "    print(\"Optimized SABR parameters:\")\n",
        "    print(\"Alpha:\", alfa)\n",
        "    print(\"Beta:\", beta)\n",
        "    print(\"Rho:\", rho)\n",
        "    print(\"Nu:\", nu)\n",
        "\n",
        "        # Veriyi torch tensöre dönüştür\n",
        "    F_torch = torch.tensor(F, dtype=torch.float32, requires_grad=True).view(-1, 1)\n",
        "    sigma_torch = torch.tensor(sigma, dtype=torch.float32, requires_grad=True).view(-1, 1)\n",
        "\n",
        "    # min max değerler\n",
        "    F_min, F_max = torch.min(F_torch).item(), torch.max(F_torch).item()\n",
        "    v_min, v_max = torch.min(sigma_torch).item(), torch.max(sigma_torch).item()\n",
        "\n",
        "    r=0.0007\n",
        "\n",
        "    lambda1, lambda2 = 1, 1\n",
        "\n",
        "    model = Alternative_FCN()\n",
        "    optimizer = torch.optim.Adam(model.parameters(),lr=2e-4)\n",
        "    scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(\n",
        "        optimizer,\n",
        "        mode='min',\n",
        "        factor=0.5,\n",
        "        patience=200,\n",
        "        min_lr=2e-5)\n",
        "\n",
        "    best_loss = float('inf')\n",
        "    save_path = 'best_model.pth'\n",
        "\n",
        "    totallosses=[]\n",
        "    Lic_list = []\n",
        "    Lpde_list = []\n",
        "    Lbd_list = []\n",
        "    Lbd_Smax_list = []\n",
        "    Lbd_Smin_list = []\n",
        "    Lbd_Vmax_list = []\n",
        "    Lbd_V0_list = []\n",
        "\n",
        "# Compute model\n",
        "\n",
        "    for i in range(1000):\n",
        "        data = generate_points_per_condition(N=1000, S_min=0.0, S_max=1.2*F_max,\n",
        "                                    sigma_min=0.0, sigma_max=1.1*v_max, t=1.0)\n",
        "\n",
        "        t0 = data['initial'].clone().detach().requires_grad_(True)\n",
        "        V0 = data['bd_sigma0'].clone().detach().requires_grad_(True)\n",
        "        S0 = data['bd_S0'].clone().detach().requires_grad_(True)\n",
        "        Smax = data['bd_Smax'].clone().detach().requires_grad_(True)\n",
        "        vmax = data['bd_sigmamax'].clone().detach().requires_grad_(True)\n",
        "        inputs = data['interior'].clone().detach().requires_grad_(True)\n",
        "        inputs_all = data['all'].clone().detach().requires_grad_(True)\n",
        "\n",
        "\n",
        "        C0 = model(t0)\n",
        "        loss1 = (torch.squeeze(C0) - IC_european_call(t0[:,0].requires_grad_(True).reshape(-1, 1), K[0]))**2\n",
        "        Lic = lambda1 * loss1.mean()\n",
        "\n",
        "    # Compute the PDE residual as the loss\n",
        "        residual = heston_pde(model, inputs[:,0].requires_grad_(True).reshape(-1, 1), inputs[:,1].requires_grad_(True).reshape(-1, 1), inputs[:,2].requires_grad_(True).reshape(-1, 1),  kappa, theta, sigma_heston, rho_heston, r)\n",
        "        Lpde = lambda2 *torch.mean(torch.relu(-residual)**2)  #AMERICAN OPTION (C-max(S-K, 0)) >= 0 , pde >= 0\n",
        "\n",
        "        bnd_early = ame_condition(model, inputs, K[0])\n",
        "\n",
        "        bnd_S_min = Smin_conditions(model, S0)\n",
        "\n",
        "        bnd_S_max = Smax_conditions(model, Smax)\n",
        "\n",
        "        bnd_v_min = v0_conditions(model, V0, K[0], r)\n",
        "\n",
        "        bnd_v_max = Vmax_conditions(model, vmax)\n",
        "\n",
        "        Lbd = ( 10*bnd_S_max + 0.0001*bnd_v_max + 1000000*bnd_v_min + 1*bnd_S_min )\n",
        "        Lic2 = 0.0000015*Lic\n",
        "        Lpde2 = Lpde\n",
        "        loss = Lic2 + Lpde2 + Lbd\n",
        "\n",
        "        loss.backward(retain_graph=True)\n",
        "        optimizer.step()\n",
        "        scheduler.step(loss)\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        totallosses.append(loss.item())\n",
        "        Lic_list.append(Lic2.item())\n",
        "        Lpde_list.append(Lpde2.item())\n",
        "        Lbd_list.append(Lbd.item())\n",
        "\n",
        "        if i % 100 == 0:\n",
        "            print(f\"Iteration {i}, Loss: {loss.item()}\")\n",
        "            print(f\"Loss-1 (IC): {Lic2.item()}, Loss-2 (pde): {Lpde2.item()} , Loss-5 (bd): {Lbd.item()}\")\n",
        "            print(\"CURRENT LR:\", scheduler.get_last_lr())\n",
        "\n",
        "        if loss.item() < best_loss:\n",
        "            best_loss = loss.item()\n",
        "            torch.save({\n",
        "                'model_state_dict': model.state_dict(),\n",
        "                'optimizer_state_dict': optimizer.state_dict(),\n",
        "                'loss': best_loss,\n",
        "                'iteration': i\n",
        "                }, save_path)\n",
        "\n",
        "    print(\"best loss: \", best_loss )\n",
        "\n",
        "    checkpoint = torch.load(\"best_model.pth\")\n",
        "    model.load_state_dict(checkpoint['model_state_dict'])\n",
        "    optimizer.load_state_dict(checkpoint['optimizer_state_dict'])\n",
        "    print(f\"Model {checkpoint['iteration']} iterasyondan yüklendi, Loss: {checkpoint['loss']:.6f}\")\n",
        "\n",
        "    F_torch = torch.tensor(F, dtype=torch.float32, requires_grad=True).view(-1, 1)\n",
        "    sigma_torch = torch.tensor(sigma, dtype=torch.float32, requires_grad=True).view(-1, 1)\n",
        "    time_torch = torch.tensor(time, dtype=torch.float32, requires_grad=True).view(-1, 1)\n",
        "\n",
        "    inputs_heston = torch.cat([F_torch, sigma_torch, time_torch], dim=1)\n",
        "\n",
        "    C = model(inputs_heston) # PINN OPTION PRICES\n",
        "    C = C.detach().numpy()\n",
        "\n",
        "    bs_op_pr = black_scholes_option_price(F, K[0], time, r, sigma) # ANALYTICAL BS OPTION PRICES\n",
        "\n",
        "    mc = sabr_european_call_mc(F, sigma, time, K[0], r, beta2, nu2, rho2, N=100, M=10000, confidence=0.95) # MONTE CARLO OPTIONS PRİCES\n",
        "\n",
        "    plt.plot(time, C, label=\"Heston-PINN\", linestyle='dashed')\n",
        "    plt.plot(time, bs_op_pr, label=\"Analytical BS Values\")\n",
        "    plt.plot(time, mc, label=\"Monte Carlo Values\")\n",
        "    plt.xlabel(\"Time (t)\")\n",
        "    plt.ylabel(\"Option Price (C)\")\n",
        "    plt.legend()\n",
        "    plot_path = os.path.join(output_dir, f\"{sheet_name}_option_price_plot_time.png\")\n",
        "    plt.savefig(plot_path)\n",
        "    plt.close()\n",
        "    plt.show()\n",
        "\n",
        "    mse1 = np.mean((mc - C.ravel())**2)\n",
        "    mape1 = np.mean(np.abs((mc - C.ravel()) / mc))\n",
        "    print(\"MSE between MC and PINN:\", mse1)\n",
        "    print(\"MAPE between MC and PINN::\", mape1)\n",
        "\n",
        "    new_row = pd.DataFrame({\n",
        "    \"Sheet\": [sheet_name],\n",
        "    \"Heston Model MSE\": [mse1],\n",
        "    \"Heston Model MAPE\": [mape1],\n",
        "    })\n",
        "\n",
        "    results_MC_df = pd.concat([results_MC_df, new_row], ignore_index=True)\n",
        "\n",
        "    prediction_df[f'Heston_{sheet_name}'] = pd.Series(C.flatten())\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "0IEfnQG8NWyk"
      },
      "source": [
        "# ***SAVING***"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7ryfn2IQDSh",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "fb77bee1-099c-4bcc-fd6e-938f929711c5"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Results saved to /content/drive/MyDrive/Bitirme_real_dataset/new/Heston/real/ame/MSE_MAPE_Results_analytic.xlsx\n",
            "Results saved to /content/drive/MyDrive/Bitirme_real_dataset/new/Heston/real/ame/Predictions.xlsx\n"
          ]
        }
      ],
      "source": [
        "# Save results to an Excel file\n",
        "results_file = \"/content/drive/MyDrive/Bitirme_real_dataset/new/Heston/real/ame/MSE_MAPE_Results_analytic.xlsx\"\n",
        "results_MC_df.to_excel(results_file, index=False)\n",
        "print(f\"Results saved to {results_file}\")\n",
        "\n",
        "\n",
        "# Save results to an Excel file\n",
        "results_file2 = \"/content/drive/MyDrive/Bitirme_real_dataset/new/Heston/real/ame/Predictions.xlsx\"\n",
        "prediction_df.to_excel(results_file2, index=False)\n",
        "print(f\"Results saved to {results_file2}\")"
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "XkR2BqwAbkiY"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "machine_shape": "hm",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}